# insert_helper.py
import os
import glob
import pandas as pd

class InsertSQLGenerator:
    def __init__(self, config: dict, input_folder: str, output_folder: str = "generated_inserts"):
        self.input_folder = input_folder
        self.output_folder = output_folder
        self.categories = config.get("categories", {})
        self.category_keys = list(self.categories.keys())

    def get_excel_files(self):
        patterns = ["*.xls", "*.xlsx", "*.xlsm"]
        files = []
        for p in patterns:
            files.extend(glob.glob(os.path.join(self.input_folder, p)))
        return files

    def load_all_sheets(self, file_path):
        try:
            xls = pd.ExcelFile(file_path)
            sheets = []
            for sheet_name in xls.sheet_names:
                try:
                    df = pd.read_excel(file_path, sheet_name=sheet_name)
                    df.columns = df.columns.str.strip()
                    for cfg in self.categories.values():
                        for col_key in ["schema_col", "table_col", "column_col"]:
                            col = cfg.get(col_key)
                            if col in df.columns:
                                df[col] = df[col].ffill()
                    sheets.append(df)
                except Exception as e:
                    print(f"‚ö†Ô∏è Error reading sheet {sheet_name}: {e}")
            return pd.concat(sheets, ignore_index=True) if sheets else pd.DataFrame()
        except Exception as e:
            print(f"‚ùå Error loading {file_path}: {e}")
            return pd.DataFrame()

    def create_row_mappings(self, df):
        row_mappings = []
        valid_rows = df.dropna(how="all")
        for _, row in valid_rows.iterrows():
            mapping = {}
            for cat in self.category_keys:
                cfg = self.categories[cat]
                schema = str(row.get(cfg["schema_col"], "NA")).strip()
                table = str(row.get(cfg["table_col"], "NA")).strip()
                column = str(row.get(cfg["column_col"], "NA")).strip()
                table_comment = str(row.get(cfg.get("table_comment_col", ""), "")).strip()
                column_comment = str(row.get(cfg.get("column_comment_col", ""), "")).strip()

                schema = "NA" if schema in ["nan", "None", ""] else schema
                table = "NA" if table in ["nan", "None", ""] else table
                column = "NA" if column in ["nan", "None", ""] else column
                table_comment = "" if table_comment in ["nan", "None"] else table_comment
                column_comment = "" if column_comment in ["nan", "None"] else column_comment

                mapping[cat] = {
                    "table": (schema, table),
                    "column": column,
                    "table_comment": table_comment,
                    "column_comment": column_comment,
                    "has_na": schema == "NA" or table == "NA" or column == "NA"
                }
            row_mappings.append(mapping)
        return row_mappings

    def generate_sql_for_row(self, mapping):
        """Generate SQL statements per row with only one case applied per row."""
        edl = mapping.get("EDL", {})
        rdmof = mapping.get("RDMOF", {})
        original = mapping.get("Original_SSR", {})

        edl_na = edl.get("has_na", True)
        rdmof_na = rdmof.get("has_na", True)
        original_na = original.get("has_na", True)

        sql_statements = []

        # CASE 1: All present ‚Üí Original‚ÜíEDL + EDL‚ÜíRDMOF
        if not original_na and not edl_na and not rdmof_na:
            sql_statements.append(self.build_sql(original, edl, description="Original_SSR ‚Üí EDL"))
            sql_statements.append(self.build_sql(edl, rdmof, description="EDL ‚Üí RDMOF"))

        # CASE 2: Only Original‚ÜíRDMOF (EDL NA)
        elif not original_na and edl_na and not rdmof_na:
            sql_statements.append(self.build_sql(original, rdmof, description="Original_SSR ‚Üí RDMOF (EDL is NA)"))

        # CASE 3: Only Original‚ÜíEDL (RDMOF NA)
        elif not original_na and not edl_na and rdmof_na:
            sql_statements.append(self.build_sql(original, edl, description="Original_SSR ‚Üí EDL (RDMOF is NA)"))

        # CASE 4: Only EDL‚ÜíRDMOF (Original NA)
        elif original_na and not edl_na and not rdmof_na:
            sql_statements.append(self.build_sql(edl, rdmof, description="EDL ‚Üí RDMOF (Original_SSR is NA)"))

        # CASE 5: Anything else ‚Üí commented placeholder
        else:
            sql_statements.append(self.build_commented_placeholder(mapping, "Multiple categories have NA values"))

        return sql_statements

    def build_sql(self, src, tgt, description="", comment_all=False):
        src_schema, src_table = src.get("table", ("NA", "NA"))
        tgt_schema, tgt_table = tgt.get("table", ("NA", "NA"))
        src_col = src.get("column", "NA")
        tgt_col = tgt.get("column", "NA")

        comments = [f"-- {description}"] if description else []

        for c in [src.get("table_comment", ""), src.get("column_comment", ""),
                  tgt.get("table_comment", ""), tgt.get("column_comment", "")]:
            if c:
                comments.extend([f"-- {line.strip()}" for line in str(c).splitlines() if line.strip()])

        comment_text = "\n".join(comments)
        if comment_text:
            comment_text += "\n"

        if comment_all or src.get("has_na") or tgt.get("has_na"):
            return (
                f"{comment_text}"
                f"-- Mapping skipped due to NA values\n"
                f"-- {src_schema}.{src_table}.{src_col} ‚Üí {tgt_schema}.{tgt_table}.{tgt_col}\n"
            )
        else:
            return (
                f"{comment_text}"
                f"INSERT INTO {tgt_schema}.{tgt_table} ({tgt_col})\n"
                f"SELECT DISTINCT {src_col} FROM {src_schema}.{src_table};\n"
            )

    def build_commented_placeholder(self, mapping, reason):
        return (
            f"-- {reason}\n"
            f"-- Row skipped: No valid transformation possible\n"
            f"-- Original_SSR: {'NA' if mapping.get('Original_SSR', {}).get('has_na', True) else 'Valid'}\n"
            f"-- EDL: {'NA' if mapping.get('EDL', {}).get('has_na', True) else 'Valid'}\n"
            f"-- RDMOF: {'NA' if mapping.get('RDMOF', {}).get('has_na', True) else 'Valid'}\n"
        )

    def process_file(self, file_path):
        df = self.load_all_sheets(file_path)
        if df.empty:
            return [], set()

        row_maps = self.create_row_mappings(df)
        all_sql = []
        unique_set = set()

        for row_map in row_maps:
            sql_list = self.generate_sql_for_row(row_map)
            for sql in sql_list:
                sql_normalized = " ".join(sql.split())
                if sql_normalized not in unique_set:
                    all_sql.append(sql)
                    unique_set.add(sql_normalized)

        return all_sql, unique_set

    def run(self):
        os.makedirs(self.output_folder, exist_ok=True)
        files = self.get_excel_files()
        if not files:
            print(f"‚ùå No Excel files found in {self.input_folder}")
            return

        total_unique = 0
        print(f"üîÑ Processing {len(files)} Excel file(s)...")

        for f in files:
            print(f"\nüìÑ Processing: {os.path.basename(f)}")
            sql_list, unique_sql = self.process_file(f)

            if sql_list:
                out_file = os.path.splitext(os.path.basename(f))[0] + ".sql"
                out_path = os.path.join(self.output_folder, out_file)
                with open(out_path, "w", encoding="utf-8") as fw:
                    fw.write(f"-- Generated SQL from: {os.path.basename(f)}\n")
                    fw.write(f"-- Total unique statements: {len(sql_list)}\n\n")
                    fw.write("\n".join(sql_list))
                total_unique += len(unique_sql)
                print(f"‚úÖ {out_file}: {len(unique_sql)} unique statements")
            else:
                print(f"‚ö†Ô∏è No valid SQL generated for {os.path.basename(f)}")

        print(f"\nüìä Summary: Total unique statements: {total_unique}")

---
def generate_sql_for_row(self, mapping):
    edl = mapping.get("EDL", {})
    rdmof = mapping.get("RDMOF", {})
    original = mapping.get("Original_SSR", {})

    edl_na = edl.get("has_na", True)
    rdmof_na = rdmof.get("has_na", True)
    original_na = original.get("has_na", True)

    sql_statements = []

    # 1Ô∏è‚É£ All present ‚Üí Original‚ÜíEDL + EDL‚ÜíRDMOF
    if not original_na and not edl_na and not rdmof_na:
        sql_statements.append(self.build_sql(original, edl, description="Original ‚Üí EDL"))
        sql_statements.append(self.build_sql(edl, rdmof, description="EDL ‚Üí RDMOF"))

    # 2Ô∏è‚É£ Original‚ÜíRDMOF (EDL NA)
    elif not original_na and edl_na and not rdmof_na:
        sql_statements.append(self.build_sql(original, rdmof, description="Original ‚Üí RDMOF"))

    # 3Ô∏è‚É£ Original‚ÜíEDL (RDMOF NA)
    elif not original_na and not edl_na and rdmof_na:
        sql_statements.append(self.build_sql(original, edl, description="Original ‚Üí EDL"))

    # 4Ô∏è‚É£ EDL‚ÜíRDMOF (Original NA)
    elif original_na and not edl_na and not rdmof_na:
        sql_statements.append(self.build_sql(edl, rdmof, description="EDL ‚Üí RDMOF"))

    # 5Ô∏è‚É£ Anything else ‚Üí placeholder
    else:
        sql_statements.append(self.build_commented_placeholder(mapping, "Multiple categories have NA values"))

    return sql_statements

