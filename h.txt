import os
import base64
import json
from pathlib import Path
from openai import AzureOpenAI
from PIL import Image
import io

# Azure OpenAI Configuration
client = AzureOpenAI(
    azure_endpoint=os.environ.get("AZURE_OPENAI_ENDPOINT", "https://YOUR_RESOURCE_NAME.openai.azure.com/"),
    api_key=os.environ.get("AZURE_OPENAI_API_KEY", "YOUR_API_KEY"),
    api_version="2024-02-15-preview"  # Ensure this supports vision
)

# Deployment Configuration
DEPLOYMENT_NAME = "gpt-4o"  # Your specific GPT-4o deployment name

def encode_image_to_base64(image_path):
    """
    Encode an image to base64 with size optimization.
    Resize large images to reduce token usage.
    """
    with Image.open(image_path) as img:
        # Resize if image is too large
        max_size = (1024, 1024)
        img.thumbnail(max_size, Image.LANCZOS)
        
        # Save to a bytes buffer
        buffered = io.BytesIO()
        img.save(buffered, format="PNG")
        return base64.b64encode(buffered.getvalue()).decode('utf-8')

def classify_document(image_path):
    """
    Classify a document using Azure OpenAI GPT-4o vision model
    """
    try:
        # Encode the image
        base64_image = encode_image_to_base64(image_path)

        # Prepare messages for classification
        messages = [
            {
                "role": "system",
                "content": "You are an expert document classifier. Analyze the document image and classify it precisely."
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "Classify this document. Provide the classification in JSON format with these keys: 'type' (document type), 'confidence' (0-100%), and 'reasoning' (brief explanation)."
                    },
                    {
                        "type": "image",
                        "image": {
                            "base64": base64_image
                        }
                    }
                ]
            }
        ]

        # Call Azure OpenAI with vision input
        response = client.chat.completions.create(
            model=DEPLOYMENT_NAME,
            messages=messages,
            max_tokens=300,
            temperature=0.1
        )

        # Extract and parse the response
        response_text = response.choices[0].message.content.strip()
        
        # Attempt to parse JSON response
        try:
            classification = json.loads(response_text)
            return classification
        except json.JSONDecodeError:
            # Fallback if JSON parsing fails
            return {
                "type": "unclassified",
                "confidence": 50,
                "reasoning": "Unable to parse classification JSON"
            }

    except Exception as e:
        print(f"Classification error: {e}")
        return {
            "type": "error",
            "confidence": 0,
            "reasoning": str(e)
        }

def main():
    # Input and output directories
    input_dir = "input_images"
    output_dir = "classification_results"
    
    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)

    # Process all images in input directory
    for filename in os.listdir(input_dir):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
            image_path = os.path.join(input_dir, filename)
            
            print(f"Processing {filename}...")
            result = classify_document(image_path)
            
            # Save classification result
            result_path = os.path.join(output_dir, f"{Path(filename).stem}_classification.json")
            with open(result_path, 'w') as f:
                json.dump(result, f, indent=2)
            
            # Print result to console
            print(f"Classification for {filename}:")
            print(json.dumps(result, indent=2))
            print("\n")

if __name__ == "__main__":
    main()
