{
    "azure_document_intelligence": {
        "endpoint": "YOUR_DOCUMENT_INTELLIGENCE_ENDPOINT",
        "key": "YOUR_DOCUMENT_INTELLIGENCE_KEY",
        "model_version": "2024-02-15-preview"
    },
    "categories": {
        "cms1500": ["cadwell", "rhymlink"],
        "invoice": ["tesla", "amazon"],
        "scheduling": ["email", "iomrequest"]
    },
    "paths": {
        "reference_dir": "reference",
        "input_dir": "input_docs",
        "output_dir": "output",
        "source_dir": "output/source",
        "classified_dir": "output/classified",
        "unclassified_dir": "output/unclassified"
    },
    "model_training": {
        "min_documents_per_category": 5,
        "max_training_documents": 100,
        "confidence_threshold": 0.7
    },
    "allowed_file_types": [".pdf", ".tiff", ".jpg", ".jpeg", ".png"]
}

-----
 import os
import json
import hashlib
import logging
import traceback
from datetime import datetime
from typing import Dict, Any, List, Optional

from azure.ai.documentintelligence import DocumentIntelligenceClient
from azure.core.credentials import AzureKeyCredential
from azure.core.exceptions import HttpResponseError

# Configure logging
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s: %(message)s',
    filename='document_processing.log',
    filemode='a'
)

class DocumentIntelligenceModelTrainer:
    def __init__(self, config_path: str = 'config.json'):
        """
        Initialize Document Intelligence Model Trainer
        """
        # Load configuration
        with open(config_path, 'r') as f:
            self.cfg = json.load(f)
        
        # Setup logging
        self.logger = logging.getLogger(__name__)
        
        # Initialize Azure client
        self.client = self._initialize_client()
        
        # Ensure directories exist
        self._prepare_directories()

    def _prepare_directories(self):
        """
        Ensure necessary directories exist
        """
        directories = [
            self.cfg['paths']['input_dir'],
            self.cfg['paths']['output_dir'],
            self.cfg['paths']['source_dir'],
            self.cfg['paths']['classified_dir'],
            self.cfg['paths']['unclassified_dir']
        ]
        
        for dir_path in directories:
            os.makedirs(dir_path, exist_ok=True)

    def _initialize_client(self) -> DocumentIntelligenceClient:
        """
        Initialize Azure Document Intelligence Client
        """
        try:
            credential = AzureKeyCredential(self.cfg["azure_document_intelligence"]["key"])
            return DocumentIntelligenceClient(
                endpoint=self.cfg["azure_document_intelligence"]["endpoint"],
                credential=credential
            )
        except Exception as e:
            self.logger.critical(f"Client initialization error: {e}")
            raise

    def classify_document(self, file_path: str) -> Dict[str, Any]:
        """
        Classify document using Document Intelligence
        """
        try:
            # Open document
            with open(file_path, "rb") as doc_file:
                # Use pre-built document model
                poller = self.client.begin_analyze_document(
                    "prebuilt-document",
                    doc_file
                )
                result = poller.result()
            
            # Default classification
            classification = {
                'main_category': 'unknown',
                'subcategory': 'unknown',
                'confidence_score': 0.0
            }
            
            # Process results
            if result.documents and result.documents[0].fields:
                document = result.documents[0]
                
                # Implement classification logic
                for cat, subcats in self.cfg['categories'].items():
                    for subcat in subcats:
                        # Example classification logic
                        if any(subcat in str(field) for field in document.fields.values()):
                            classification['main_category'] = cat
                            classification['subcategory'] = subcat
                            classification['confidence_score'] = document.confidence
                            break
            
            return classification

        except HttpResponseError as http_err:
            self.logger.error(f"HTTP error during classification: {http_err}")
            return {
                'main_category': 'unknown',
                'subcategory': 'unknown',
                'confidence_score': 0.0
            }
        except Exception as e:
            self.logger.error(f"Document classification error: {e}")
            return {
                'main_category': 'unknown',
                'subcategory': 'unknown',
                'confidence_score': 0.0
            }

    def validate_reference_documents(self) -> bool:
        """
        Validate reference document structure and count
        """
        ref_dir = self.cfg['paths']['reference_dir']
        min_docs = self.cfg['model_training']['min_documents_per_category']
        
        try:
            for main_category in os.listdir(ref_dir):
                main_path = os.path.join(ref_dir, main_category)
                if not os.path.isdir(main_path):
                    continue
                
                for subcategory in os.listdir(main_path):
                    subcat_path = os.path.join(main_path, subcategory)
                    if not os.path.isdir(subcat_path):
                        continue
                    
                    # Count documents
                    documents = [
                        f for f in os.listdir(subcat_path)
                        if os.path.isfile(os.path.join(subcat_path, f))
                    ]
                    
                    # Check document count
                    if len(documents) < min_docs:
                        self.logger.warning(
                            f"Insufficient documents in {main_category}/{subcategory}. "
                            f"Found {len(documents)}, minimum required is {min_docs}"
                        )
                        return False
            
            return True
        
        except Exception as e:
            self.logger.error(f"Reference document validation error: {e}")
            return False

---
import os
import shutil
import logging
import fitz
from helper import DocumentIntelligenceModelTrainer

# Configure logging
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s: %(message)s',
    filename='document_processing.log',
    filemode='a'
)

def process_documents(trainer):
    """
    Document processing workflow
    """
    # Validate reference documents
    if not trainer.validate_reference_documents():
        logging.warning("Reference documents do not meet minimum requirements")
        return
    
    # Configuration
    cfg = trainer.cfg
    input_dir = cfg['paths']['input_dir']
    source_dir = cfg['paths']['source_dir']
    classified_dir = cfg['paths']['classified_dir']
    unclassified_dir = cfg['paths']['unclassified_dir']
    
    # Process each document
    for filename in os.listdir(input_dir):
        filepath = os.path.join(input_dir, filename)
        
        # Skip unsupported file types
        if not any(filename.lower().endswith(ext) for ext in cfg['allowed_file_types']):
            logging.warning(f"Unsupported file type: {filename}")
            continue
        
        # Copy to source directory
        source_filepath = os.path.join(source_dir, filename)
        shutil.copy(filepath, source_filepath)
        
        # Classify document
        classification = trainer.classify_document(filepath)
        
        # Determine confidence threshold
        confidence_threshold = cfg['model_training']['confidence_threshold']
        
        # Prepare output
        if classification['confidence_score'] >= confidence_threshold:
            # Classified document
            output_category_dir = os.path.join(
                classified_dir, 
                classification['main_category'], 
                classification['subcategory']
            )
            os.makedirs(output_category_dir, exist_ok=True)
            
            # Save classified document
            output_filepath = os.path.join(output_category_dir, filename)
            shutil.copy(filepath, output_filepath)
        else:
            # Unclassified document
            output_filepath = os.path.join(unclassified_dir, filename)
            shutil.copy(filepath, output_filepath)

def main():
    # Initialize model trainer
    trainer = DocumentIntelligenceModelTrainer()
    
    # Process documents
    process_documents(trainer)

if __name__ == "__main__":
    main()
