def identify_vendor_from_filename(filename):
    """
    Identify vendor name from PDF filename.
    
    Parameters:
    - filename: PDF filename
    
    Returns:
    - Vendor name or "Unknown" if not identifiable
    """
    # List of known vendors
    vendors = ["Cadwell", "Rhythmlink", "Ives", "Neurovision", "Medronics"]
    
    # Check if any vendor name is in the filename
    filename_lower = filename.lower()
    for vendor in vendors:
        if vendor.lower() in filename_lower:
            return vendor
    
    # If no match found, return Unknown
    return "Unknown"

def copy_to_source_documents(blob_service_client, container_name, file_content, filename):
    """
    Copy a file to the SourceDocument folder in the Azure Blob Storage.
    
    Parameters:
    - blob_service_client: Azure Blob Service client
    - container_name: Container name
    - file_content: File content as bytes
    - filename: Original filename
    
    Returns:
    - (success, url) tuple
    """
    try:
        # Generate timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Create blob name with timestamp
        blob_name = f"SourceDocument/{filename}_{timestamp}.pdf"
        
        # Upload blob
        container_client = blob_service_client.get_container_client(container_name)
        blob_client = container_client.get_blob_client(blob_name)
        
        # Set content settings
        content_settings = ContentSettings(content_type="application/pdf")
        
        # Upload file
        blob_client.upload_blob(file_content, overwrite=True, content_settings=content_settings)
        
        return True, blob_client.url
    except Exception as e:
        st.error(f"Error copying to SourceDocument: {str(e)}")
        return False, None

# In the "Upload Results to Azure Blob Storage" section
if st.button("Upload Results to Blob Storage"):
    with st.spinner("Uploading results..."):
        all_pdf_results = st.session_state.all_pdf_results
        timestamp = st.session_state.last_processing_timestamp or datetime.now().strftime("%Y%m%d_%H%M%S")
        
        blob_upload_results = []
        
        for pdf_result in all_pdf_results:
            filename = pdf_result["filename"]
            base_filename = os.path.splitext(filename)[0]
            
            # Determine vendor
            vendor = identify_vendor_from_filename(filename)
            
            # Determine confidence level
            is_high_confidence = has_high_confidence(pdf_result, threshold=95.0)
            confidence_folder = "high_confidence/" if is_high_confidence else "low_confidence/"
            
            # Create the text content with key-value pairs
            page_results_text = create_page_results_text(pdf_result)
            
            # Create timestamp filename
            timestamp_filename = f"{base_filename}_{timestamp}"
            
            # Extract invoice number and total for filename
            invoice_number = "unknown"
            total_amount = "unknown"
            
            # Look through the data to find invoice number and total
            for page in pdf_result["pages"]:
                data = page["data"]
                if not isinstance(data, dict) or "error" in data:
                    continue
                    
                for field, field_data in data.items():
                    if field == "InvoiceNumber":
                        if isinstance(field_data, dict):
                            invoice_number = field_data.get("value", "unknown")
                        else:
                            invoice_number = field_data if field_data else "unknown"
                    elif field == "Total":
                        if isinstance(field_data, dict):
                            total_amount = field_data.get("value", "unknown")
                        else:
                            total_amount = field_data if field_data else "unknown"
            
            # Clean values for filename use
            safe_invoice_number = ''.join(c for c in str(invoice_number) if c.isalnum() or c in '-_.')
            safe_total_amount = ''.join(c for c in str(total_amount) if c.isalnum() or c in '-_.')
            
            # Create folder structure - ProcessedResult/Vendor/confidence_level
            result_folder = f"ProcessedResult/{vendor}/{confidence_folder}"
            
            # Upload text file to blob storage
            text_blob_name = f"{result_folder}{base_filename}_{safe_invoice_number}_{safe_total_amount}_{timestamp}.txt"
            text_success, text_url = upload_to_blob_storage(
                blob_service_client,
                result_upload_container,
                text_blob_name,
                page_results_text,
                "text/plain"
            )
            
            # Upload JSON to blob storage
            json_blob_name = f"{result_folder}{base_filename}_{safe_invoice_number}_{safe_total_amount}_{timestamp}.json"
            pdf_json = json.dumps(pdf_result, ensure_ascii=False, indent=2)
            json_success, json_url = upload_to_blob_storage(
                blob_service_client,
                result_upload_container,
                json_blob_name,
                pdf_json,
                "application/json"
            )
            
            # Create and upload CSV
            try:
                # Create a DataFrame for just this PDF
                pdf_rows = []
                for page in pdf_result["pages"]:
                    page_num = page["page"]
                    data = page["data"]
                    
                    # Skip error pages
                    if "error" in data:
                        continue
                    
                    # Initialize row data
                    row_data = {"Page": page_num}
                    
                    # Process each field
                    for field in ["VendorName", "InvoiceNumber", "InvoiceDate", "CustomerName", 
                                "PurchaseOrder", "StockCode", "UnitPrice", "InvoiceAmount", 
                                "Freight", "Salestax", "Total"]:
                        field_data = data.get(field, {})
                        
                        if isinstance(field_data, dict):
                            value = field_data.get("value", "N/A")
                            confidence = field_data.get("confidence", 0)
                        else:
                            value = field_data if field_data else "N/A"
                            confidence = 0
                        
                        # Add to row data
                        row_data[field] = value
                        row_data[f"{field} Confidence"] = round(confidence * 100, 2)
                    
                    # Add extracted timestamp
                    extraction_timestamp = page.get("extraction_timestamp", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                    row_data["Extraction_Timestamp"] = extraction_timestamp
                    
                    # Add manual edit flag
                    has_manual_edits = False
                    if ('manual_edit_tracking' in st.session_state and 
                        filename in st.session_state.manual_edit_tracking and 
                        str(page_num) in st.session_state.manual_edit_tracking[filename]):
                        has_manual_edits = True
                    
                    row_data["Manual_Edit"] = "Y" if has_manual_edits else "N"
                    
                    # Add completed row to rows
                    pdf_rows.append(row_data)
                
                # Create DataFrame and CSV for this PDF
                if pdf_rows:
                    pdf_df = pd.DataFrame(pdf_rows, dtype=str)
                    pdf_csv = pdf_df.to_csv(index=False)
                    
                    # Upload CSV to blob storage
                    csv_blob_name = f"{result_folder}{base_filename}_{safe_invoice_number}_{safe_total_amount}_{timestamp}.csv"
                    csv_success, csv_url = upload_to_blob_storage(
                        blob_service_client,
                        result_upload_container,
                        csv_blob_name,
                        pdf_csv,
                        "text/csv"
                    )
                else:
                    csv_success, csv_url = False, None
            except Exception as e:
                st.warning(f"Could not create CSV for {filename}: {e}")
                csv_success, csv_url = False, None
            
            # Store results
            blob_upload_results.append({
                "filename": filename,
                "vendor": vendor,
                "confidence": "High" if is_high_confidence else "Low",
                "text_success": text_success,
                "text_url": text_url if text_success else None,
                "json_success": json_success,
                "json_url": json_url if json_success else None,
                "csv_success": csv_success,
                "csv_url": csv_url if csv_success else None
            })
        
        # Display upload results
        st.subheader("Azure Blob Storage Upload Results")
        
        # Create a table to show upload results
        upload_rows = []
        for result in blob_upload_results:
            upload_rows.append({
                "Filename": result["filename"],
                "Vendor": result["vendor"],
                "Confidence": result["confidence"],
                "Text File": "✅ Uploaded" if result["text_success"] else "❌ Failed",
                "JSON File": "✅ Uploaded" if result["json_success"] else "❌ Failed",
                "CSV File": "✅ Uploaded" if result["csv_success"] else "❌ Failed"
            })
        
        upload_df = pd.DataFrame(upload_rows)
        st.dataframe(upload_df, use_container_width=True)

# In the Extract Data mode section, inside the if files_to_process block:
# After the line where you set st.session_state.last_processing_timestamp = timestamp

# For uploaded files
if input_method == "Upload Files":
    # Copy source documents to blob storage
    if blob_service_client:
        st.write("Copying source documents to Azure Blob Storage...")
        copy_results = []
        
        for pdf_file in files_to_process:
            # Get file content
            pdf_content = pdf_file.getvalue()
            filename = pdf_file.name
            
            # Copy to SourceDocument folder
            success, url = copy_to_source_documents(
                blob_service_client,
                selected_container if 'selected_container' in locals() else azure_storage_container_name,
                pdf_content,
                filename
            )
            
            copy_results.append({
                "filename": filename,
                "success": success,
                "url": url
            })
        
        # Show copy results
        st.write("Source document copy results:")
        copy_success = [r for r in copy_results if r["success"]]
        copy_failed = [r for r in copy_results if not r["success"]]
        st.write(f"✅ Successfully copied {len(copy_success)} files")
        if copy_failed:
            st.write(f"❌ Failed to copy {len(copy_failed)} files")

# In the Extract Data mode, inside the Azure Blob Storage processing section,
# after the line where you set files_to_process = pdf_blobs if process_button else None

if files_to_process and blob_service_client:
    # Copy blob files to SourceDocument folder
    st.write("Copying source documents to SourceDocument folder...")
    copy_results = []
    
    for blob_name in files_to_process:
        try:
            # Download the blob
            blob_content = download_blob_to_memory(blob_service_client, selected_container, blob_name)
            if blob_content:
                # Get just the filename
                filename = blob_name.split('/')[-1]
                
                # Copy to SourceDocument folder
                success, url = copy_to_source_documents(
                    blob_service_client,
                    selected_container,
                    blob_content,
                    filename
                )
                
                copy_results.append({
                    "filename": filename,
                    "success": success,
                    "url": url
                })
            else:
                st.warning(f"Could not download blob for copying: {blob_name}")
                copy_results.append({
                    "filename": blob_name.split('/')[-1],
                    "success": False,
                    "url": None
                })
        except Exception as e:
            st.error(f"Error copying blob {blob_name}: {str(e)}")
            copy_results.append({
                "filename": blob_name.split('/')[-1],
                "success": False,
                "url": None
            })
    
    # Show copy results
    st.write("Source document copy results:")
    copy_success = [r for r in copy_results if r["success"]]
    copy_failed = [r for r in copy_results if not r["success"]]
    st.write(f"✅ Successfully copied {len(copy_success)} files")
    if copy_failed:
        st.write(f"❌ Failed to copy {len(copy_failed)} files")
