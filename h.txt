import os
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime

from helper import AzureStorageHelper, PDFProcessor
from llm import AzureOpenAIClient
#main.py
def main():
    parser = argparse.ArgumentParser(description="Process PDF files using Azure OpenAI")
    parser.add_argument("--apitype", choices=["general", "batch"], required=True, 
                      help="API type to use (general or batch)")
    parser.add_argument("--source", choices=["azure", "local"], required=True,
                      help="Source location of PDF files (azure or local)")
    parser.add_argument("--folder", required=True, 
                      help="Folder path (in Azure Blob Storage or local filesystem)")
    parser.add_argument("--config", default="config.json", 
                      help="Path to configuration file")
    
    args = parser.parse_args()
    
    try:
        # Load configuration
        config = load_config(args.config)
        
        # Process PDF files from either Azure or local folder
        if args.source == "azure":
            process_azure_pdf_files(config, args.apitype, args.folder)
        else:  # local
            process_local_pdf_files(config, args.apitype, args.folder)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        return 1
    
    return 0


2. Rename the existing process_pdf_files function to process_azure_pdf_files:
3. Add a new function to process local PDF files:
def process_local_pdf_files(config, api_type, local_folder):
    """
    Process PDF files from a local folder.
    
    Parameters:
    - config: Configuration dictionary
    - api_type: 'batch' or 'general'
    - local_folder: Folder path in local filesystem
    """
    # Initialize helpers
    storage_helper = AzureStorageHelper(
        config["azure_storage"]["connection_string"],
        config["azure_storage"]["input_container"],
        config["azure_storage"]["output_container"]
    )
    
    pdf_processor = PDFProcessor(config)
    
    ai_client = AzureOpenAIClient(config)
    
    # Check if folder exists
    folder_path = Path(local_folder)
    if not folder_path.exists() or not folder_path.is_dir():
        print(f"Folder not found: {local_folder}")
        return
    
    # Find all PDF files in the folder
    pdf_files = list(folder_path.glob("*.pdf"))
    
    if not pdf_files:
        print(f"No PDF files found in folder: {local_folder}")
        return
    
    print(f"Found {len(pdf_files)} PDF files to process")
    
    # Process each PDF
    for i, pdf_file in enumerate(pdf_files):
        try:
            print(f"Processing file {i+1}/{len(pdf_files)}: {pdf_file.name}")
            
            # Read file content
            with open(pdf_file, 'rb') as f:
                file_content = f.read()
            
            # Extract pages as base64 strings
            filename = pdf_file.name
            pages = pdf_processor.extract_pdf_pages(file_content)
            
            if not pages:
                print(f"No pages extracted from {filename}")
                continue
            
            print(f"Extracted {len(pages)} pages from {filename}")
            
            # Prepare batches for processing
            batch_size = config["processing"]["batch_size"]
            
            all_results = []
            for batch_start in range(0, len(pages), batch_size):
                batch_end = min(batch_start + batch_size, len(pages))
                batch_pages = pages[batch_start:batch_end]
                
                # Split into page numbers and base64 strings
                page_nums = [p[0] for p in batch_pages]
                base64_strings = [p[1] for p in batch_pages]
                
                # Create prompts
                prompts = [pdf_processor.create_extraction_prompt() for _ in range(len(batch_pages))]
                
                print(f"Processing batch of {len(batch_pages)} pages (pages {batch_start+1}-{batch_end})")
                
                # Process batch using specified API type
                if api_type == "batch":
                    raw_results = ai_client.process_batch(base64_strings, prompts)
                else:
                    raw_results = ai_client.process_general(base64_strings, prompts)
                
                # Process the results
                processed_results = pdf_processor.process_batch_results(raw_results, page_nums)
                all_results.extend(processed_results)
                
                print(f"Processed batch {batch_start+1}-{batch_end}")
            
            # Create CSV and determine confidence level
            csv_content, invoice_number, total_amount = pdf_processor.create_csv_for_results(
                all_results, filename
            )
            
            if csv_content:
                # Determine confidence level for folder structure
                is_high_confidence = pdf_processor.has_high_confidence(all_results)
                
                # Determine folder path based on confidence
                if is_high_confidence:
                    folder_path = config["azure_storage"]["high_confidence_folder"]
                    print(f"{filename} has HIGH confidence (â‰¥{config['processing']['confidence_threshold']}%)")
                else:
                    folder_path = config["azure_storage"]["low_confidence_folder"]
                    print(f"{filename} has LOW confidence (<{config['processing']['confidence_threshold']}%)")
                
                # Prepare filenames for upload
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                base_filename = os.path.splitext(filename)[0]
                
                # Upload CSV to blob storage
                csv_blob_name = f"{folder_path}{base_filename}_{invoice_number}_{total_amount}_{timestamp}.csv"
                csv_success, csv_url = storage_helper.upload_to_storage(
                    csv_blob_name,
                    csv_content,
                    "text/csv"
                )
                
                # Upload original PDF to appropriate folder
                source_folder = "source_documents/" + folder_path
                source_blob_name = f"{source_folder}{filename}"
                source_success, source_url = storage_helper.upload_to_storage(
                    source_blob_name,
                    file_content,
                    "application/pdf"
                )
                
                print(f"CSV upload: {'Success' if csv_success else 'Failed'}")
                print(f"Source PDF upload: {'Success' if source_success else 'Failed'}")
                
                # Also save the CSV locally if desired
                output_dir = Path("output")
                output_dir.mkdir(exist_ok=True)
                
                confidence_dir = output_dir / ("high_confidence" if is_high_confidence else "low_confidence")
                confidence_dir.mkdir(exist_ok=True)
                
                output_path = confidence_dir / f"{base_filename}_{invoice_number}_{total_amount}_{timestamp}.csv"
                with open(output_path, "w") as f:
                    f.write(csv_content)
                
                print(f"CSV saved locally to: {output_path}")
            else:
                print(f"No extractable content found in {filename}")
        
        except Exception as e:
            print(f"Error processing {pdf_file.name}: {str(e)}")
    
    print("Processing complete!")
