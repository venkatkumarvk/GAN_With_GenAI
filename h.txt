"""
MAIN PIPELINE - COMPLETE AZURE RAG DOCUMENT EXTRACTION
=======================================================

COMPLETE WORKFLOW WITH CONFIDENCE-BASED STORAGE

Example: Provider1 with 20 documents, confidence_threshold=0.50
"""

import os
import json
import logging
from datetime import datetime
from typing import List, Dict, Any
import hashlib

# Import all modules
from helper import (
    ConfigManager,
    AzureBlobManager,
    DocumentIntelligenceManager,
    AzureOpenAIManager,
    AzureAISearchManager
)
# Note: No separate OCR import needed - using DocumentIntelligenceManager from helper
from text_rag import TextRAGExtractor
from multimodal_rag import MultimodalRAGExtractor
from unified_rag import UnifiedRAGExtractor
from costtracking import CostTracker

# Setup logging
os.makedirs('logs', exist_ok=True)
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'logs/extraction_{timestamp}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def generate_document_id(provider: str, document_name: str) -> str:
    """Generate unique document ID using SHA-256"""
    unique_string = f"{provider}_{document_name}_{datetime.utcnow().isoformat()}"
    return hashlib.sha256(unique_string.encode()).hexdigest()


def calculate_min_confidence(results: List[Dict]) -> float:
    """Calculate minimum confidence across ALL fields in ALL documents"""
    all_confidences = []
    
    for doc in results:
        extracted = doc.get('extracted_fields', {})
        for field_name, field_data in extracted.items():
            if isinstance(field_data, dict):
                conf = field_data.get('confidence', 0.0)
                all_confidences.append(float(conf))
    
    return min(all_confidences) if all_confidences else 0.0


def calculate_top_confidence_per_field(results: List[Dict], fields: List[str]) -> float:
    """
    Calculate minimum of the TOP confidences per field.
    For each field, finds the highest confidence across all documents,
    then returns the minimum of those top values.
    
    This is what's shown in the CSV (highest confidence per field).
    """
    field_top_confidences = {}
    
    for field in fields:
        top_conf = 0.0
        for doc in results:
            extracted = doc.get('extracted_fields', {})
            if field in extracted:
                field_data = extracted[field]
                if isinstance(field_data, dict):
                    conf = field_data.get('confidence', 0.0)
                    top_conf = max(top_conf, float(conf))
        field_top_confidences[field] = top_conf
    
    # Return minimum of the top confidences
    return min(field_top_confidences.values()) if field_top_confidences else 0.0


def calculate_avg_confidence(results: List[Dict]) -> float:
    """Calculate average confidence for reporting"""
    all_confidences = []
    
    for doc in results:
        extracted = doc.get('extracted_fields', {})
        for field_name, field_data in extracted.items():
            if isinstance(field_data, dict):
                conf = field_data.get('confidence', 0.0)
                all_confidences.append(float(conf))
    
    return sum(all_confidences) / len(all_confidences) if all_confidences else 0.0


def main():
    """
    MAIN PIPELINE
    
    WORKFLOW EXAMPLE (Provider1 with 20 documents):
    ================================================
    
    1. Load config.json
       - fields: ["name", "nationality"]
       - confidence_threshold: 0.50
       - mode: "text" or "multimodal"
    
    2. List documents from inputcontainer/Provider1/
       - document_001.pdf
       - document_002.pdf
       - ... (20 files total)
    
    3. For EACH document:
       a) OCR extraction → Get text
       b) Generate embeddings → Vector (3072 dims)
       c) Store in Azure AI Search
       d) Extract fields:
          - If mode="text": Use TextRAGExtractor
          - If mode="multimodal": Use MultimodalRAGExtractor
       e) Get extraction:
          {
            "name": {"value": "JOHN DOE", "confidence": 0.95},
            "nationality": {"value": "USA", "confidence": 0.98}
          }
    
    4. After ALL 20 documents processed:
       - Calculate MIN confidence across ALL fields
       - Example: doc1 has 0.95, doc2 has 0.96, doc15 has 0.52
       - MIN = 0.52 (the lowest)
    
    5. Compare MIN confidence to threshold:
       - If MIN >= threshold → highconfidence/
       - If MIN < threshold → lowconfidence/
       
       Example: 0.52 >= 0.50 → highconfidence/ 
    
    6. Save outputs to:
       outputcontainer/highconfidence/provider1_20250219_120000/
       ├── provider1_20250219_120000.csv (1 row with all fields)
       ├── provider1_20250219_120000_detailed.json (20 docs details)
       └── provider1_20250219_120000_costs.json (cost breakdown)
    """
    
    print("="*80)
    print("  AZURE RAG DOCUMENT EXTRACTION PIPELINE")
    print("="*80)
    
    # Load configuration
    cfg = ConfigManager('config.json')
    
    # Extract configuration
    # Load configuration
    blob_config = cfg.get("AzureBlob")
    openai_config = cfg.get("AzureOpenAI")
    embedding_config = cfg.get("AzureEmbedding")
    doc_intel_config = cfg.get("DocumentIntelligence")
    search_config = cfg.get("AzureAISearch")
    
    # Validate required sections exist
    if not blob_config:
        raise ValueError("Missing 'AzureBlob' section in config.json")
    if not openai_config:
        raise ValueError("Missing 'AzureOpenAI' section in config.json")
    if not embedding_config:
        raise ValueError("Missing 'AzureEmbedding' section in config.json")
    if not doc_intel_config:
        raise ValueError("Missing 'DocumentIntelligence' section in config.json")
    if not search_config:
        raise ValueError("Missing 'AzureAISearch' section in config.json")
    
    fields = cfg.get("fields")
    if not fields:
        raise ValueError("Missing 'fields' in config.json")
    
    # Get config values with defaults
    confidence_threshold = cfg.get("confidence_threshold", 0.50)
    min_text_length = cfg.get("min_text_length", 10)
    rag_config = cfg.get("rag", {})
    costs_config = cfg.get("costs", {})
    
    mode = rag_config.get("mode", "text")
    top_k = rag_config.get("top_k", 5)
    similarity_threshold = rag_config.get("similarity_threshold", 0.70)
    
    print(f"\n Configuration loaded")
    print(f"  Mode: {mode}")
    print(f"  Fields: {', '.join(fields)}")
    print(f"  Confidence Threshold: {confidence_threshold} ({int(confidence_threshold*100)}%)")
    print(f"  Min Text Length: {min_text_length} chars (skip shorter documents)")
    print(f"  RAG: top_k={top_k}, similarity={similarity_threshold}")
    
    # Initialize Azure services
    input_container = blob_config['inputcontainer']
    output_container = blob_config['outputcontainer']
    
    blob_manager = AzureBlobManager(
        blob_config['connection_string'],
        input_container,
        output_container
    )
    doc_intel_manager = DocumentIntelligenceManager(
        doc_intel_config['endpoint'],
        doc_intel_config['key']
    )
    openai_manager = AzureOpenAIManager(
        gpt_endpoint=openai_config['endpoint'],
        gpt_api_key=openai_config['api_key'],
        gpt_api_version=openai_config['api_version'],
        gpt_deployment=openai_config['deployment_name'],
        embedding_endpoint=embedding_config['endpoint'],
        embedding_api_key=embedding_config['api_key'],
        embedding_api_version=embedding_config['api_version'],
        embedding_deployment=embedding_config['deployment_name'],
        embedding_dimension=embedding_config['dimension']
    )
    search_manager = AzureAISearchManager(
        search_config['endpoint'],
        search_config['api_key']
    )
    
    print(f" Azure services initialized")
    
    # List providers and their documents using YOUR helper.py methods
    provider_list = blob_manager.get_providers()
    
    if not provider_list:
        print(f"\n No providers found in {input_container}")
        return
    
    # Get documents for each provider
    SUPPORTED_EXTENSIONS = {'.pdf', '.jpg', '.jpeg', '.png', '.doc', '.docx', '.tiff', '.tif', '.bmp'}
    
    providers = {}
    total_docs = 0
    for provider_name in provider_list:
        files = blob_manager.get_provider_files(provider_name)
        if files:
            # Filter for supported file types only
            supported_files = [
                f['name'] for f in files 
                if os.path.splitext(f['name'])[1].lower() in SUPPORTED_EXTENSIONS
            ]
            
            if supported_files:
                providers[provider_name] = supported_files
                total_docs += len(supported_files)
                print(f"  {provider_name}: {len(supported_files)} supported documents")
            else:
                print(f"    {provider_name}: No supported documents (only supports: PDF, JPG, PNG, DOC, DOCX)")
    
    if not providers:
        print(f"\n No supported documents found!")
        print(f"   Supported formats: {', '.join(SUPPORTED_EXTENSIONS)}")
        return
    
    print(f"\n Total: {total_docs} supported documents in {len(providers)} providers")
    print(f"  Providers: {', '.join(providers.keys())}")
    
    # Initialize extractors
    if mode == "text":
        extractor = TextRAGExtractor(
            search_endpoint=search_config['endpoint'],
            search_api_key=search_config['api_key'],
            openai_manager=openai_manager,
            fields=fields,
            top_k=top_k,
            similarity_threshold=similarity_threshold
        )
    else:
        extractor = MultimodalRAGExtractor(
            search_endpoint=search_config['endpoint'],
            search_api_key=search_config['api_key'],
            openai_manager=openai_manager,
            blob_manager=blob_manager,
            fields=fields,
            top_k=top_k,
            similarity_threshold=similarity_threshold
        )
    
    print(f" Extractor initialized: {mode.upper()}")
    
    # Track all providers
    provider_results = []
    
    # Process each provider
    for provider_name, provider_docs in providers.items():
        run_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Sanitize provider name for IDs (remove spaces, special chars)
        provider_name_clean = provider_name.replace(' ', '_').replace('-', '_')
        provider_name_clean = ''.join(c for c in provider_name_clean if c.isalnum() or c == '_')
        
        # Create unique provider ID: providername_timestamp
        provider_id = f"{provider_name_clean}_{run_timestamp}"
        
        print(f"\n{'='*80}")
        print(f"Processing Provider: {provider_name} ({len(provider_docs)} documents)")
        print(f"Provider ID: {provider_id}")
        print(f"Run Timestamp: {run_timestamp}")
        print(f"{'='*80}")
        
        # Create index with timestamp: providername_timestamp_index
        # Example: anand_emp001_20260219_022745_index
        index_name = provider_name.lower().replace(' ', '_').replace('-', '_')
        index_name = ''.join(c for c in index_name if c.isalnum() or c == '_')
        index_name = f"{index_name}_{run_timestamp}_index"
        
        print(f"\n Azure AI Search Index: {index_name}")
        
        # Create index if doesn't exist, reuse if exists
        try:
            search_manager.create_index(index_name, embedding_dimension=embedding_config['dimension'])
            print(f"    Index ready (created or reused)\n")
        except Exception as e:
            if "already exists" in str(e).lower():
                print(f"    Using existing index\n")
            else:
                logger.error(f"Index error: {e}")
                raise
        
        results = []
        skipped_docs = []  # Track skipped documents
        
        # Process each document
        for idx, blob_path in enumerate(provider_docs, 1):
            doc_name = blob_path.split('/')[-1]
            print(f"\n[{idx}/{len(provider_docs)}] {doc_name}")
            
            try:
                # Step 1: Download blob as base64 (YOUR helper.py method)
                base64_data = blob_manager.download_blob_as_base64(blob_path)
                file_extension = os.path.splitext(doc_name)[1]
                
                # OCR with DocumentIntelligenceManager (already has base64)
                ocr_result = doc_intel_manager.analyze_document(base64_data, file_extension)
                
                if not ocr_result.get('success', False):
                    error_msg = ocr_result.get('error', 'Unknown error')
                    print(f"    OCR failed: {error_msg}")
                    logger.error(f"OCR failed for {doc_name}: {error_msg}")
                    continue
                
                # Support both 'text' and 'content' keys (different OCR modules use different keys)
                document_text = ocr_result.get('text') or ocr_result.get('content', '')
                
                if not document_text:
                    print(f"     No text extracted - skipping (likely portrait photo or blank page)")
                    logger.warning(f"No text extracted from {doc_name} - skipped")
                    continue
                
                pages = ocr_result.get('page_count', 1) or ocr_result.get('pages', 1)
                text_length = len(document_text.strip())
                
                print(f"    OCR: {text_length} chars | {pages} page(s) | {file_extension}")
                
                # Smart skip: Ignore photos with minimal text (portraits, blank pages, etc.)
                if text_length < min_text_length:
                    print(f"     Text too short ({text_length} chars < {min_text_length})")
                    print(f"     SKIPPED - Not uploaded to Azure AI Search")
                    logger.info(f"Skipped {doc_name} - insufficient text ({text_length} chars)")
                    skipped_docs.append({
                        'document_name': doc_name,
                        'reason': 'insufficient_text',
                        'text_length': text_length,
                        'min_required': min_text_length
                    })
                    continue
                
                # Document has sufficient text - proceed with processing
                print(f"    Sufficient text detected - proceeding with extraction")
                # Step 2: Generate embeddings
                embedding = openai_manager.generate_embeddings(document_text)
                print(f"    Embedding: {len(embedding)} dims")
                
                # Step 3: Store in search (for future RAG)
                doc_id = generate_document_id(provider_name, doc_name)
                search_manager.upload_document(
                    index_name=index_name,
                    doc_id=doc_id,
                    content=document_text,
                    document_name=doc_name,
                    provider=provider_name,
                    content_vector=embedding,
                    extracted_fields={},
                    page_count=pages
                )
                print(f"     Stored in Azure AI Search")
                
                # Step 4: Extract fields
                if mode == "text":
                    extraction = extractor.extract_with_rag(
                        document_text=document_text,
                        provider=provider_name,
                        source_document=doc_name,
                        index_name=index_name
                    )
                else:
                    extraction = extractor.extract_with_rag(
                        document_text=document_text,
                        provider=provider_name,
                        source_document=doc_name,
                        index_name=index_name,
                        blob_path=blob_path
                    )
                
                if extraction['success']:
                    extracted_fields = extraction['extracted_fields']
                    
                    # Calculate doc confidence
                    confidences = [
                        f.get('confidence', 0.0) 
                        for f in extracted_fields.values() 
                        if isinstance(f, dict)
                    ]
                    doc_conf = sum(confidences) / len(confidences) if confidences else 0.0
                    
                    print(f"    Extracted: {len(extracted_fields)} fields")
                    print(f"    Confidence: {doc_conf:.2f} | RAG: {extraction.get('used_rag', False)}")
                    
                    # Store result
                    results.append({
                        'id': doc_id,
                        'document_name': doc_name,
                        'extracted_fields': extracted_fields,
                        'avg_confidence': doc_conf,
                        'used_rag': extraction.get('used_rag', False),
                        'has_vision': extraction.get('has_vision', False),
                        'system_prompt': extraction.get('system_prompt', ''),
                        'user_prompt': extraction.get('user_prompt', '')
                    })
                    
                    # Update search with extracted fields
                    search_manager.upload_document(
                        index_name=index_name,
                        doc_id=doc_id,
                        content=document_text,
                        document_name=doc_name,
                        provider=provider_name,
                        content_vector=embedding,
                        extracted_fields=json.dumps(extracted_fields),
                        page_count=pages
                    )
                else:
                    print(f"    Extraction failed: {extraction.get('error', 'Unknown')}")
                
            except Exception as e:
                logger.error(f"Error processing {doc_name}: {e}", exc_info=True)
                print(f"    Error: {e}")
                continue
        
        print(f"\n{'='*80}")
        print(f"Processed {len(results)}/{len(provider_docs)} documents")
        print(f"{'='*80}")
        
        if not results:
            print("  No successful extractions, skipping output")
            continue
        
        # Calculate confidences
        min_conf = calculate_min_confidence(results)
        avg_conf = calculate_avg_confidence(results)
        top_conf = calculate_top_confidence_per_field(results, fields)
        
        # Determine category based on TOP confidence per field (what's in CSV)
        # This matches the actual CSV output values
        if top_conf >= confidence_threshold:
            category = "highconfidence"
        else:
            category = "lowconfidence"
        
        # Simple summary
        status = "COMPLETED" if len(results) > 0 else "NO RESULTS"
        print(f"\nProvider: {provider_name}")
        print(f"Status: {status}")
        print(f"Processed: {len(results)}/{len(provider_docs)} documents")
        print(f"Top Confidence (CSV values): {top_conf:.2f}")
        print(f"Category: {category} (threshold: {confidence_threshold:.2f})")
        if len(skipped_docs) > 0:
            print(f"Skipped: {len(skipped_docs)} documents (insufficient text)")
        
        # Save outputs with subfolder structure
        # outputcontainer/highconfidence/provider_id/processedcsvresult/file.csv
        # outputcontainer/highconfidence/provider_id/processedjsonresult/file.json
        # outputcontainer/highconfidence/provider_id/estimatecost/file.json
        output_base_path = f"{category}/{provider_id}"
        csv_folder = f"{output_base_path}/processedcsvresult"
        json_folder = f"{output_base_path}/processedjsonresult"
        cost_folder = f"{output_base_path}/estimatecost"
        
        # Build CSV with YOUR format
        csv_lines = []
        
        # Header: provider_id, provider, extraction_datetime, field, field_confidence, field_source_document
        csv_header = ['provider_id', 'provider', 'extraction_datetime']
        for field in fields:
            csv_header.extend([field, f"{field}_confidence", f"{field}_source_document"])
        csv_lines.append(','.join(csv_header))
        
        # Data row
        extraction_datetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        csv_data = {
            'provider_id': provider_id,
            'provider': provider_name,
            'extraction_datetime': extraction_datetime
        }
        
        # Get HIGHEST CONFIDENCE extraction for each field (not just first!)
        for field in fields:
            best_result = None
            best_confidence = -1
            
            # Find result with highest confidence for this field
            for r in results:
                if field in r['extracted_fields']:
                    fd = r['extracted_fields'][field]
                    if isinstance(fd, dict):
                        conf = fd.get('confidence', 0.0)
                        if conf > best_confidence:
                            best_confidence = conf
                            best_result = {
                                'value': fd.get('value', ''),
                                'confidence': conf,
                                'document': r.get('document_name', '')
                            }
            
            # Use best result (highest confidence)
            if best_result:
                csv_data[field] = best_result['value']
                csv_data[f"{field}_confidence"] = f"{best_result['confidence']:.2f}"
                csv_data[f"{field}_source_document"] = best_result['document']
            else:
                # If field not found in any document
                csv_data[field] = ''
                csv_data[f"{field}_confidence"] = '0.00'
                csv_data[f"{field}_source_document"] = ''
        
        # Build CSV row with proper escaping
        def escape_csv_value(val):
            """Escape CSV value if it contains comma, quote, or newline"""
            val_str = str(val)
            if ',' in val_str or '"' in val_str or '\n' in val_str:
                # Escape quotes and wrap in quotes
                return f'"{val_str.replace('"', '""')}"'
            return val_str
        
        csv_lines.append(','.join(escape_csv_value(csv_data.get(h, '')) for h in csv_header))
        
        # Upload CSV to processedcsvresult folder
        csv_path = f"{csv_folder}/{provider_id}.csv"
        blob_manager.upload_to_blob(
            '\n'.join(csv_lines),
            csv_path,
            'text/csv'
        )
        print(f" CSV saved: {csv_path}")
        
        # Build and upload JSON
        json_output = {
            'provider': provider_name,
            'provider_id': provider_id,
            'timestamp': run_timestamp,
            'total_documents': len(results),
            'min_confidence': min_conf,
            'avg_confidence': avg_conf,
            'confidence_threshold': confidence_threshold,
            'category': category,
            'mode': mode,
            'results': results
        }
        
        # Upload JSON to processedjsonresult folder
        json_path = f"{json_folder}/{provider_id}_detailed.json"
        blob_manager.upload_to_blob(
            json.dumps(json_output, indent=2),
            json_path,
            'application/json'
        )
        print(f" JSON saved: {json_path}")
        
        # Track costs
        cost_tracker = CostTracker(costs_config)
        token_usage = {
            'prompt_tokens': openai_manager.prompt_tokens,
            'completion_tokens': openai_manager.completion_tokens,
            'total_tokens': openai_manager.total_tokens
        }
        
        cost_data = cost_tracker.calculate_provider_costs(
            provider=provider_name,
            provider_id=provider_id,
            total_documents=len(results),
            token_usage=token_usage,
            avg_pages_per_doc=2.0
        )
        
        # Upload costs to estimatecost folder
        cost_path = f"{cost_folder}/{provider_id}_costs.json"
        blob_manager.upload_to_blob(
            json.dumps(cost_data, indent=2),
            cost_path,
            'application/json'
        )
        print(f" Costs saved: {cost_path}")
        print(f"   Total Cost: ${cost_data['costs']['total_estimated']:.4f}")
        
        # Track provider result
        provider_results.append({
            'provider': provider_name,
            'status': 'COMPLETED' if len(results) > 0 else 'NO RESULTS',
            'processed': len(results),
            'total': len(provider_docs),
            'skipped': len(skipped_docs)
        })
    
    # Final summary
    print(f"\n{'='*80}")
    print("FINAL SUMMARY")
    print(f"{'='*80}")
    print(f"Total Providers: {len(provider_results)}")
    
    completed = sum(1 for p in provider_results if p['status'] == 'COMPLETED')
    no_results = sum(1 for p in provider_results if p['status'] == 'NO RESULTS')
    
    print(f"Completed: {completed}")
    print(f"No Results: {no_results}")
    print()
    
    for pr in provider_results:
        print(f"{pr['provider']}: {pr['status']} ({pr['processed']}/{pr['total']} processed)")
    
    print(f"{'='*80}\n")


if __name__ == "__main__":
    main()


----

"""
MULTIMODAL RAG EXTRACTION  
==========================
Vision + Text RAG extraction
Uses GPT-4o Vision to analyze document images + RAG examples
"""

import json
import logging
import base64
from typing import List, Dict, Any, Optional
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential
from prompt_builder import ExtractionPromptBuilder

logger = logging.getLogger(__name__)


class MultimodalRAGExtractor:
    """
    Multimodal RAG extractor
    Uses GPT-4o Vision + OCR text + RAG examples
    Better for poor quality scans
    """
    
    def __init__(
        self,
        search_endpoint: str,
        search_api_key: str,
        openai_manager,
        blob_manager,
        fields: List[str],
        top_k: int = 5,
        similarity_threshold: float = 0.70
    ):
        self.search_endpoint = search_endpoint
        self.search_credential = AzureKeyCredential(search_api_key)
        self.openai_manager = openai_manager
        self.blob_manager = blob_manager
        self.fields = fields
        self.top_k = top_k
        self.similarity_threshold = similarity_threshold
        
        # Initialize prompt builder
        self.prompt_builder = ExtractionPromptBuilder(fields)
        
        logger.info(f"MultimodalRAGExtractor initialized | top_k={top_k}")
    
    def extract_with_rag(
        self,
        document_text: str,
        provider: str,
        source_document: str,
        index_name: str = None,
        blob_path: str = None,
        document_type: Optional[str] = "passport"
    ) -> Dict[str, Any]:
        """
        Extract fields using multimodal RAG
        
        Args:
            document_text: OCR text
            provider: Provider name
            source_document: Document filename
            index_name: Specific index name to use
            blob_path: Path to document in blob storage
            document_type: Document type hint
            
        Returns:
            Extraction result with metadata
        """
        logger.info(f"Multimodal RAG extraction | doc={source_document}")
        
        # Step 1: Get document image
        try:
            image_data = self._get_document_image(blob_path)
            if not image_data:
                logger.warning("Failed to get image, falling back to text-only")
                return self._extract_text_only(
                    document_text, provider, source_document, document_type
                )
        except Exception as e:
            logger.error(f"Image retrieval failed: {e}")
            return self._extract_text_only(
                document_text, provider, source_document, document_type
            )
        
        # Step 2: Generate embedding
        try:
            query_vector = self.openai_manager.generate_embeddings(document_text)
            logger.info(f"Generated embedding | dim={len(query_vector)}")
        except Exception as e:
            logger.error(f"Embedding failed: {e}")
            return self._extract_text_only(
                document_text, provider, source_document, document_type
            )
        
        # Step 3: Search similar documents
        similar_docs = []
        try:
            similar_docs = self._search_similar_documents(
                provider=provider,
                query_vector=query_vector,
                top_k=self.top_k,
                index_name=index_name
            )
            
            # Filter by threshold
            similar_docs = [
                doc for doc in similar_docs
                if doc.get('@search.score', 0) >= self.similarity_threshold
            ]
            
            logger.info(f"Found {len(similar_docs)} similar docs")
            
        except Exception as e:
            logger.warning(f"Search failed: {e}")
            similar_docs = []
        
        # Step 4: Build prompts
        system_prompt = self.prompt_builder.build_system_prompt(
            document_type=document_type
        )
        
        if similar_docs:
            text_prompt = self.prompt_builder.build_extraction_prompt_with_rag(
                document_text=document_text,
                similar_documents=similar_docs,
                top_k=min(len(similar_docs), self.top_k)
            )
            method = "Multimodal RAG"
        else:
            text_prompt = self.prompt_builder.build_extraction_prompt_without_rag(
                document_text=document_text
            )
            method = "Multimodal Standard"
        
        logger.info(f"Using method: {method}")
        
        # Step 5: Extract with GPT-4o Vision
        try:
            result = self._call_vision_api(
                system_prompt=system_prompt,
                text_prompt=text_prompt,
                image_data=image_data,
                source_document=source_document
            )
            
            result['extraction_method'] = method
            result['similar_docs_count'] = len(similar_docs)
            result['used_rag'] = len(similar_docs) > 0
            result['has_vision'] = True
            
            return result
            
        except Exception as e:
            logger.error(f"Vision extraction failed: {e}")
            return {
                'success': False,
                'extracted_fields': {},
                'error': str(e),
                'extraction_method': method
            }
    
    def _get_document_image(self, blob_path: str) -> Optional[str]:
        """Get base64-encoded image from blob storage"""
        try:
            # Download from blob as base64 (YOUR helper.py method)
            base64_image = self.blob_manager.download_blob_as_base64(blob_path)
            
            logger.info(f"Retrieved image | size={len(base64_image)} chars")
            return base64_image
            
        except Exception as e:
            logger.error(f"Failed to get image: {e}")
            return None
    
    def _search_similar_documents(
        self,
        provider: str,
        query_vector: List[float],
        top_k: int,
        index_name: str = None
    ) -> List[Dict[str, Any]]:
        """Search for similar documents"""
        
        # Use provided index_name OR build from provider
        if not index_name:
            index_name = provider.lower().replace(' ', '_').replace('-', '_')
            index_name = ''.join(c for c in index_name if c.isalnum() or c == '_')
            index_name = f"{index_name}_index"
        
        logger.info(f"Searching index: {index_name}")
        
        try:
            search_client = SearchClient(
                endpoint=self.search_endpoint,
                index_name=index_name,
                credential=self.search_credential
            )
            
            results = search_client.search(
                search_text=None,
                vector_queries=[{
                    "kind": "vector",
                    "vector": query_vector,
                    "fields": "content_vector",
                    "k": top_k
                }],
                select=["id", "content", "document_name", "extracted_fields"],
                top=top_k
            )
            
            similar_documents = [dict(result) for result in results]
            logger.info(f"Retrieved {len(similar_documents)} similar documents")
            
            return similar_documents
            
        except Exception as e:
            logger.error(f"Vector search failed: {e}")
            return []
    
    def _call_vision_api(
        self,
        system_prompt: str,
        text_prompt: str,
        image_data: str,
        source_document: str
    ) -> Dict[str, Any]:
        """Call GPT-4o Vision API"""
        
        try:
            # Detect image type from base64 header or file extension
            image_type = "image/jpeg"  # default
            if source_document.lower().endswith('.png'):
                image_type = "image/png"
            elif source_document.lower().endswith('.jpg') or source_document.lower().endswith('.jpeg'):
                image_type = "image/jpeg"
            elif source_document.lower().endswith('.gif'):
                image_type = "image/gif"
            elif source_document.lower().endswith('.webp'):
                image_type = "image/webp"
            
            # Build vision message
            messages = [
                {"role": "system", "content": system_prompt},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": text_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{image_type};base64,{image_data}",
                                "detail": "high"  # Use high detail for better accuracy
                            }
                        }
                    ]
                }
            ]
            
            response = self.openai_manager.gpt_client.chat.completions.create(
                model=self.openai_manager.gpt_deployment,
                messages=messages,
                temperature=0.0,
                max_tokens=2000
            )
            
            # Track tokens
            if hasattr(response, 'usage'):
                self.openai_manager.prompt_tokens += response.usage.prompt_tokens
                self.openai_manager.completion_tokens += response.usage.completion_tokens
                self.openai_manager.total_tokens += response.usage.total_tokens
            
            content = response.choices[0].message.content.strip()
            
            # Clean markdown
            if content.startswith("```"):
                content = content.replace("```json", "").replace("```", "").strip()
            
            # Parse JSON
            data = json.loads(content)
            
            # Normalize format
            normalized_data = {}
            for field_name in data:
                field_value = data[field_name]
                
                if isinstance(field_value, dict) and 'value' in field_value:
                    normalized_data[field_name] = {
                        'value': field_value.get('value', ''),
                        'confidence': float(field_value.get('confidence', 0.0)),
                        'source_document': source_document
                    }
                else:
                    normalized_data[field_name] = {
                        'value': str(field_value) if field_value else '',
                        'confidence': 0.5,
                        'source_document': source_document
                    }
            
            logger.info(f"Extracted {len(normalized_data)} fields with vision")
            
            return {
                'success': True,
                'extracted_fields': normalized_data,
                'raw_response': content,
                'system_prompt': system_prompt,
                'user_prompt': text_prompt
            }
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parse error: {e}")
            return {
                'success': False,
                'extracted_fields': {},
                'error': f"JSON parse error: {e}",
                'raw_response': content[:500] if 'content' in locals() else ''
            }
        except Exception as e:
            logger.error(f"Vision API call failed: {e}")
            return {
                'success': False,
                'extracted_fields': {},
                'error': str(e),
                'raw_response': ''
            }
    
    def _extract_text_only(
        self,
        document_text: str,
        provider: str,
        source_document: str,
        document_type: Optional[str]
    ) -> Dict[str, Any]:
        """Fallback to text-only if vision fails"""
        
        logger.info("Falling back to text-only extraction")
        
        # Use text_rag approach
        from text_rag import TextRAGExtractor
        
        text_extractor = TextRAGExtractor(
            search_endpoint=self.search_endpoint,
            search_api_key=self.search_credential.key,
            openai_manager=self.openai_manager,
            fields=self.fields,
            top_k=self.top_k,
            similarity_threshold=self.similarity_threshold
        )
        
        return text_extractor.extract_with_rag(
            document_text=document_text,
            provider=provider,
            source_document=source_document,
            document_type=document_type
        )
