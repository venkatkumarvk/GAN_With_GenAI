# helper.py
import pandas as pd
import re
import os
import json
from typing import List, Tuple, Dict, Set, Optional
from collections import defaultdict


def load_config_from_file(config_file: str) -> dict:
    """Load configuration from JSON file."""
    try:
        with open(config_file, 'r') as f:
            config = json.load(f)
        print(f"✅ Configuration loaded from: {config_file}")
        return config
    except Exception as e:
        print(f"❌ Error loading config file: {e}")
        return {}


def normalize_categories(categories: List[str]) -> List[str]:
    """Normalize categories by replacing spaces with underscores and converting to uppercase."""
    return [cat.strip().replace(" ", "_").upper() for cat in categories]


class DatabricksSchemaGenerator:
    def __init__(self,
                 excel_file_path: str,
                 output_base_folder: str = "generated_schemas",
                 sheet_name: Optional[str] = None,
                 categories: Optional[List[str]] = None):
        self.excel_file_path = excel_file_path
        self.output_base_folder = output_base_folder
        self.sheet_name = sheet_name
        self.predefined_categories = set(categories) if categories else None
        self.tables_created = 0
        self.categories = set()

    def load_excel_data(self) -> Optional[pd.DataFrame]:
        try:
            excel_file = pd.ExcelFile(self.excel_file_path)
            sheets = excel_file.sheet_names
            print(f"📄 Available sheets: {sheets}")

            sheet = self.sheet_name if self.sheet_name in sheets else sheets[0]
            print(f"🔍 Using sheet: {sheet}")

            df = pd.read_excel(excel_file, sheet_name=sheet)
            print(f"✅ Loaded {df.shape[0]} rows and {df.shape[1]} columns.")
            return df
        except Exception as e:
            print(f"❌ Error loading Excel file: {e}")
            return None

    def map_datatype(self, datatype: str) -> str:
        if pd.isna(datatype):
            return 'VARCHAR(255)'
        dtype = str(datatype).upper().strip()

        if m := re.match(r'VARCHAR2\((\d+)\s*BYTE\)', dtype):
            return f'VARCHAR({m.group(1)})'
        if m := re.match(r'VARCHAR2\((\d+)\)', dtype):
            return f'VARCHAR({m.group(1)})'
        if m := re.match(r'NUMBER\((\d+),\s*(\d+)\)', dtype):
            return f'DECIMAL({m.group(1)},{m.group(2)})'
        if m := re.match(r'NUMBER\((\d+)\)', dtype):
            return 'INT' if int(m.group(1)) <= 10 else 'BIGINT'
        if 'TIMESTAMP' in dtype:
            return 'TIMESTAMP'
        if 'DATE' in dtype:
            return 'DATE'
        if 'CHAR' in dtype:
            return 'VARCHAR(1)'
        if 'CLOB' in dtype:
            return 'STRING'
        if 'BLOB' in dtype:
            return 'BINARY'
        return 'VARCHAR(255)'

    def detect_categories_from_columns(self, df: pd.DataFrame) -> Dict[str, Dict[str, str]]:
        categories = {}
        if self.predefined_categories:
            print(f"🎯 Using predefined categories: {list(self.predefined_categories)}")
            self.categories = self.predefined_categories.copy()

        for col in df.columns:
            col_upper = col.upper()
            if ' - ' in col_upper:
                category_match = col_upper.split(' - ')[0].strip().replace(' ', '_').upper()

                if not self.predefined_categories or category_match in self.predefined_categories:
                    if 'PHYSICAL' in col_upper and 'TABLE' in col_upper:
                        categories.setdefault(category_match, {})['table_col'] = col
                        self.categories.add(category_match)
                    elif 'COLUMN' in col_upper and 'NAME' in col_upper:
                        categories.setdefault(category_match, {})['column_col'] = col
                        self.categories.add(category_match)
                    elif 'DATA' in col_upper and 'TYPE' in col_upper:
                        categories.setdefault(category_match, {})['datatype_col'] = col
                        self.categories.add(category_match)

        print(f"🔍 Final categories to process: {list(self.categories)}")
        print(f"🔍 Category column mapping: {categories}")
        return categories

    def extract_tables_by_physical_name(self, df: pd.DataFrame) -> Dict[str, Dict[str, List[Tuple[str, str]]]]:
        categories_config = self.detect_categories_from_columns(df)
        result = {}
        seen_columns = {}

        for category in self.categories:
            result[category] = defaultdict(list)
            seen_columns[category] = defaultdict(set)

        for _, row in df.iterrows():
            for category in self.categories:
                if category not in categories_config:
                    continue
                config = categories_config[category]
                table_name = row.get(config.get('table_col'))
                column_name = row.get(config.get('column_col'))
                datatype_value = row.get(config.get('datatype_col'))

                if pd.notna(table_name) and pd.notna(column_name):
                    table_name = str(table_name).strip()
                    column_name = str(column_name).strip()
                    if column_name.lower() not in seen_columns[category][table_name]:
                        dtype = self.map_datatype(datatype_value)
                        result[category][table_name].append((column_name, dtype))
                        seen_columns[category][table_name].add(column_name.lower())

        return result

    def create_folder_structure(self):
        folders = list(self.categories) + ["consolidated"]
        if not os.path.exists(self.output_base_folder):
            os.makedirs(self.output_base_folder)
        for folder in folders:
            os.makedirs(os.path.join(self.output_base_folder, folder), exist_ok=True)

    def generate_schema_sql(self, table_name: str, columns: List[Tuple[str, str]], category: str) -> str:
        sql = f"-- {category} - {table_name} Table Schema\n"
        sql += f"CREATE TABLE IF NOT EXISTS external_catalog.EDM_Reporting.{table_name} (\n"
        sql += ",\n".join([f"    [{col}] {dtype}" for col, dtype in columns])
        sql += "\n);"
        return sql

    def generate_category_consolidated_schema(self, category: str, tables: Dict[str, List[Tuple[str, str]]]) -> str:
        consolidated_sql = f"-- {category} CATEGORY - CONSOLIDATED SCHEMA\n\n"
        for table_name, columns in tables.items():
            sql = self.generate_schema_sql(table_name, columns, category)
            consolidated_sql += sql + "\n\n"
        return consolidated_sql

    def generate_master_consolidated_schema(self, tables_by_category: Dict[str, Dict[str, List[Tuple[str, str]]]]) -> str:
        master_sql = "-- MASTER CONSOLIDATED SCHEMA\n\n"
        for category, tables in tables_by_category.items():
            master_sql += f"-- {category} CATEGORY\n\n"
            for table_name, columns in tables.items():
                sql = self.generate_schema_sql(table_name, columns, category)
                master_sql += sql + "\n\n"
        return master_sql

    def run(self):
        df = self.load_excel_data()
        if df is None:
            return

        tables_by_category = self.extract_tables_by_physical_name(df)
        self.create_folder_structure()

        total_tables = 0
        for category, tables in tables_by_category.items():
            folder = os.path.join(self.output_base_folder, category)
            for table_name, columns in tables.items():
                sql = self.generate_schema_sql(table_name, columns, category)
                with open(os.path.join(folder, f"{table_name.lower()}.sql"), "w") as f:
                    f.write(sql)
                total_tables += 1

            consolidated = self.generate_category_consolidated_schema(category, tables)
            with open(os.path.join(folder, f"{category.lower()}_consolidated.sql"), "w") as f:
                f.write(consolidated)

        master_sql = self.generate_master_consolidated_schema(tables_by_category)
        with open(os.path.join(self.output_base_folder, "consolidated", "all_tables_master_consolidated.sql"), "w") as f:
            f.write(master_sql)

        self.tables_created = total_tables
        print(f"✅ Completed: {total_tables} tables processed.")

    def get_table_count(self) -> int:
        return self.tables_created

    def get_detected_categories(self) -> Set[str]:
        return self.categories
