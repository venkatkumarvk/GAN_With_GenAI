# insert_helper.py

import os
import json
import pandas as pd
import glob
from typing import List, Dict, Tuple, Optional
from collections import defaultdict

class InsertSQLGenerator:
    def __init__(self,
                 input_folder: str,
                 output_folder: str = "generated_inserts",
                 categories: Optional[Dict[str, Dict[str, str]]] = None):
        self.input_folder = input_folder
        self.output_folder = output_folder
        self.categories = categories or {}
        self.category_keys = list(self.categories.keys())  # preserve order

    def get_excel_files(self) -> List[str]:
        """Get all Excel files from the input folder"""
        excel_patterns = ['*.xlsx', '*.xls', '*.xlsm']
        excel_files = []
        for pattern in excel_patterns:
            excel_files.extend(glob.glob(os.path.join(self.input_folder, pattern)))
        return excel_files

    def load_all_sheets(self, file_path: str) -> pd.DataFrame:
        """Load and combine all sheets from Excel file"""
        try:
            xls = pd.ExcelFile(file_path)
            all_sheets = []
            for sheet in xls.sheet_names:
                try:
                    df = pd.read_excel(file_path, sheet_name=sheet)
                    df.columns = df.columns.str.strip()
                    # Forward fill schema/table/column values for merged cells
                    for cfg in self.categories.values():
                        for col_key in ['schema_col', 'table_col', 'column_col']:
                            col = cfg.get(col_key)
                            if col in df.columns:
                                df[col] = df[col].ffill()
                    all_sheets.append(df)
                except Exception as e:
                    print(f"‚ö†Ô∏è Error reading sheet {sheet} in {os.path.basename(file_path)}: {e}")
            if all_sheets:
                return pd.concat(all_sheets, ignore_index=True)
            else:
                return pd.DataFrame()
        except Exception as e:
            print(f"‚ùå Error loading {file_path}: {str(e)}")
            return pd.DataFrame()

    def determine_flow_direction(self, row_mappings: Dict) -> List[Tuple[str, str]]:
        """Determine flow between categories"""
        valid_categories = [c for c, i in row_mappings.items() if not i.get('has_na', False)]
        flows = []

        # Original forward flow
        original_flow = [(self.category_keys[i], self.category_keys[i+1])
                         for i in range(len(self.category_keys)-1)]
        for src, tgt in original_flow:
            flows.append((src, tgt))

        # Reverse flows if missing
        if 'EDL' not in valid_categories and 'Original_SSR' in valid_categories and 'RDMOF' in valid_categories:
            flows.append(('RDMOF', 'Original_SSR'))
        if 'RDMOF' not in valid_categories and 'Original_SSR' in valid_categories and 'EDL' in valid_categories:
            flows.append(('EDL', 'Original_SSR'))
        return flows

    def create_table_column_pairs(self, df: pd.DataFrame) -> List[Dict]:
        """Create row mappings"""
        pairs = []
        seen = set()
        valid_rows = df.dropna(how='all')
        for _, row in valid_rows.iterrows():
            row_mappings = {}
            for cat in self.category_keys:
                cfg = self.categories[cat]
                schema = str(row.get(cfg['schema_col'], 'NA')).strip()
                table = str(row.get(cfg['table_col'], 'NA')).strip()
                column = str(row.get(cfg['column_col'], 'NA')).strip()
                table_comment = str(row.get(cfg.get('table_comment_col', ''), '')).strip()
                column_comment = str(row.get(cfg.get('column_comment_col', ''), '')).strip()

                if schema in ['nan', 'None']: schema = 'NA'
                if table in ['nan', 'None']: table = 'NA'
                if column in ['nan', 'None']: column = 'NA'

                row_mappings[cat] = {
                    "table": (schema, table),
                    "column": column,
                    "table_comment": table_comment,
                    "column_comment": column_comment,
                    "has_na": schema == "NA" or table == "NA" or column == "NA"
                }
            row_mappings["flows"] = self.determine_flow_direction(row_mappings)
            sig = tuple((cat, d["table"], d["column"]) for cat, d in row_mappings.items() if cat != "flows")
            if sig not in seen:
                seen.add(sig)
                pairs.append(row_mappings)
        return pairs

    def generate_insert_sql(self, src, src_col, tgt, tgt_col,
                            src_has_na=False, tgt_has_na=False,
                            src_table_comment="", src_col_comment="",
                            tgt_table_comment="", tgt_col_comment="") -> str:
        """Generate SQL with comments and NA handling"""
        src_schema, src_tab = src
        tgt_schema, tgt_tab = tgt
        comments = []
        if src_table_comment: comments.append(f"Source table: {src_table_comment}")
        if src_col_comment: comments.append(f"Source column: {src_col_comment}")
        if tgt_table_comment: comments.append(f"Target table: {tgt_table_comment}")
        if tgt_col_comment: comments.append(f"Target column: {tgt_col_comment}")
        comment_text = "\n".join([f"-- {c}" for c in comments]) + ("\n" if comments else "")

        if src_has_na and tgt_has_na:
            return f"-- Both source and target NA\n{comment_text}-- INSERT skipped\n"
        elif src_has_na:
            return f"-- Source NA ‚Üí inserting NULL\n{comment_text}INSERT INTO {tgt_schema}.{tgt_tab} ({tgt_col}) SELECT NULL;\n"
        elif tgt_has_na:
            return f"-- Target NA ‚Üí skipped\n{comment_text}-- INSERT INTO {tgt_schema}.{tgt_tab} ({tgt_col}) SELECT DISTINCT {src_col} FROM {src_schema}.{src_tab};\n"
        else:
            return f"{comment_text}INSERT INTO {tgt_schema}.{tgt_tab} ({tgt_col}) SELECT DISTINCT {src_col} FROM {src_schema}.{src_tab};\n"

    def process_single_file(self, file_path: str) -> List[str]:
        """Process one Excel file"""
        df = self.load_all_sheets(file_path)
        if df.empty:
            return []
        pairs = self.create_table_column_pairs(df)
        statements = []
        for pair in pairs:
            for src_cat, tgt_cat in pair["flows"]:
                if src_cat in pair and tgt_cat in pair:
                    src, tgt = pair[src_cat], pair[tgt_cat]
                    stmt = self.generate_insert_sql(
                        src["table"], src["column"],
                        tgt["table"], tgt["column"],
                        src["has_na"], tgt["has_na"],
                        src.get("table_comment",""), src.get("column_comment",""),
                        tgt.get("table_comment",""), tgt.get("column_comment","")
                    )
                    statements.append(stmt)
        return statements

    def run(self):
        """Generate one SQL file per Excel file"""
        excel_files = self.get_excel_files()
        if not excel_files:
            print("‚ùå No Excel files found")
            return
        os.makedirs(self.output_folder, exist_ok=True)

        for file in excel_files:
            sql_statements = self.process_single_file(file)
            if sql_statements:
                out_file = os.path.splitext(os.path.basename(file))[0] + ".sql"
                out_path = os.path.join(self.output_folder, out_file)
                with open(out_path, "w", encoding="utf-8") as f:
                    f.write(f"-- Generated from {os.path.basename(file)}\n")
                    f.write("\n".join(sql_statements))
                print(f"‚úÖ File generated: {out_file} with {len(sql_statements)} statements")
            else:
                print(f"‚ö†Ô∏è No valid mappings in {os.path.basename(file)}")


----
import json
from insert_helper import InsertSQLGenerator

def main():
    try:
        with open("schema_config.json", "r") as f:
            config = json.load(f)

        print("üöÄ Starting INSERT SQL Generation...")
        generator = InsertSQLGenerator(
            input_folder=config["input_folder"],
            output_folder=config.get("output_folder", "generated_inserts"),
            categories=config["categories"]
        )
        generator.run()

    except FileNotFoundError:
        print("‚ùå schema_config.json not found")
    except KeyError as e:
        print(f"‚ùå Missing config key: {e}")
    except Exception as e:
        print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    main()

