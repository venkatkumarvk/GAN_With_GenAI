import logging
import json
from typing import Dict, Any

class AzureOpenAICostTracker:
    def __init__(self, pricing_config: Dict[str, float]):
        """
        Initialize cost tracker with pricing configuration
        
        :param pricing_config: Dictionary with pricing details
        Example:
        {
            'gpt4o': {
                'input_price_per_1m_tokens': 2.50,
                'output_price_per_1m_tokens': 10.00,
                'cached_input_price_per_1m_tokens': 1.25
            }
        }
        """
        self.pricing_config = pricing_config
        self.total_cost = 0.0
        self.model_usage = {}
        self.log_file = 'azure_openai_cost_log.json'

    def calculate_cost(self, 
                       model_name: str, 
                       input_tokens: int, 
                       output_tokens: int, 
                       is_cached_input: bool = False) -> float:
        """
        Calculate cost for a specific API call
        
        :param model_name: Name of the Azure OpenAI model
        :param input_tokens: Number of input tokens
        :param output_tokens: Number of output tokens
        :param is_cached_input: Whether input tokens are from cached context
        :return: Total cost for the API call
        """
        try:
            model_pricing = self.pricing_config.get(model_name, {})
            
            # Determine input token price based on caching
            input_price_per_1m = (model_pricing.get('cached_input_price_per_1m_tokens', 0) 
                                  if is_cached_input 
                                  else model_pricing.get('input_price_per_1m_tokens', 0))
            
            output_price_per_1m = model_pricing.get('output_price_per_1m_tokens', 0)
            
            # Calculate costs
            input_cost = (input_tokens / 1_000_000) * input_price_per_1m
            output_cost = (output_tokens / 1_000_000) * output_price_per_1m
            
            total_call_cost = input_cost + output_cost
            
            # Update tracking
            self.total_cost += total_call_cost
            
            if model_name not in self.model_usage:
                self.model_usage[model_name] = {
                    'total_cost': 0.0,
                    'input_tokens': 0,
                    'output_tokens': 0,
                    'calls': 0
                }
            
            self.model_usage[model_name]['total_cost'] += total_call_cost
            self.model_usage[model_name]['input_tokens'] += input_tokens
            self.model_usage[model_name]['output_tokens'] += output_tokens
            self.model_usage[model_name]['calls'] += 1
            
            # Log the usage
            self._log_usage(model_name, input_tokens, output_tokens, total_call_cost, is_cached_input)
            
            return total_call_cost
        
        except Exception as e:
            logging.error(f"Cost calculation error: {e}")
            return 0.0

    def _log_usage(self, model_name, input_tokens, output_tokens, call_cost, is_cached_input):
        """
        Log detailed usage information
        """
        try:
            with open(self.log_file, 'a') as f:
                log_entry = {
                    'timestamp': datetime.now().isoformat(),
                    'model': model_name,
                    'input_tokens': input_tokens,
                    'output_tokens': output_tokens,
                    'is_cached_input': is_cached_input,
                    'call_cost': call_cost
                }
                f.write(json.dumps(log_entry) + '\n')
        except Exception as e:
            logging.error(f"Usage logging error: {e}")

    def get_total_cost(self) -> float:
        """
        Get total accumulated cost
        """
        return self.total_cost

    def get_model_usage(self) -> Dict[str, Any]:
        """
        Get detailed usage for all models
        """
        return self.model_usage

    def reset(self):
        """
        Reset all tracking metrics
        """
        self.total_cost = 0.0
        self.model_usage = {}


          -------------

          import os
import json
import hashlib
import logging
import shutil
from openai import AzureOpenAI
from azure_cost_tracker import AzureOpenAICostTracker
from datetime import datetime

# Configure logging
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s: %(message)s',
    filename='document_processing.log',
    filemode='w'
)

def verify_azure_configuration(cfg):
    """
    Comprehensive Azure OpenAI configuration validation
    """
    # Check API Key
    if not cfg['azure_openai']['api_key'] or cfg['azure_openai']['api_key'] == 'YOUR_AZURE_OPENAI_KEY':
        raise ValueError("‚ùå Invalid Azure OpenAI API Key. Replace with your actual key.")
    
    # Check Endpoint
    if not cfg['azure_openai']['endpoint'] or 'openai.azure.com' not in cfg['azure_openai']['endpoint']:
        raise ValueError("‚ùå Invalid Azure OpenAI Endpoint")
    
    # Check Deployment Name
    if not cfg['azure_openai']['deployment_name']:
        raise ValueError("‚ùå Missing Deployment Name")
    
    # Check API Version
    supported_versions = ['2024-05-01-preview', '2024-02-15-preview']
    if cfg['azure_openai']['api_version'] not in supported_versions:
        raise ValueError(f"‚ùå Unsupported API Version. Use one of {supported_versions}")

def load_config(config_path="config.json"):
    """
    Load configuration from JSON file
    """
    try:
        with open(config_path, "r") as f:
            cfg = json.load(f)
        
        # Verify configuration
        verify_azure_configuration(cfg)
        
        # Default pricing configuration if not provided
        if 'pricing' not in cfg:
            cfg['pricing'] = {
                'gpt4o': {
                    'input_price_per_1m_tokens': 2.50,
                    'output_price_per_1m_tokens': 10.00,
                    'cached_input_price_per_1m_tokens': 1.25
                }
            }
        
        return cfg
    except FileNotFoundError:
        logging.error(f"Config file not found: {config_path}")
        raise
    except json.JSONDecodeError:
        logging.error(f"Invalid JSON in config file: {config_path}")
        raise

def compute_reference_hash(ref_dir):
    """
    Compute a comprehensive hash of reference directory contents
    """
    hasher = hashlib.sha256()
    
    # Ensure consistent sorting and hashing
    for root, _, files in sorted(os.walk(ref_dir)):
        for f in sorted(files):
            path = os.path.join(root, f)
            
            # Include file path, modification time, and content
            hasher.update(path.encode())
            hasher.update(str(os.path.getmtime(path)).encode())
            
            try:
                with open(path, 'rb') as file:
                    hasher.update(file.read())
            except Exception as e:
                logging.warning(f"Could not read file {path} for hashing: {e}")
    
    return hasher.hexdigest()

def prepare_reference_metadata(ref_dir):
    """
    Generate a structured metadata of reference documents
    """
    reference_metadata = {}
    
    for main_category in os.listdir(ref_dir):
        main_path = os.path.join(ref_dir, main_category)
        if not os.path.isdir(main_path):
            continue
        
        reference_metadata[main_category] = {}
        
        for subcategory in os.listdir(main_path):
            subcat_path = os.path.join(main_path, subcategory)
            if not os.path.isdir(subcat_path):
                continue
            
            # Count documents in each subcategory
            doc_count = len([f for f in os.listdir(subcat_path) 
                             if os.path.isfile(os.path.join(subcat_path, f))])
            
            reference_metadata[main_category][subcategory] = {
                'document_count': doc_count,
                'documents': [f for f in os.listdir(subcat_path) 
                              if os.path.isfile(os.path.join(subcat_path, f))]
            }
    
    return reference_metadata

def fine_tune_if_new_reference(cfg):
    """
    Check if reference data has changed and log details
    """
    ref_dir = cfg["paths"]["reference_dir"]
    hash_file = os.path.join(ref_dir, ".reference_hash")
    
    try:
        # Compute current reference hash
        hash_now = compute_reference_hash(ref_dir)
        
        # Check if hash file exists
        if os.path.exists(hash_file):
            with open(hash_file, 'r') as f:
                last_hash = f.read().strip()
        else:
            last_hash = ''
        
        # Compare hashes
        if hash_now != last_hash:
            # Log detailed changes
            current_metadata = prepare_reference_metadata(ref_dir)
            
            logging.info("üöÄ New Reference Data Detected")
            logging.info("Reference Document Metadata:")
            logging.info(json.dumps(current_metadata, indent=2))
            
            # Save new hash
            with open(hash_file, 'w') as f:
                f.write(hash_now)
            
            return True
        
        return False
    
    except Exception as e:
        logging.error(f"Reference check error: {e}")
        return False

def get_azure_client(cfg):
    """
    Initialize Azure OpenAI client with error handling
    """
    try:
        # Initialize cost tracker
        cost_tracker = AzureOpenAICostTracker(cfg.get('pricing', {}))
        
        client = AzureOpenAI(
            api_key=cfg["azure_openai"]["api_key"],
            api_version=cfg["azure_openai"]["api_version"],
            azure_endpoint=cfg["azure_openai"]["endpoint"]
        )
        return client, cfg["azure_openai"]["deployment_name"], cost_tracker
    except Exception as e:
        logging.critical(f"Azure client initialization error: {e}")
        raise

def prepare_directories(cfg):
    """
    Prepare necessary directories for processing
    """
    # Ensure input, output, and reference directories exist
    directories = [
        cfg['paths']['input_dir'],
        cfg['paths']['output_dir'],
        cfg['paths']['reference_dir'],
        os.path.join(cfg['paths']['output_dir'], 'source'),
        os.path.join(cfg['paths']['output_dir'], 'classified'),
        os.path.join(cfg['paths']['output_dir'], 'unclassified')
    ]
    
    for dir_path in directories:
        os.makedirs(dir_path, exist_ok=True)


          ------
          '
          import os
import io
import json
import base64
import shutil
import logging
import traceback
import fitz  # PyMuPDF
from PIL import Image
from datetime import datetime

from helper import (
    load_config, 
    fine_tune_if_new_reference, 
    get_azure_client, 
    prepare_directories,
    prepare_reference_metadata
)

# Configure logging
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s: %(message)s',
    filename='document_processing.log',
    filemode='a'  # Append mode to keep historical logs
)

# [All previous functions remain the same]

def classify_page(document_image, client, deployment_name, cfg, cost_tracker):
    """
    Enhanced page-level classification with reference-based validation and token tracking
    """
    try:
        # [Previous preprocessing steps remain the same]

        # Make API call with token tracking
        try:
            response = client.chat.completions.create(
                model=deployment_name,
                messages=[
                    {
                        "role": "system",
                        "content": prompt
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "Please classify this document image based on reference documents."
                            },
                            {
                                "type": "image",
                                "image_base64": base64_image
                            }
                        ]
                    }
                ],
                response_format={"type": "json_object"},
                max_tokens=300  # Limit response length
            )

            # Track token usage and calculate cost
            input_tokens = response.usage.prompt_tokens
            output_tokens = response.usage.completion_tokens
            
            # Assuming GPT-4o model and no caching for first request
            call_cost = cost_tracker.calculate_cost(
                model_name='gpt4o', 
                input_tokens=input_tokens, 
                output_tokens=output_tokens,
                is_cached_input=False
            )

            logging.info(f"API Call Cost Breakdown:\n"
                         f"Input Tokens: {input_tokens}\n"
                         f"Output Tokens: {output_tokens}\n"
                         f"Total Call Cost: ${call_cost:.4f}")

            # [Rest of the classification logic remains the same]

        except Exception as api_error:
            logging.error(f"API Classification Error: {api_error}")
            logging.error(traceback.format_exc())
            
            return 'unknown', 'unknown', 0.0, f"Classification error: {str(api_error)}"

    except Exception as e:
        logging.error(f"Page classification error: {e}")
        logging.error(traceback.format_exc())
        
        return 'unknown', 'unknown', 0.0, f"Error in page classification: {str(e)}"

def process_documents():
    """
    Page-level document classification with token and cost tracking
    """
    try:
        # Load configuration
        cfg = load_config()
        
        # Verify reference documents exist
        reference_dir = cfg['paths']['reference_dir']
        if not os.path.exists(reference_dir) or not os.listdir(reference_dir):
            logging.critical("No reference documents found. Classification cannot proceed.")
            print("‚ùå No reference documents found. Please add reference documents.")
            return

        # Prepare directories
        prepare_directories(cfg)
        
        # Check for reference changes
        fine_tune_if_new_reference(cfg)
        
        # Initialize Azure client with cost tracking
        client, deployment, cost_tracker = get_azure_client(cfg)
        
        # [Rest of the processing logic remains largely the same]

        # Add total processing cost logging at the end
        logging.info("\n--- Processing Session Cost Summary ---")
        logging.info(json.dumps({
            'total_processing_cost': cost_tracker.get_total_cost(),
            'model_usage_details': cost_tracker.get_model_usage()
        }, indent=2))

        print(f"\n‚úÖ Page-Level Document Processing Complete")
        print(f"   Total Processing Cost: ${cost_tracker.get_total_cost():.4f}")

    except Exception as overall_error:
        logging.critical(f"Critical processing error: {overall_error}")
        logging.critical(traceback.format_exc())
        print("‚ùå Document Processing Failed. Check logs for details.")

if __name__ == "__main__":
    process_documents()
