import os
import glob
import pandas as pd

class InsertSQLGenerator:
    def __init__(self, config=None):
        self.config = config or {}

    def load_all_sheets(self, file_path):
        """Load all sheets in Excel and concatenate non-empty sheets that contain 'Category'."""
        try:
            xls = pd.ExcelFile(file_path)
            df_list = []
            for sheet in xls.sheet_names:
                df_sheet = pd.read_excel(xls, sheet_name=sheet)
                if not df_sheet.empty and "Category" in df_sheet.columns:
                    df_list.append(df_sheet)
            if df_list:
                return pd.concat(df_list, ignore_index=True)
            return pd.DataFrame()
        except Exception as e:
            print(f"Error loading Excel {file_path}: {e}")
            return pd.DataFrame()

    def create_row_mappings(self, df):
        """Create a list of dicts containing value + NA status per row."""
        row_maps = []
        for _, row in df.iterrows():
            mapping = {
                "Original_SSR": {"value": row.get("Original_SSR"), "has_na": pd.isna(row.get("Original_SSR"))},
                "EDL": {"value": row.get("EDL"), "has_na": pd.isna(row.get("EDL"))},
                "RDMOF": {"value": row.get("RDMOF"), "has_na": pd.isna(row.get("RDMOF"))},
            }
            row_maps.append(mapping)
        return row_maps

    def build_sql(self, src, dest, description=""):
        """Return SQL string for copying data."""
        return f"-- {description}\nINSERT INTO {dest['value']}_TABLE (COLUMN) SELECT COLUMN FROM {src['value']}_TABLE;"

    def build_commented_placeholder(self, mapping, reason):
        """Return a commented line for skipped rows."""
        return f"-- Skipped: {reason}"

    def generate_sql_for_row(self, mapping, row_number=None):
        """Generate SQL statements based on NA conditions for a single row."""
        edl = mapping.get("EDL", {})
        rdmof = mapping.get("RDMOF", {})
        original = mapping.get("Original_SSR", {})

        edl_na = edl.get("has_na", True)
        rdmof_na = rdmof.get("has_na", True)
        original_na = original.get("has_na", True)

        sql_statements = []
        row_comment = f"-- Row {row_number} mapping: " if row_number is not None else "-- Row mapping: "

        # 1️⃣ All present → Original→EDL + EDL→RDMOF
        if not original_na and not edl_na and not rdmof_na:
            sql_statements.append(f"{row_comment}Original → EDL")
            sql_statements.append(self.build_sql(original, edl, description="Original → EDL"))
            sql_statements.append(f"{row_comment}EDL → RDMOF")
            sql_statements.append(self.build_sql(edl, rdmof, description="EDL → RDMOF"))

        # 2️⃣ Original→RDMOF (EDL NA only)
        elif not original_na and edl_na and not rdmof_na:
            sql_statements.append(f"{row_comment}Original → RDMOF (EDL NA)")
            sql_statements.append(self.build_sql(original, rdmof, description="Original → RDMOF"))

        # 3️⃣ Original→EDL (RDMOF NA only)
        elif not original_na and not edl_na and rdmof_na:
            sql_statements.append(f"{row_comment}Original → EDL (RDMOF NA)")
            sql_statements.append(self.build_sql(original, edl, description="Original → EDL"))

        # 4️⃣ EDL→RDMOF (Original NA only)
        elif original_na and not edl_na and not rdmof_na:
            sql_statements.append(f"{row_comment}EDL → RDMOF (Original NA)")
            sql_statements.append(self.build_sql(edl, rdmof, description="EDL → RDMOF"))

        # 5️⃣ Skip all other partial or invalid combinations
        else:
            sql_statements.append(f"{row_comment}Skipped due to multiple NA values")
            sql_statements.append(self.build_commented_placeholder(mapping, "Multiple categories have NA values"))

        return sql_statements

    def process_file(self, file_path):
        """Process a single Excel file and return unique SQL statements."""
        df = self.load_all_sheets(file_path)
        if df.empty:
            return [], set()

        row_maps = self.create_row_mappings(df)
        all_sql = []
        unique_set = set()

        for idx, row_map in enumerate(row_maps, start=1):
            sql_list = self.generate_sql_for_row(row_map, row_number=idx)
            for sql in sql_list:
                sql_normalized = " ".join(sql.split())
                if sql_normalized not in unique_set:
                    all_sql.append(sql)
                    unique_set.add(sql_normalized)

        return all_sql, unique_set

    def process_folder(self, folder_path, output_folder):
        """Process all Excel files in a folder and write consolidated SQLs."""
        os.makedirs(output_folder, exist_ok=True)
        excel_files = glob.glob(os.path.join(folder_path, "*.xlsx"))

        for file_path in excel_files:
            all_sql, _ = self.process_file(file_path)
            file_name = os.path.splitext(os.path.basename(file_path))[0]
            output_file = os.path.join(output_folder, f"{file_name}_consolidated.sql")

            with open(output_file, "w") as f:
                f.write("\n\n".join(all_sql))
            print(f"Processed {file_path} → {output_file}")


# =======================
# Example usage
# =======================
# config = {}  # Optional configuration dictionary
# generator = InsertSQLGenerator(config)
# generator.process_folder("input_folder_path", "output_folder_path")
