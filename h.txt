import os
import json
import pandas as pd
from typing import List, Dict, Tuple, Optional
from collections import defaultdict


class InsertSQLGenerator:
    def __init__(self,
                 excel_file_path: str,
                 output_folder: str = "generated_inserts",
                 sheet_name: Optional[str] = None,
                 categories: Optional[Dict[str, Dict[str, str]]] = None):
        self.excel_file_path = excel_file_path
        self.output_folder = output_folder
        self.sheet_name = sheet_name
        self.categories = categories or {}
        self.category_keys = list(self.categories.keys())  # preserve order

    def load_excel_data(self) -> pd.DataFrame:
        """Load and clean Excel data from all sheets"""
        try:
            # Load all sheets if no specific sheet_name is provided
            if self.sheet_name is None:
                sheets = pd.read_excel(self.excel_file_path, sheet_name=None)
                df = pd.concat(sheets.values(), ignore_index=True)
            else:
                df = pd.read_excel(self.excel_file_path, sheet_name=self.sheet_name)

            # Clean column names
            df.columns = df.columns.str.strip()

            # Forward fill for schema, table, and column names
            for cfg in self.categories.values():
                for col_key in ['schema_col', 'table_col', 'column_col']:
                    col = cfg.get(col_key)
                    if col and col in df.columns:
                        df[col] = df[col].fillna(method='ffill')

            return df

        except Exception as e:
            print(f"‚ùå Error loading Excel file: {e}")
            return pd.DataFrame()

    def generate_insert_sql(self, src_table: Tuple[str, str], src_col: str,
                            tgt_table: Tuple[str, str], tgt_col: str,
                            src_has_na: bool = False, tgt_has_na: bool = False) -> str:
        src_schema, src_tab = src_table
        tgt_schema, tgt_tab = tgt_table

        if src_has_na and tgt_has_na:
            return (
                f"-- Insert from {src_schema}.{src_tab}.{src_col} to {tgt_schema}.{tgt_tab}.{tgt_col}\n"
                f"-- WARNING: Both source and target have NA values\n"
                f"-- INSERT INTO {tgt_schema}.{tgt_tab} ({tgt_col})\n"
                f"-- SELECT NULL AS {tgt_col};\n"
            )
        elif src_has_na:
            return (
                f"-- Insert from {src_schema}.{src_tab}.{src_col} to {tgt_schema}.{tgt_tab}.{tgt_col}\n"
                f"-- WARNING: Source has NA values\n"
                f"INSERT INTO {tgt_schema}.{tgt_tab} ({tgt_col})\n"
                f"SELECT NULL AS {tgt_col};\n"
            )
        elif tgt_has_na:
            return (
                f"-- Insert from {src_schema}.{src_tab}.{src_col} to {tgt_schema}.{tgt_tab}.{tgt_col}\n"
                f"-- WARNING: Target has NA values\n"
                f"-- INSERT INTO {tgt_schema}.{tgt_tab} ({tgt_col})\n"
                f"-- SELECT DISTINCT {src_col} FROM {src_schema}.{src_tab};\n"
            )
        else:
            return (
                f"-- Insert from {src_schema}.{src_tab}.{src_col} to {tgt_schema}.{tgt_tab}.{tgt_col}\n"
                f"INSERT INTO {tgt_schema}.{tgt_tab} ({tgt_col})\n"
                f"SELECT DISTINCT {src_col} FROM {src_schema}.{src_tab};\n"
            )

    def create_table_column_pairs(self, df: pd.DataFrame) -> List[Dict]:
        """Create ordered row-based mappings between all category columns"""
        pairs = []
        seen = set()

        for _, row in df.iterrows():
            row_map = {}

            for cat in self.category_keys:
                cfg = self.categories[cat]
                schema_val = row.get(cfg['schema_col'])
                table_val = row.get(cfg['table_col'])
                column_val = row.get(cfg['column_col'])

                # Normalize values and check if NA
                def norm(val): return str(val).strip() if pd.notna(val) else 'NA'
                schema = norm(schema_val) or 'NA'
                table = norm(table_val) or 'NA'
                column = norm(column_val) or 'NA'

                has_na = any(x in ['NA', '', 'None', 'nan'] for x in [schema, table, column])

                row_map[cat] = {
                    'table': (schema, table),
                    'column': column,
                    'has_na': has_na
                }

            # Prevent duplicate mappings
            signature = tuple((cat, m['table'], m['column']) for cat, m in row_map.items())
            if signature not in seen:
                pairs.append(row_map)
                seen.add(signature)

        return pairs

    def run(self):
        df = self.load_excel_data()
        if df.empty:
            print("‚ùå No valid Excel data loaded.")
            return

        os.makedirs(self.output_folder, exist_ok=True)

        mappings = self.create_table_column_pairs(df)
        if not mappings:
            print("‚ùå No valid table-column pairs found.")
            return

        all_sql = []
        total_inserted = 0
        total_skipped = 0

        for i in range(len(self.category_keys) - 1):
            src_cat = self.category_keys[i]
            tgt_cat = self.category_keys[i + 1]
            cat_sql = []
            seen_sql = set()

            for mapping in mappings:
                if src_cat not in mapping or tgt_cat not in mapping:
                    continue

                src = mapping[src_cat]
                tgt = mapping[tgt_cat]
                sql = self.generate_insert_sql(src['table'], src['column'],
                                               tgt['table'], tgt['column'],
                                               src['has_na'], tgt['has_na'])
                sql_key = ' '.join(sql.split())
                if sql_key not in seen_sql:
                    cat_sql.append(sql)
                    all_sql.append(sql)
                    seen_sql.add(sql_key)
                    total_inserted += 1
                else:
                    total_skipped += 1

            file_path = os.path.join(self.output_folder, f"{src_cat}_to_{tgt_cat}.sql")
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(f"-- INSERT statements from {src_cat} to {tgt_cat}\n")
                if cat_sql:
                    f.write("\n".join(cat_sql))
                else:
                    f.write("-- No valid mappings found\n")

        # Write combined INSERT file
        combined_file = os.path.join(self.output_folder, "all_insert_statements.sql")
        with open(combined_file, 'w', encoding='utf-8') as f:
            f.write(f"-- Combined INSERT statements for all transitions\n")
            f.write(f"-- Total inserts: {total_inserted}, Skipped: {total_skipped}\n\n")
            f.write("\n".join(all_sql) if all_sql else "-- No INSERTs generated")

        print(f"‚úÖ INSERT generation complete: {total_inserted} statements generated.")
        print(f"üìÅ Output folder: {self.output_folder}")
