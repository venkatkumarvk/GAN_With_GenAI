# insert_helper.py

import os
import pandas as pd
from typing import List, Dict, Tuple, Optional
from collections import defaultdict


class InsertSQLGenerator:
    def __init__(self,
                 excel_file_path: str,
                 output_folder: str = "generated_inserts",
                 categories: Optional[Dict[str, Dict[str, str]]] = None):
        self.excel_file_path = excel_file_path
        self.output_folder = output_folder
        self.categories = categories or {}
        self.category_keys = list(self.categories.keys())

    def load_excel_data(self) -> pd.DataFrame:
        try:
            all_sheets = pd.read_excel(self.excel_file_path, sheet_name=None)
            all_dfs = []

            for sheet_name, df in all_sheets.items():
                df.columns = df.columns.str.strip()
                for cfg in self.categories.values():
                    for col_key in ['schema_col', 'table_col', 'column_col']:
                        col = cfg.get(col_key)
                        if col and col in df.columns:
                            df[col] = df[col].fillna(method='ffill')
                all_dfs.append(df)

            return pd.concat(all_dfs, ignore_index=True)

        except Exception as e:
            print(f"âŒ Error loading Excel file: {e}")
            return pd.DataFrame()

    def generate_insert_sql(self, src_table: Tuple[str, str], src_col: str,
                            tgt_table: Tuple[str, str], tgt_col: str,
                            src_has_na: bool = False, tgt_has_na: bool = False) -> str:

        src_schema, src_tab = src_table
        tgt_schema, tgt_tab = tgt_table

        if src_has_na and tgt_has_na:
            return (
                f"-- Insert from {src_schema}.{src_tab}.{src_col} to {tgt_schema}.{tgt_tab}.{tgt_col}\n"
                f"-- WARNING: Both source and target have NA values\n"
                f"-- INSERT INTO {tgt_schema}.{tgt_tab} ({tgt_col})\n"
                f"-- SELECT NULL AS {tgt_col}; -- Placeholder for NA mapping\n"
            )
        elif src_has_na:
            return (
                f"-- Insert from {src_schema}.{src_tab}.{src_col} to {tgt_schema}.{tgt_tab}.{tgt_col}\n"
                f"-- WARNING: Source has NA values, inserting NULL\n"
                f"INSERT INTO {tgt_schema}.{tgt_tab} ({tgt_col})\n"
                f"SELECT NULL AS {tgt_col}; -- Source mapping is NA\n"
            )
        elif tgt_has_na:
            return (
                f"-- Insert from {src_schema}.{src_tab}.{src_col} to {tgt_schema}.{tgt_tab}.{tgt_col}\n"
                f"-- WARNING: Target has NA values, INSERT commented out\n"
                f"-- INSERT INTO {tgt_schema}.{tgt_tab} ({tgt_col})\n"
                f"-- SELECT DISTINCT {src_col} FROM {src_schema}.{src_tab}; -- Target mapping is NA\n"
            )
        else:
            return (
                f"-- Insert from {src_schema}.{src_tab}.{src_col} to {tgt_schema}.{tgt_tab}.{tgt_col}\n"
                f"INSERT INTO {tgt_schema}.{tgt_tab} ({tgt_col})\n"
                f"SELECT DISTINCT {src_col} FROM {src_schema}.{src_tab};\n"
            )

    def create_table_column_pairs(self, df: pd.DataFrame) -> List[Dict]:
        pairs = []
        seen_mappings = set()
        df = df.dropna(how='all')

        for idx, row in df.iterrows():
            row_mappings = {}
            for cat in self.category_keys:
                cfg = self.categories[cat]
                schema_val = row.get(cfg['schema_col'])
                table_val = row.get(cfg['table_col'])
                column_val = row.get(cfg['column_col'])

                schema = str(schema_val).strip() if pd.notna(schema_val) else 'NA'
                table = str(table_val).strip() if pd.notna(table_val) else 'NA'
                column = str(column_val).strip() if pd.notna(column_val) else 'NA'

                if schema.lower() in ['nan', 'none', '']: schema = 'NA'
                if table.lower() in ['nan', 'none', '']: table = 'NA'
                if column.lower() in ['nan', 'none', '']: column = 'NA'

                row_mappings[cat] = {
                    'table': (schema, table),
                    'column': column,
                    'has_na': schema == 'NA' or table == 'NA' or column == 'NA'
                }

            if len(row_mappings) >= 2:
                mapping_signature = tuple(
                    (cat, info['table'][0], info['table'][1], info['column'])
                    for cat, info in sorted(row_mappings.items())
                )
                if mapping_signature not in seen_mappings:
                    pairs.append(row_mappings)
                    seen_mappings.add(mapping_signature)

        return pairs

    def run(self):
        df = self.load_excel_data()
        os.makedirs(self.output_folder, exist_ok=True)

        table_column_pairs = self.create_table_column_pairs(df)

        if not table_column_pairs:
            print("No valid data found to generate INSERT statements")
            return

        all_insert_sqls = []
        files_generated = []
        total_generated = 0
        total_skipped = 0

        for i in range(len(self.category_keys) - 1):
            cat_src = self.category_keys[i]
            cat_tgt = self.category_keys[i + 1]

            insert_statements = []
            unique_sql_statements = set()
            insert_count = 0
            duplicate_count = 0

            for pair_data in table_column_pairs:
                if cat_src in pair_data and cat_tgt in pair_data:
                    src_info = pair_data[cat_src]
                    tgt_info = pair_data[cat_tgt]

                    sql = self.generate_insert_sql(
                        src_info['table'], src_info['column'],
                        tgt_info['table'], tgt_info['column'],
                        src_info.get('has_na', False),
                        tgt_info.get('has_na', False)
                    )

                    sql_normalized = ' '.join(sql.split())
                    if sql_normalized not in unique_sql_statements:
                        insert_statements.append(sql)
                        all_insert_sqls.append(sql)
                        unique_sql_statements.add(sql_normalized)
                        insert_count += 1
                    else:
                        duplicate_count += 1

            file_name = f"{cat_src}_to_{cat_tgt}.sql"
            file_path = os.path.join(self.output_folder, file_name)

            with open(file_path, "w", encoding='utf-8') as f:
                f.write(f"-- INSERT statements from {cat_src} to {cat_tgt}\n")
                f.write(f"-- Generated {insert_count} unique statements")
                if duplicate_count > 0:
                    f.write(f" (skipped {duplicate_count} duplicates)")
                f.write(f"\n\n")
                f.write("\n".join(insert_statements) if insert_statements else "-- No valid data found\n")

            files_generated.append(file_name)
            total_generated += insert_count
            total_skipped += duplicate_count

        # Write combined file
        combined_file = "all_insert_statements.sql"
        with open(os.path.join(self.output_folder, combined_file), "w", encoding='utf-8') as f:
            f.write(f"-- All INSERT statements combined\n")
            f.write(f"-- Total unique statements: {len(all_insert_sqls)}\n")
            f.write(f"-- Categories: {' â†’ '.join(self.category_keys)}\n\n")
            f.write("\n".join(all_insert_sqls) if all_insert_sqls else "-- No INSERT statements generated\n")

        print(f"âœ… Generated {total_generated} INSERT statements")
        if total_skipped:
            print(f"   Skipped {total_skipped} duplicate statements")
        print(f"ðŸ“‚ Output folder: {self.output_folder}")
