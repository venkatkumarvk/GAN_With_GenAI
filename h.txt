# In the Azure Blob Storage upload section where you create CSV files
# Upload CSV to blob storage
try:
    # Create a DataFrame for just this PDF
    pdf_rows = []
    for page in pdf_result["pages"]:
        page_num = page["page"]
        data = page["data"]
        extraction_timestamp = page.get("extraction_timestamp", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        
        # Check for errors
        if "error" in data:
            row_data = {"Page": page_num, "Extraction_Timestamp": extraction_timestamp}
            for field in ["VendorName", "InvoiceNumber", "InvoiceDate", "CustomerName", 
                        "PurchaseOrder", "StockCode", "UnitPrice", "InvoiceAmount", 
                        "Freight", "Salestax", "Total"]:
                row_data[field] = "N/A"
                row_data[f"{field} Confidence"] = 0
            
            # Add edit tracking columns
            row_data["Manually_Edited_Fields"] = ""
            row_data["Edit_Timestamp"] = ""
            row_data["Original_Values"] = ""
            
            pdf_rows.append(row_data)
            continue
        
        # Initialize row data
        row_data = {"Page": page_num, "Extraction_Timestamp": extraction_timestamp}
        
        # Process each field
        for field in ["VendorName", "InvoiceNumber", "InvoiceDate", "CustomerName", 
                      "PurchaseOrder", "StockCode", "UnitPrice", "InvoiceAmount", 
                      "Freight", "Salestax", "Total"]:
            field_data = data.get(field, {})
            
            if isinstance(field_data, dict):
                value = field_data.get("value", "N/A")
                confidence = field_data.get("confidence", 0)
            else:
                value = field_data if field_data else "N/A"
                confidence = 0
            
            # Add to row data
            row_data[field] = value
            row_data[f"{field} Confidence"] = round(confidence * 100, 2)
        
        # Add edit tracking columns
        edited_fields = []
        edit_timestamps = []
        original_values = []
        
        # Check manual edit tracking info
        if ('manual_edit_tracking' in st.session_state and 
            pdf_result["filename"] in st.session_state.manual_edit_tracking and 
            str(page_num) in st.session_state.manual_edit_tracking[pdf_result["filename"]]):
            
            # Get the edit tracking info for this page
            edit_info = st.session_state.manual_edit_tracking[pdf_result["filename"]][str(page_num)]
            
            for field, info in edit_info.items():
                if info.get("edited", False):
                    edited_fields.append(field)
                    edit_timestamps.append(f"{field}: {info.get('edit_timestamp', 'N/A')}")
                    original_values.append(f"{field}: {info.get('previous_value', 'N/A')}")
        
        row_data["Manually_Edited_Fields"] = ", ".join(edited_fields) if edited_fields else ""
        row_data["Edit_Timestamp"] = "; ".join(edit_timestamps) if edit_timestamps else ""
        row_data["Original_Values"] = "; ".join(original_values) if original_values else ""
        
        # Add completed row to rows
        pdf_rows.append(row_data)
    
    # Create DataFrame and CSV for this PDF
    if pdf_rows:
        pdf_df = pd.DataFrame(pdf_rows, dtype=str)
        pdf_csv = pdf_df.to_csv(index=False)
        
        # Upload CSV to blob storage
        csv_blob_name = f"{timestamp_filename}.csv"
        csv_success, csv_url = upload_to_blob_storage(
            blob_service_client,
            result_upload_container,
            csv_blob_name,
            pdf_csv,
            "text/csv"
        )
    else:
        csv_success, csv_url = False, None
except Exception as e:
    st.warning(f"Could not create CSV for {filename}: {e}")
    csv_success, csv_url = False, None
