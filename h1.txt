import os
import io
import json
import base64
import shutil
import logging
import traceback
import fitz  # PyMuPDF
from PIL import Image
from datetime import datetime

from helper import (
    load_config, 
    fine_tune_if_new_reference, 
    get_azure_client, 
    prepare_directories,
    prepare_reference_metadata
)

# Configure logging
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s: %(message)s',
    filename='document_processing.log',
    filemode='a'  # Append mode to keep historical logs
)

def preprocess_image_for_classification(image_bytes):
    """
    Preprocess image to ensure compatibility with GPT-4o
    """
    try:
        # Open image from bytes
        img = Image.open(io.BytesIO(image_bytes))
        
        # Convert to RGB if needed
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # Resize image
        img = img.resize((800, 600), Image.LANCZOS)
        
        # Compress image
        buffer = io.BytesIO()
        img.save(buffer, format="PNG", optimize=True, quality=85)
        
        # Convert to base64
        base64_image = base64.b64encode(buffer.getvalue()).decode('utf-8')
        
        return base64_image
    
    except Exception as e:
        logging.error(f"Image preprocessing error: {e}")
        return None

def prepare_reference_prompt(cfg, reference_dir):
    """
    Generate a detailed prompt using reference document metadata
    """
    # Collect reference document details
    reference_details = {}
    
    for main_category in os.listdir(reference_dir):
        main_path = os.path.join(reference_dir, main_category)
        if not os.path.isdir(main_path):
            continue
        
        reference_details[main_category] = {}
        
        for subcategory in os.listdir(main_path):
            subcat_path = os.path.join(main_path, subcategory)
            if not os.path.isdir(subcat_path):
                continue
            
            # Count and list reference documents
            reference_docs = [f for f in os.listdir(subcat_path) 
                              if os.path.isfile(os.path.join(subcat_path, f))]
            
            reference_details[main_category][subcategory] = {
                'document_count': len(reference_docs),
                'document_types': list(set(os.path.splitext(doc)[1] for doc in reference_docs))
            }
    
    return reference_details

def extract_page_image(file_path, page_number):
    """
    Extract image for a specific page from various document types
    """
    try:
        # PDF handling
        if file_path.lower().endswith('.pdf'):
            doc = fitz.open(file_path)
            
            # Validate page number
            if page_number < 0 or page_number >= len(doc):
                logging.error(f"Invalid page number {page_number} for {file_path}")
                return _create_blank_image()
            
            page = doc.load_page(page_number)
            pix = page.get_pixmap()
            
            # Validate pixmap
            if not pix or pix.width <= 0 or pix.height <= 0:
                logging.error(f"Invalid page {page_number} in {file_path}")
                return _create_blank_image()
            
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            doc.close()
        
        # Image handling
        elif file_path.lower().endswith(('.jpg', '.jpeg', '.png')):
            img = Image.open(file_path)
        
        else:
            logging.error(f"Unsupported file type: {file_path}")
            return _create_blank_image()
        
        # Resize and convert to bytes
        img = img.resize((800, 600), Image.LANCZOS)
        buf = io.BytesIO()
        img.save(buf, format="PNG")
        return buf.getvalue()
    
    except Exception as e:
        logging.error(f"Error extracting page {page_number} from {file_path}: {e}")
        logging.error(traceback.format_exc())
        return _create_blank_image()

def _create_blank_image():
    """
    Create a blank white image for error cases
    """
    img = Image.new('RGB', (800, 600), color='white')
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    return buf.getvalue()

def classify_page(document_image, client, deployment_name, cfg):
    """
    Enhanced page-level classification with reference-based validation
    """
    try:
        # Validate and preprocess image
        base64_image = preprocess_image_for_classification(document_image)
        
        if not base64_image:
            logging.error("Failed to preprocess image")
            raise ValueError("Image preprocessing failed")

        # Prepare reference details
        reference_dir = cfg['paths']['reference_dir']
        reference_details = prepare_reference_prompt(cfg, reference_dir)

        # Prepare reference categories for prompt
        categories_str = json.dumps(cfg['categories'], indent=2)
        reference_str = json.dumps(reference_details, indent=2)

        # Detailed page classification prompt
        prompt = f"""
        You are an advanced document classifier specializing in precise categorization 
        based on reference document characteristics.

        REFERENCE DOCUMENT OVERVIEW:
        {reference_str}

        CLASSIFICATION GUIDELINES:
        1. Analyze the document page carefully
        2. Compare with available reference documents
        3. Classify ONLY if there is a strong similarity to reference documents
        4. Be extremely strict in classification

        CLASSIFICATION CRITERIA:
        - Require high visual and structural similarity to reference documents
        - Match document layout, content type, and key characteristics
        - If no clear match exists, classify as 'unknown'

        Available Categories:
        {categories_str}

        Provide your classification in this JSON format:
        {{
            "main_category": "exact main category or 'unknown'",
            "subcategory": "exact subcategory or 'unknown'",
            "confidence_score": 0.0-1.0,
            "reasoning": "Detailed explanation of classification decision, emphasizing reference document similarities"
        }}

        CRITICAL INSTRUCTIONS:
        - Only classify if there is SUBSTANTIAL similarity to reference documents
        - Confidence score should reflect the strength of similarity
        - Provide explicit reasoning linking the page to reference documents
        """

        # Make API call with explicit error handling
        try:
            response = client.chat.completions.create(
                model=deployment_name,
                messages=[
                    {
                        "role": "system",
                        "content": prompt
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "Please classify this document image based on reference documents."
                            },
                            {
                                "type": "image",
                                "image_base64": base64_image
                            }
                        ]
                    }
                ],
                response_format={"type": "json_object"},
                max_tokens=300  # Limit response length
            )

            # Extract and parse response
            result = json.loads(response.choices[0].message.content)

            # Extract and validate classification
            main_category = result.get('main_category', 'unknown')
            subcategory = result.get('subcategory', 'unknown')
            confidence_score = float(result.get('confidence_score', 0.0))
            reasoning = result.get('reasoning', 'No reasoning provided')

            # Strict validation against reference documents
            if (main_category == 'unknown' or 
                main_category not in cfg['categories'] or 
                subcategory not in cfg['categories'].get(main_category, [])):
                # Fallback to unknown if no clear match
                main_category = 'unknown'
                subcategory = 'unknown'
                confidence_score = 0.0

            # Log detailed classification
            logging.info(f"Classification Details:\n" + json.dumps({
                'main_category': main_category,
                'subcategory': subcategory,
                'confidence_score': confidence_score,
                'reasoning': reasoning
            }, indent=2))

            return main_category, subcategory, confidence_score, reasoning

        except Exception as api_error:
            logging.error(f"API Classification Error: {api_error}")
            logging.error(traceback.format_exc())
            
            return 'unknown', 'unknown', 0.0, f"Classification error: {str(api_error)}"

    except Exception as e:
        logging.error(f"Page classification error: {e}")
        logging.error(traceback.format_exc())
        
        return 'unknown', 'unknown', 0.0, f"Error in page classification: {str(e)}"

def process_documents():
    """
    Page-level document classification
    """
    try:
        # Load configuration
        cfg = load_config()
        
        # Verify reference documents exist
        reference_dir = cfg['paths']['reference_dir']
        if not os.path.exists(reference_dir) or not os.listdir(reference_dir):
            logging.critical("No reference documents found. Classification cannot proceed.")
            print("❌ No reference documents found. Please add reference documents.")
            return

        # Prepare directories
        prepare_directories(cfg)
        
        # Check for reference changes
        fine_tune_if_new_reference(cfg)
        
        # Initialize Azure client
        client, deployment = get_azure_client(cfg)
        
        # Set up directories
        input_dir = cfg['paths']['input_dir']
        output_dir = cfg['paths']['output_dir']
        source_dir = os.path.join(output_dir, 'source')
        classified_dir = os.path.join(output_dir, 'classified')
        unclassified_dir = os.path.join(output_dir, 'unclassified')
        
        # Ensure directories exist
        os.makedirs(source_dir, exist_ok=True)
        os.makedirs(classified_dir, exist_ok=True)
        os.makedirs(unclassified_dir, exist_ok=True)
        
        # Logging for processing session
        processing_timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.info(f"\n\n--- Processing Session Started: {processing_timestamp} ---")
        
        # Processing statistics
        stats = {
            'total_documents': 0,
            'total_pages': 0,
            'classified_pages': 0,
            'unclassified_pages': 0,
            'page_classification_details': {}
        }

        # Process each document
        for fname in os.listdir(input_dir):
            fpath = os.path.join(input_dir, fname)
            
            # Skip directories and hidden files
            if not os.path.isfile(fpath) or fname.startswith('.'):
                continue

            # Determine file type
            file_type = os.path.splitext(fname)[1].lower()
            
            # Skip non-processable file types
            if file_type not in ['.pdf', '.jpg', '.jpeg', '.png', '.docx']:
                logging.warning(f"Unsupported file type: {fname}")
                continue

            # Count total documents
            stats['total_documents'] += 1

            try:
                # Open PDF to get page count (for PDFs)
                if file_type == '.pdf':
                    doc = fitz.open(fpath)
                    total_pages = len(doc)
                    doc.close()
                else:
                    total_pages = 1  # For non-PDF files

                stats['total_pages'] += total_pages

                # Copy original document to source directory
                shutil.copy(fpath, os.path.join(source_dir, fname))

                # Page-level classification
                classified_pages_by_category = {}
                unclassified_pages = list(range(total_pages))  # Initially all pages are unclassified

                for page_num in range(total_pages):
                    # Extract page image
                    page_image = extract_page_image(fpath, page_num)
                    
                    # Classify page
                    main_cat, sub_cat, confidence, reasoning = classify_page(
                        page_image, 
                        client, 
                        deployment,
                        cfg
                    )

                    # Determine page destination
                    confidence_threshold = cfg['classification'].get('confidence_threshold', 0.5)
                    if confidence >= confidence_threshold:
                        # Organize classified pages by category
                        category_key = f"{main_cat}|{sub_cat}"
                        if category_key not in classified_pages_by_category:
                            classified_pages_by_category[category_key] = []
                        classified_pages_by_category[category_key].append(page_num)
                        
                        # Remove from unclassified pages
                        unclassified_pages.remove(page_num)
                        
                        stats['classified_pages'] += 1
                    
                    # Update page classification details
                    if main_cat not in stats['page_classification_details']:
                        stats['page_classification_details'][main_cat] = {}
                    stats['page_classification_details'][main_cat][sub_cat] = \
                        stats['page_classification_details'][main_cat].get(sub_cat, 0) + 1

                # Process classified pages by category
                for category, pages in classified_pages_by_category.items():
                    main_cat, sub_cat = category.split('|')
                    
                    # Create classified directory
                    cat_dest_dir = os.path.join(classified_dir, main_cat, sub_cat)
                    os.makedirs(cat_dest_dir, exist_ok=True)

                    # Create new PDF with classified pages
                    doc = fitz.open(fpath)
                    output = fitz.open()
                    
                    # Extract specified pages
                    for page_num in pages:
                        output.insert_pdf(doc, from_page=page_num, to_page=page_num)
                    
                    # Generate output filename
                    page_range_str = "_".join(map(str, [p+1 for p in pages]))
                    output_filename = f"{os.path.splitext(fname)[0]}_pages_{page_range_str}.pdf"
                    
                    # Save classified pages PDF
                    output_path = os.path.join(cat_dest_dir, output_filename)
                    output.save(output_path)
                    
                    output.close()
                    doc.close()

                # Handle unclassified pages
                stats['unclassified_pages'] = len(unclassified_pages)
                if unclassified_pages:
                    # Create new PDF with unclassified pages
                    doc = fitz.open(fpath)
                    output = fitz.open()
                    
                    # Extract unclassified pages
                    for page_num in unclassified_pages:
                        output.insert_pdf(doc, from_page=page_num, to_page=page_num)
                    
                    # Generate unclassified filename
                    page_range_str = "_".join(map(str, [p+1 for p in unclassified_pages]))
                    unclassified_filename = f"{os.path.splitext(fname)[0]}_unclassified_pages_{page_range_str}.pdf"
                    
                    # Save unclassified pages PDF
                    unclassified_path = os.path.join(unclassified_dir, unclassified_filename)
                    output.save(unclassified_path)
                    
                    output.close()
                    doc.close()

            except Exception as e:
                logging.error(f"Processing error for {fname}: {e}")
                logging.error(traceback.format_exc())

        # Log comprehensive processing summary
        logging.info("\n--- Processing Session Summary ---")
        logging.info(json.dumps(stats, indent=2))

        print("\n✅ Page-Level Document Processing Complete")

    except Exception as overall_error:
        logging.critical(f"Critical processing error: {overall_error}")
        logging.critical(traceback.format_exc())
        print("❌ Document Processing Failed. Check logs for details.")

if __name__ == "__main__":
    process_documents()
