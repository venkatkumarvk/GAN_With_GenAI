import os
import json
import pandas as pd
from typing import List, Dict, Tuple, Optional
from collections import defaultdict

class InsertSQLGenerator:
    def __init__(self,
                 excel_file_path: str,
                 output_folder: str = "generated_inserts",
                 sheet_name: Optional[str] = None,
                 categories: Optional[Dict[str, Dict[str, str]]] = None,
                 category_order: Optional[List[str]] = None):
        self.excel_file_path = excel_file_path
        self.output_folder = output_folder
        self.sheet_name = sheet_name
        self.categories = categories or {}
        self.category_order = category_order or list(self.categories.keys())

    def load_excel_data(self) -> pd.DataFrame:
        df = pd.read_excel(self.excel_file_path, sheet_name=self.sheet_name)
        df.columns = df.columns.str.strip()
        for cfg in self.categories.values():
            for col_key in ['schema_col', 'table_col', 'column_col']:
                col = cfg.get(col_key)
                if col in df.columns:
                    df[col] = df[col].ffill()
        return df

    def extract_column_mappings(self, df: pd.DataFrame, cat: str) -> Dict[Tuple[str, str], List[str]]:
        cfg = self.categories[cat]
        schema_col = cfg['schema_col']
        table_col = cfg['table_col']
        column_col = cfg['column_col']
        
        result = defaultdict(list)
        filtered_df = df[
            df[schema_col].notna() &
            df[table_col].notna() &
            df[column_col].notna()
        ]

        for _, row in filtered_df.iterrows():
            schema = str(row[schema_col]).strip()
            table = str(row[table_col]).strip()
            column = str(row[column_col]).strip()
            result[(schema, table)].append(column)

        return result

    def generate_insert_sql(self, src_table: Tuple[str, str], src_col: str,
                            tgt_table: Tuple[str, str], tgt_col: str) -> str:
        src_schema, src_tab = src_table
        tgt_schema, tgt_tab = tgt_table

        return (
            f"-- Insert from {src_tab} to {tgt_tab}\n"
            f"INSERT INTO {tgt_schema}.{tgt_tab} ({tgt_col})\n"
            f"SELECT {src_col} FROM {src_schema}.{src_tab};\n"
        )

    def run(self):
        df = self.load_excel_data()
        os.makedirs(self.output_folder, exist_ok=True)

        mappings_per_cat = {
            cat: self.extract_column_mappings(df, cat)
            for cat in self.category_order
        }

        all_insert_sqls = []
        total_insert_count = 0

        for i in range(len(self.category_order) - 1):
            cat_src = self.category_order[i]
            cat_tgt = self.category_order[i + 1]

            src_map = mappings_per_cat[cat_src]
            tgt_map = mappings_per_cat[cat_tgt]

            insert_statements = []
            insert_count = 0

            for src_table, src_columns in src_map.items():
                for tgt_table, tgt_columns in tgt_map.items():
                    # Use min length to avoid mismatch
                    for src_col, tgt_col in zip(src_columns, tgt_columns):
                        sql = self.generate_insert_sql(src_table, src_col, tgt_table, tgt_col)
                        insert_statements.append(sql)
                        all_insert_sqls.append(sql)
                        insert_count += 1
                        total_insert_count += 1

            file_name = f"{cat_src}_to_{cat_tgt}.sql"
            with open(os.path.join(self.output_folder, file_name), "w") as f:
                f.write("\n".join(insert_statements))

            print(f"‚úÖ Generated {insert_count} INSERT statements for: {cat_src} ‚Üí {cat_tgt}")

        # Save master insert file
        with open(os.path.join(self.output_folder, "all_insert_statements.sql"), "w") as f:
            f.write("\n".join(all_insert_sqls))

        print(f"\nüì¶ Total INSERT statements generated: {total_insert_count}")
        print(f"üìÅ Output folder: {self.output_folder}")
