"""
TEXT-ONLY RAG EXTRACTION
========================
Based on your working rag_extraction.py
Extracts fields using OCR text + RAG examples
"""

import json
import logging
from typing import List, Dict, Any, Optional
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential
from prompt_builder import ExtractionPromptBuilder

logger = logging.getLogger(__name__)


class TextRAGExtractor:
    """
    Text-only RAG extractor
    Uses OCR text + similar document examples
    """
    
    def __init__(
        self,
        search_endpoint: str,
        search_api_key: str,
        openai_manager,
        fields: List[str],
        top_k: int = 5,
        similarity_threshold: float = 0.70
    ):
        self.search_endpoint = search_endpoint
        self.search_credential = AzureKeyCredential(search_api_key)
        self.openai_manager = openai_manager
        self.fields = fields
        self.top_k = top_k
        self.similarity_threshold = similarity_threshold
        
        # Initialize prompt builder
        self.prompt_builder = ExtractionPromptBuilder(fields)
        
        logger.info(f"TextRAGExtractor initialized | top_k={top_k}")
    
    def extract_with_rag(
        self,
        document_text: str,
        provider: str,
        source_document: str,
        index_name: str = None,
        document_type: Optional[str] = "passport"
    ) -> Dict[str, Any]:
        """
        Extract fields using text RAG
        
        Args:
            document_text: OCR text
            provider: Provider name
            source_document: Document filename
            index_name: Specific index name to use (if provided)
            document_type: Document type hint
            
        Returns:
            Extraction result with metadata
        """
        logger.info(f"Text RAG extraction | doc={source_document}")
        
        # Step 1: Generate embedding
        try:
            query_vector = self.openai_manager.generate_embeddings(document_text)
            logger.info(f"Generated embedding | dim={len(query_vector)}")
        except Exception as e:
            logger.error(f"Embedding failed: {e}")
            return self._extract_without_rag(document_text, source_document, document_type)
        
        # Step 2: Search similar documents
        similar_docs = []
        try:
            similar_docs = self._search_similar_documents(
                provider=provider,
                query_vector=query_vector,
                top_k=self.top_k,
                index_name=index_name
            )
            
            # Filter by threshold
            similar_docs = [
                doc for doc in similar_docs
                if doc.get('@search.score', 0) >= self.similarity_threshold
            ]
            
            logger.info(f"Found {len(similar_docs)} similar docs above threshold")
            
        except Exception as e:
            logger.warning(f"Search failed: {e}, using standard extraction")
            similar_docs = []
        
        # Step 3: Build prompts
        system_prompt = self.prompt_builder.build_system_prompt(
            document_type=document_type
        )
        
        if similar_docs:
            user_prompt = self.prompt_builder.build_extraction_prompt_with_rag(
                document_text=document_text,
                similar_documents=similar_docs,
                top_k=min(len(similar_docs), self.top_k)
            )
            method = "Text RAG"
        else:
            user_prompt = self.prompt_builder.build_extraction_prompt_without_rag(
                document_text=document_text
            )
            method = "Text Standard"
        
        logger.info(f"Using method: {method}")
        
        # Step 4: Extract with GPT-4o
        try:
            result = self._call_extraction_api(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                source_document=source_document
            )
            
            result['extraction_method'] = method
            result['similar_docs_count'] = len(similar_docs)
            result['used_rag'] = len(similar_docs) > 0
            result['has_vision'] = False
            
            return result
            
        except Exception as e:
            logger.error(f"Extraction failed: {e}")
            return {
                'success': False,
                'extracted_fields': {},
                'error': str(e),
                'extraction_method': method
            }
    
    def _search_similar_documents(
        self,
        provider: str,
        query_vector: List[float],
        top_k: int,
        index_name: str = None
    ) -> List[Dict[str, Any]]:
        """Search for similar documents using vector similarity"""
        
        # Use provided index_name OR build from provider
        if not index_name:
            # Fallback: build from provider name
            index_name = provider.lower().replace(' ', '_').replace('-', '_')
            index_name = ''.join(c for c in index_name if c.isalnum() or c == '_')
            index_name = f"{index_name}_index"
        
        logger.info(f"Searching index: {index_name}")
        
        try:
            search_client = SearchClient(
                endpoint=self.search_endpoint,
                index_name=index_name,
                credential=self.search_credential
            )
            
            results = search_client.search(
                search_text=None,
                vector_queries=[{
                    "kind": "vector",
                    "vector": query_vector,
                    "fields": "content_vector",
                    "k": top_k
                }],
                select=["id", "content", "document_name", "extracted_fields"],
                top=top_k
            )
            
            similar_documents = [dict(result) for result in results]
            logger.info(f"Retrieved {len(similar_documents)} similar documents")
            
            return similar_documents
            
        except Exception as e:
            logger.error(f"Vector search failed: {e}")
            return []
    
    def _extract_without_rag(
        self,
        document_text: str,
        source_document: str,
        document_type: Optional[str] = None
    ) -> Dict[str, Any]:
        """Fallback: Extract without RAG"""
        
        logger.info("Extracting without RAG (fallback)")
        
        system_prompt = self.prompt_builder.build_system_prompt(
            document_type=document_type
        )
        
        user_prompt = self.prompt_builder.build_extraction_prompt_without_rag(
            document_text=document_text
        )
        
        result = self._call_extraction_api(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            source_document=source_document
        )
        
        result['extraction_method'] = "Text Standard (no RAG)"
        result['similar_docs_count'] = 0
        result['used_rag'] = False
        result['has_vision'] = False
        
        return result
    
    def _call_extraction_api(
        self,
        system_prompt: str,
        user_prompt: str,
        source_document: str
    ) -> Dict[str, Any]:
        """Call GPT-4o API for extraction"""
        
        try:
            response = self.openai_manager.gpt_client.chat.completions.create(
                model=self.openai_manager.gpt_deployment,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.0,
                max_tokens=2000
            )
            
            # Track tokens
            if hasattr(response, 'usage'):
                self.openai_manager.prompt_tokens += response.usage.prompt_tokens
                self.openai_manager.completion_tokens += response.usage.completion_tokens
                self.openai_manager.total_tokens += response.usage.total_tokens
            
            content = response.choices[0].message.content.strip()
            
            # Clean markdown
            if content.startswith("```"):
                content = content.replace("```json", "").replace("```", "").strip()
            
            # Parse JSON
            data = json.loads(content)
            
            # Normalize format
            normalized_data = {}
            for field_name in data:
                field_value = data[field_name]
                
                if isinstance(field_value, dict) and 'value' in field_value:
                    normalized_data[field_name] = {
                        'value': field_value.get('value', ''),
                        'confidence': float(field_value.get('confidence', 0.0)),
                        'source_document': source_document
                    }
                else:
                    normalized_data[field_name] = {
                        'value': str(field_value) if field_value else '',
                        'confidence': 0.5,
                        'source_document': source_document
                    }
            
            logger.info(f"Extracted {len(normalized_data)} fields successfully")
            
            return {
                'success': True,
                'extracted_fields': normalized_data,
                'raw_response': content,
                'system_prompt': system_prompt,
                'user_prompt': user_prompt
            }
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parse error: {e} | Content: {content[:200]}")
            return {
                'success': False,
                'extracted_fields': {},
                'error': f"JSON parse error: {e}",
                'raw_response': content[:500]
            }
        except Exception as e:
            logger.error(f"API call failed: {e}")
            return {
                'success': False,
                'extracted_fields': {},
                'error': str(e),
                'raw_response': ''
            }


-----


  """
MULTIMODAL RAG EXTRACTION  
==========================
Vision + Text RAG extraction
Uses GPT-4o Vision to analyze document images + RAG examples
"""

import json
import logging
import base64
from typing import List, Dict, Any, Optional
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential
from prompt_builder import ExtractionPromptBuilder

logger = logging.getLogger(__name__)


class MultimodalRAGExtractor:
    """
    Multimodal RAG extractor
    Uses GPT-4o Vision + OCR text + RAG examples
    Better for poor quality scans
    """
    
    def __init__(
        self,
        search_endpoint: str,
        search_api_key: str,
        openai_manager,
        blob_manager,
        fields: List[str],
        top_k: int = 5,
        similarity_threshold: float = 0.70
    ):
        self.search_endpoint = search_endpoint
        self.search_credential = AzureKeyCredential(search_api_key)
        self.openai_manager = openai_manager
        self.blob_manager = blob_manager
        self.fields = fields
        self.top_k = top_k
        self.similarity_threshold = similarity_threshold
        
        # Initialize prompt builder
        self.prompt_builder = ExtractionPromptBuilder(fields)
        
        logger.info(f"MultimodalRAGExtractor initialized | top_k={top_k}")
    
    def extract_with_rag(
        self,
        document_text: str,
        provider: str,
        source_document: str,
        index_name: str = None,
        blob_path: str = None,
        document_type: Optional[str] = "passport"
    ) -> Dict[str, Any]:
        """
        Extract fields using multimodal RAG
        
        Args:
            document_text: OCR text
            provider: Provider name
            source_document: Document filename
            index_name: Specific index name to use
            blob_path: Path to document in blob storage
            document_type: Document type hint
            
        Returns:
            Extraction result with metadata
        """
        logger.info(f"Multimodal RAG extraction | doc={source_document}")
        
        # Step 1: Get document image
        try:
            image_data = self._get_document_image(blob_path)
            if not image_data:
                logger.warning("Failed to get image, falling back to text-only")
                return self._extract_text_only(
                    document_text, provider, source_document, document_type
                )
        except Exception as e:
            logger.error(f"Image retrieval failed: {e}")
            return self._extract_text_only(
                document_text, provider, source_document, document_type
            )
        
        # Step 2: Generate embedding
        try:
            query_vector = self.openai_manager.generate_embeddings(document_text)
            logger.info(f"Generated embedding | dim={len(query_vector)}")
        except Exception as e:
            logger.error(f"Embedding failed: {e}")
            return self._extract_text_only(
                document_text, provider, source_document, document_type
            )
        
        # Step 3: Search similar documents
        similar_docs = []
        try:
            similar_docs = self._search_similar_documents(
                provider=provider,
                query_vector=query_vector,
                top_k=self.top_k,
                index_name=index_name
            )
            
            # Filter by threshold
            similar_docs = [
                doc for doc in similar_docs
                if doc.get('@search.score', 0) >= self.similarity_threshold
            ]
            
            logger.info(f"Found {len(similar_docs)} similar docs")
            
        except Exception as e:
            logger.warning(f"Search failed: {e}")
            similar_docs = []
        
        # Step 4: Build prompts
        system_prompt = self.prompt_builder.build_system_prompt(
            document_type=document_type
        )
        
        if similar_docs:
            text_prompt = self.prompt_builder.build_extraction_prompt_with_rag(
                document_text=document_text,
                similar_documents=similar_docs,
                top_k=min(len(similar_docs), self.top_k)
            )
            method = "Multimodal RAG"
        else:
            text_prompt = self.prompt_builder.build_extraction_prompt_without_rag(
                document_text=document_text
            )
            method = "Multimodal Standard"
        
        logger.info(f"Using method: {method}")
        
        # Step 5: Extract with GPT-4o Vision
        try:
            result = self._call_vision_api(
                system_prompt=system_prompt,
                text_prompt=text_prompt,
                image_data=image_data,
                source_document=source_document
            )
            
            result['extraction_method'] = method
            result['similar_docs_count'] = len(similar_docs)
            result['used_rag'] = len(similar_docs) > 0
            result['has_vision'] = True
            
            return result
            
        except Exception as e:
            logger.error(f"Vision extraction failed: {e}")
            return {
                'success': False,
                'extracted_fields': {},
                'error': str(e),
                'extraction_method': method
            }
    
    def _get_document_image(self, blob_path: str) -> Optional[str]:
        """Get base64-encoded image from blob storage"""
        try:
            # Download from blob as base64 (YOUR helper.py method)
            base64_image = self.blob_manager.download_blob_as_base64(blob_path)
            
            logger.info(f"Retrieved image | size={len(base64_image)} chars")
            return base64_image
            
        except Exception as e:
            logger.error(f"Failed to get image: {e}")
            return None
    
    def _search_similar_documents(
        self,
        provider: str,
        query_vector: List[float],
        top_k: int,
        index_name: str = None
    ) -> List[Dict[str, Any]]:
        """Search for similar documents"""
        
        # Use provided index_name OR build from provider
        if not index_name:
            index_name = provider.lower().replace(' ', '_').replace('-', '_')
            index_name = ''.join(c for c in index_name if c.isalnum() or c == '_')
            index_name = f"{index_name}_index"
        
        logger.info(f"Searching index: {index_name}")
        
        try:
            search_client = SearchClient(
                endpoint=self.search_endpoint,
                index_name=index_name,
                credential=self.search_credential
            )
            
            results = search_client.search(
                search_text=None,
                vector_queries=[{
                    "kind": "vector",
                    "vector": query_vector,
                    "fields": "content_vector",
                    "k": top_k
                }],
                select=["id", "content", "document_name", "extracted_fields"],
                top=top_k
            )
            
            similar_documents = [dict(result) for result in results]
            logger.info(f"Retrieved {len(similar_documents)} similar documents")
            
            return similar_documents
            
        except Exception as e:
            logger.error(f"Vector search failed: {e}")
            return []
    
    def _call_vision_api(
        self,
        system_prompt: str,
        text_prompt: str,
        image_data: str,
        source_document: str
    ) -> Dict[str, Any]:
        """Call GPT-4o Vision API"""
        
        try:
            # Build vision message
            messages = [
                {"role": "system", "content": system_prompt},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": text_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            }
                        }
                    ]
                }
            ]
            
            response = self.openai_manager.gpt_client.chat.completions.create(
                model=self.openai_manager.gpt_deployment,
                messages=messages,
                temperature=0.0,
                max_tokens=2000
            )
            
            # Track tokens
            if hasattr(response, 'usage'):
                self.openai_manager.prompt_tokens += response.usage.prompt_tokens
                self.openai_manager.completion_tokens += response.usage.completion_tokens
                self.openai_manager.total_tokens += response.usage.total_tokens
            
            content = response.choices[0].message.content.strip()
            
            # Clean markdown
            if content.startswith("```"):
                content = content.replace("```json", "").replace("```", "").strip()
            
            # Parse JSON
            data = json.loads(content)
            
            # Normalize format
            normalized_data = {}
            for field_name in data:
                field_value = data[field_name]
                
                if isinstance(field_value, dict) and 'value' in field_value:
                    normalized_data[field_name] = {
                        'value': field_value.get('value', ''),
                        'confidence': float(field_value.get('confidence', 0.0)),
                        'source_document': source_document
                    }
                else:
                    normalized_data[field_name] = {
                        'value': str(field_value) if field_value else '',
                        'confidence': 0.5,
                        'source_document': source_document
                    }
            
            logger.info(f"Extracted {len(normalized_data)} fields with vision")
            
            return {
                'success': True,
                'extracted_fields': normalized_data,
                'raw_response': content,
                'system_prompt': system_prompt,
                'user_prompt': text_prompt
            }
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parse error: {e}")
            return {
                'success': False,
                'extracted_fields': {},
                'error': f"JSON parse error: {e}",
                'raw_response': content[:500] if 'content' in locals() else ''
            }
        except Exception as e:
            logger.error(f"Vision API call failed: {e}")
            return {
                'success': False,
                'extracted_fields': {},
                'error': str(e),
                'raw_response': ''
            }
    
    def _extract_text_only(
        self,
        document_text: str,
        provider: str,
        source_document: str,
        document_type: Optional[str]
    ) -> Dict[str, Any]:
        """Fallback to text-only if vision fails"""
        
        logger.info("Falling back to text-only extraction")
        
        # Use text_rag approach
        from text_rag import TextRAGExtractor
        
        text_extractor = TextRAGExtractor(
            search_endpoint=self.search_endpoint,
            search_api_key=self.search_credential.key,
            openai_manager=self.openai_manager,
            fields=self.fields,
            top_k=self.top_k,
            similarity_threshold=self.similarity_threshold
        )
        
        return text_extractor.extract_with_rag(
            document_text=document_text,
            provider=provider,
            source_document=source_document,
            document_type=document_type
        )
