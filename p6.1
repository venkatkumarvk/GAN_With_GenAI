import base64
import os
import json
import tempfile
import streamlit as st
from dotenv import load_dotenv
from openai import AzureOpenAI
from pathlib import Path
import fitz  # PyMuPDF
import pandas as pd
from datetime import datetime
import io
import zipfile
from azure.storage.blob import BlobServiceClient, ContentSettings

# Load environment variables from .env file
load_dotenv()

# Azure OpenAI environment variables
aoai_endpoint = os.getenv("AOAI_ENDPOINT")
aoai_api_key = os.getenv("AOAI_API_KEY")
aoai_deployment_name = os.getenv("AOAI_DEPLOYMENT")

# Azure Blob Storage environment variables
azure_storage_connection_string = os.getenv("AZURE_STORAGE_CONNECTION_STRING")
azure_storage_container_name = os.getenv("AZURE_STORAGE_CONTAINER_NAME", "pdf-extraction-results")

# Initialize session state variables for storing results between reruns
if 'all_pdf_results' not in st.session_state:
    st.session_state.all_pdf_results = []
if 'results_df' not in st.session_state:
    st.session_state.results_df = None
if 'edited_results_df' not in st.session_state:
    st.session_state.edited_results_df = None
if 'current_pdf_index' not in st.session_state:
    st.session_state.current_pdf_index = 0
if 'current_page_index' not in st.session_state:
    st.session_state.current_page_index = 0
if 'files_to_process' not in st.session_state:
    st.session_state.files_to_process = None
if 'input_method' not in st.session_state:
    st.session_state.input_method = "Upload Files"
if 'blob_service_client' not in st.session_state:
    st.session_state.blob_service_client = None
if 'selected_container' not in st.session_state:
    st.session_state.selected_container = None
if 'editing_mode' not in st.session_state:
    st.session_state.editing_mode = False
if 'confidence_threshold' not in st.session_state:
    st.session_state.confidence_threshold = 90.0

# Initialize the Azure OpenAI client
@st.cache_resource
def get_client():
    return AzureOpenAI(
        azure_endpoint=aoai_endpoint,
        api_key=aoai_api_key,
        api_version="2024-08-01-preview"
    )

# Initialize the Azure Blob Storage client
@st.cache_resource
def get_blob_service_client():
    return BlobServiceClient.from_connection_string(azure_storage_connection_string)

def get_blob_containers(blob_service_client):
    """
    Get a list of available containers in the Azure Blob Storage account.
    """
    try:
        containers = []
        for container in blob_service_client.list_containers():
            containers.append(container.name)
        return containers
    except Exception as e:
        st.error(f"Error listing containers: {e}")
        return []

def get_blob_folders(blob_service_client, container_name):
    """
    Get a list of "folders" (common prefixes) in the Azure Blob Storage container.
    Note: Blob storage doesn't have actual folders, but we can simulate them using prefixes.
    """
    try:
        container_client = blob_service_client.get_container_client(container_name)
        
        # Get all blobs in the container
        blobs = container_client.list_blobs()
        
        # Extract folder paths (common prefixes before the last '/')
        folders = set()
        for blob in blobs:
            name = blob.name
            if '/' in name:
                folder = name.rsplit('/', 1)[0] + '/'
                folders.add(folder)
            
        # Add a root option
        folders.add("")  # root directory
        
        return sorted(list(folders))
    except Exception as e:
        st.error(f"Error listing folders in container {container_name}: {e}")
        return []

def list_pdf_blobs(blob_service_client, container_name, folder_prefix=""):
    """
    List all PDF blobs in the specified container and folder prefix.
    """
    try:
        container_client = blob_service_client.get_container_client(container_name)
        
        # Get blobs with the folder prefix that are PDFs
        pdf_blobs = []
        for blob in container_client.list_blobs(name_starts_with=folder_prefix):
            if blob.name.lower().endswith('.pdf'):
                pdf_blobs.append(blob.name)
                
        return pdf_blobs
    except Exception as e:
        st.error(f"Error listing PDF blobs: {e}")
        return []

def download_blob_to_memory(blob_service_client, container_name, blob_name):
    """
    Download a blob to memory.
    """
    try:
        container_client = blob_service_client.get_container_client(container_name)
        blob_client = container_client.get_blob_client(blob_name)
        
        # Download the blob content
        download_stream = blob_client.download_blob()
        content = download_stream.readall()
        
        return content
    except Exception as e:
        st.error(f"Error downloading blob {blob_name}: {e}")
        return None

def render_pdf_preview(pdf_file):
    """
    Render a preview of the first page of a PDF file.
    For uploaded files or blob downloads.
    """
    tmp_path = None
    try:
        # If it's a uploaded file, get the bytes
        if hasattr(pdf_file, 'getvalue'):
            pdf_bytes = pdf_file.getvalue()
        else:
            # Assume it's already bytes (from blob storage)
            pdf_bytes = pdf_file
            
        # Create a temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(pdf_bytes)
            tmp_path = tmp_file.name
            
        # Open the PDF and get the first page as an image
        with fitz.open(tmp_path) as doc:
            if len(doc) > 0:
                # Get the first page
                page = doc.load_page(0)
                
                # Render the page to an image (with higher resolution)
                zoom = 2.0  # zoom factor
                mat = fitz.Matrix(zoom, zoom)
                pix = page.get_pixmap(matrix=mat)
                
                # Convert to an image
                img_bytes = pix.tobytes()
                
                # Return the image
                return img_bytes
            else:
                st.sidebar.warning("PDF appears to be empty")
                return None
                
    except Exception as e:
        st.sidebar.error(f"Error rendering PDF preview: {e}")
        return None
    finally:
        # Clean up temporary file
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.unlink(tmp_path)
            except Exception as cleanup_error:
                st.sidebar.warning(f"Could not remove temporary preview file: {cleanup_error}")

def display_pdf_previews_sidebar(files, blob_service_client=None, container_name=None):
    """
    Display preview thumbnails of PDFs in the sidebar.
    Works with both uploaded files and blob references.
    """
    st.sidebar.header("PDF Previews")
    
    if not files:
        st.sidebar.info("No PDF files to preview")
        return
    
    # Create a scrollable area for previews
    preview_area = st.sidebar.container()
    
    with preview_area:
        for i, file in enumerate(files):
            # Create an expander for each file
            if isinstance(file, str):  # It's a blob name
                filename = file.split('/')[-1]  # Extract filename from path
                with st.sidebar.expander(f"{i+1}. {filename}"):
                    # Download blob contents
                    blob_content = download_blob_to_memory(blob_service_client, container_name, file)
                    if blob_content:
                        img_bytes = render_pdf_preview(blob_content)
                        if img_bytes:
                            # Display image with caption
                            st.image(img_bytes, caption=f"Page 1 of {filename}", use_column_width=True)
                        else:
                            st.warning("Could not generate preview")
                    else:
                        st.error(f"Could not download {filename}")
            else:  # It's an uploaded file
                with st.sidebar.expander(f"{i+1}. {file.name}"):
                    # Get file position
                    pos = file.tell()
                    
                    # Generate preview
                    img_bytes = render_pdf_preview(file)
                    
                    # Reset file position for later use
                    file.seek(pos)
                    
                    if img_bytes:
                        # Display image with caption
                        st.image(img_bytes, caption=f"Page 1 of {file.name}", use_column_width=True)
                    else:
                        st.warning("Could not generate preview")

def convert_pdf_to_base64(pdf_file):
    """
    Convert a PDF file to base64 for embedding in HTML.
    
    Parameters:
    - pdf_file: Either a BytesIO object or bytes
    
    Returns:
    - base64 string of the PDF file
    """
    try:
        # If it's an uploaded file with getvalue method, use that
        if hasattr(pdf_file, 'getvalue'):
            pdf_bytes = pdf_file.getvalue()
        else:
            # Assume it's already bytes
            pdf_bytes = pdf_file
            
        # Encode to base64
        base64_pdf = base64.b64encode(pdf_bytes).decode('utf-8')
        return base64_pdf
    except Exception as e:
        st.error(f"Error converting PDF to base64: {e}")
        return None

def display_pdf_viewer(base64_pdf, height=500):
    """
    Display a PDF viewer in the Streamlit app using base64 encoded PDF.
    No temporary files are created on disk.
    
    Parameters:
    - base64_pdf: base64 encoded PDF data
    - height: height of the viewer iframe
    """
    if not base64_pdf:
        st.error("No PDF data available to display")
        return
        
    # Create the HTML with PDF.js for better viewing
    pdf_display = f"""
    <iframe src="data:application/pdf;base64,{base64_pdf}" width="100%" height="{height}" 
    type="application/pdf"></iframe>
    """
    
    # Display the PDF
    st.markdown(pdf_display, unsafe_allow_html=True)

def image_to_data_url(image_bytes, mime_type='image/png'):
    """
    Convert image bytes to a data URL.
    """
    base64_encoded_data = base64.b64encode(image_bytes).decode('utf-8')
    return f"data:{mime_type};base64,{base64_encoded_data}"

def call_azure_openai_vision(prompt, image_data_url, client, deployment_name):
    """
    Call the Azure OpenAI Vision service to analyze an image.
    """
    try:
        completion = client.chat.completions.create(
            model=deployment_name,
            messages=[{
                "role": "system",
                "content": "You are an AI helpful assistant that extracts information from invoice documents. Your task is to extract the following fields from invoices: VendorName, InvoiceNumber, InvoiceDate, CustomerName, PurchaseOrder, StockCode, UnitPrice, InvoiceAmount, Freight, Salestax, and Total. Return a JSON object with these keys. For each field, also include a confidence score between 0 and 1. The response format should be: {\"VendorName\": {\"value\": \"ABC Corp\", \"confidence\": 0.95}, \"InvoiceNumber\": {\"value\": \"INV-12345\", \"confidence\": 0.87}, ...and so on for each field.}"
            }, {
                "role": "user",
                "content": [{
                    "type": "text",
                    "text": prompt
                }, {
                    "type": "image_url",
                    "image_url": {
                        "url": image_data_url
                    }
                }]
            }],
            max_tokens=2000,
            temperature=0.7,
            response_format={"type": "json_object"}
        )
        
        # Extract and parse the response content
        response_content = completion.choices[0].message.content
        return json.loads(response_content)
    except Exception as e:
        st.error(f"Error calling Azure OpenAI: {str(e)}")
        return {"error": str(e)}

def process_pdf(pdf_file, prompt, client, deployment_name, progress_bar=None, progress_text=None):
    """
    Process a PDF file and extract information from all pages.
    """
    tmp_path = None
    try:
        # Create a temporary file to store the uploaded PDF
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(pdf_file.getvalue())
            tmp_path = tmp_file.name
        
        # Get the filename
        filename = pdf_file.name
        
        # Open the PDF file
        with fitz.open(tmp_path) as doc:
            page_count = len(doc)
            
            if progress_text:
                progress_text.text(f"Processing {filename} - {page_count} pages...")
            
            # Create a list to store extracted data from all pages
            all_page_results = []
            
            # Process each page in the PDF
            for page_num in range(page_count):
                try:
                    # Update progress
                    if progress_bar:
                        progress_bar.progress((page_num + 1) / page_count)
                    if progress_text:
                        progress_text.text(f"Processing {filename} - Page {page_num+1}/{page_count}")
                    
                    # Load the current page
                    page = doc.load_page(page_num)
                    
                    # Process image
                    zoom = 2  # Zoom factor for image quality
                    pix = page.get_pixmap(matrix=fitz.Matrix(zoom, zoom))
                    image_bytes = pix.tobytes()
                    
                    # Convert image to data URL
                    image_data_url = image_to_data_url(image_bytes)
                    
                    # Call Azure OpenAI Vision to extract structured information
                    extracted_info = call_azure_openai_vision(prompt, image_data_url, client, deployment_name)
                    
                    # Add page info to the collected results
                    extracted_info_with_page = {
                        "page": page_num + 1,
                        "data": extracted_info
                    }
                    
                    # Add to our collection of all page results
                    all_page_results.append(extracted_info_with_page)
                    
                except Exception as e:
                    error_msg = f"Error processing page {page_num+1} of {filename}: {e}"
                    st.warning(error_msg)
                    all_page_results.append({
                        "page": page_num + 1,
                        "data": {"error": str(e)}
                    })
        
        # Create a result object that contains all pages' data
        final_result = {
            "filename": filename,
            "total_pages": page_count,
            "pages": all_page_results
        }
        
        return final_result
        
    except Exception as e:
        error_msg = f"Error processing {pdf_file.name}: {e}"
        st.error(error_msg)
        return {
            "filename": pdf_file.name,
            "error": str(e),
            "total_pages": 0,
            "pages": []
        }
    finally:
        # Clean up the temporary file
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.unlink(tmp_path)
            except Exception as cleanup_error:
                st.warning(f"Could not remove temporary file {tmp_path}: {cleanup_error}")

def process_blob_pdfs(blob_service_client, container_name, pdf_blobs, prompt, client, deployment_name):
    """
    Process PDF blobs from Azure Blob Storage.
    """
    all_pdf_results = []
    
    # Create progress tracking
    progress_bar = st.progress(0)
    progress_text = st.empty()
    
    for i, blob_name in enumerate(pdf_blobs):
        progress_text.text(f"Processing file {i+1}/{len(pdf_blobs)}: {blob_name}")
        tmp_path = None
        
        try:
            # Download blob to memory
            blob_content = download_blob_to_memory(blob_service_client, container_name, blob_name)
            
            if blob_content is None:
                st.warning(f"Could not download blob: {blob_name}")
                continue
            
            # Create a BytesIO object from the blob content
            blob_file = io.BytesIO(blob_content)
            filename = blob_name.split('/')[-1]  # Set the filename to the blob name without folder path
            blob_file.name = filename
            
            # Create a temporary file for processing
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(blob_content)
                tmp_path = tmp_file.name
                
            # Open the PDF file
            with fitz.open(tmp_path) as doc:
                page_count = len(doc)
                
                progress_text.text(f"Processing {filename} - {page_count} pages...")
                
                # Create a list to store extracted data from all pages
                all_page_results = []
                
                # Process each page in the PDF
                for page_num in range(page_count):
                    try:
                        # Update progress
                        sub_progress = (i + (page_num + 1) / page_count) / len(pdf_blobs)
                        progress_bar.progress(sub_progress)
                        progress_text.text(f"Processing {filename} - Page {page_num+1}/{page_count}")
                        
                        # Load the current page
                        page = doc.load_page(page_num)
                        
                        # Process image
                        zoom = 2  # Zoom factor for image quality
                        pix = page.get_pixmap(matrix=fitz.Matrix(zoom, zoom))
                        image_bytes = pix.tobytes()
                        
                        # Convert image to data URL
                        image_data_url = image_to_data_url(image_bytes)
                        
                        # Call Azure OpenAI Vision to extract structured information
                        extracted_info = call_azure_openai_vision(prompt, image_data_url, client, deployment_name)
                        
                        # Add page info to the collected results
                        extracted_info_with_page = {
                            "page": page_num + 1,
                            "data": extracted_info
                        }
                        
                        # Add to our collection of all page results
                        all_page_results.append(extracted_info_with_page)
                        
                    except Exception as e:
                        error_msg = f"Error processing page {page_num+1} of {filename}: {e}"
                        st.warning(error_msg)
                        all_page_results.append({
                            "page": page_num + 1,
                            "data": {"error": str(e)}
                        })
                
                # Create a result object that contains all pages' data
                final_result = {
                    "filename": filename,
                    "total_pages": page_count,
                    "pages": all_page_results
                }
                
                # Add to our collection of all PDF results
                all_pdf_results.append(final_result)
            
        except Exception as e:
            st.error(f"Error processing blob {blob_name}: {e}")
            all_pdf_results.append({
                "filename": blob_name.split('/')[-1],
                "error": str(e),
                "total_pages": 0,
                "pages": []
            })
        finally:
            # Clean up the temporary file
            if tmp_path and os.path.exists(tmp_path):
                try:
                    os.unlink(tmp_path)
                except Exception as cleanup_error:
                    st.warning(f"Could not remove temporary file {tmp_path}: {cleanup_error}")
            
            # Update overall progress
            progress_bar.progress((i + 1) / len(pdf_blobs))
    
    progress_text.text("Processing complete!")
    progress_bar.progress(1.0)
    
    return all_pdf_results

def create_results_dataframe(all_pdf_results):
    """
    Create a pandas DataFrame from the extracted results for easy viewing.
    """
    rows = []
    
    # Define the fields we're extracting
    fields = [
        "VendorName", "InvoiceNumber", "InvoiceDate", "CustomerName", 
        "PurchaseOrder", "StockCode", "UnitPrice", "InvoiceAmount", 
        "Freight", "Salestax", "Total"
    ]
    
    for pdf_result in all_pdf_results:
        filename = pdf_result["filename"]
        
        for page in pdf_result["pages"]:
            page_num = page["page"]
            data = page["data"]
            
            # Check for errors
            if "error" in data:
                row_data = {
                    "Filename": filename,
                    "Page": page_num
                }
                
                # Add placeholders for all fields and confidence values
                for field in fields:
                    row_data[field] = "N/A"
                    row_data[f"{field} Confidence"] = 0
                
                rows.append(row_data)
                continue
            
            # Initialize row data
            row_data = {
                "Filename": filename,
                "Page": page_num
            }
            
            # Process each field
            for field in fields:
                field_data = data.get(field, {})
                
                if isinstance(field_data, dict):
                    value = field_data.get("value", "N/A")
                    confidence = field_data.get("confidence", 0)
                else:
                    value = field_data if field_data else "N/A"
                    confidence = 0
                
                # Ensure values are strings to avoid PyArrow errors
                if isinstance(value, (list, dict)):
                    value = str(value)
                
                # Add to row data
                row_data[field] = value
                row_data[f"{field} Confidence"] = round(confidence * 100, 2)
            
            # Add completed row to rows
            rows.append(row_data)
    
    try:
        # First method: Try creating a DataFrame with string type
        # This avoids PyArrow conversion issues for mixed types
        return pd.DataFrame(rows, dtype=str)
    except Exception as e:
        st.warning(f"Error creating DataFrame: {e}. Trying alternative method...")
        
        try:
            # Second method: Try with pandas default types but disable PyArrow
            with pd.option_context('mode.dtype_backend', 'numpy'):  # Use NumPy instead of PyArrow
                return pd.DataFrame(rows)
        except Exception as e:
            st.warning(f"Second method failed: {e}. Using final fallback method...")
            
            try:
                # Third method: Convert all values to strings explicitly before creating DataFrame
                string_rows = []
                for row in rows:
                    string_row = {}
                    for key, value in row.items():
                        string_row[key] = str(value)
                    string_rows.append(string_row)
                return pd.DataFrame(string_rows)
            except Exception as e:
                st.error(f"All DataFrame creation methods failed: {e}")
                # Return empty DataFrame as absolute last resort
                return pd.DataFrame()

def apply_confidence_highlighting(df, threshold=90.0):
    """
    Apply styling to the DataFrame to highlight cells based on confidence scores.
    """
    # Define the fields we're extracting
    fields = [
        "VendorName", "InvoiceNumber", "InvoiceDate", "CustomerName", 
        "PurchaseOrder", "StockCode", "UnitPrice", "InvoiceAmount", 
        "Freight", "Salestax", "Total"
    ]
    
    # Create a style function for confidence scores
    def highlight_confidence(s):
        if s.name.endswith(' Confidence'):
            # Extract value and convert to float if possible
            try:
                vals = pd.to_numeric(s, errors='coerce')
                return ['background-color: #e6ffe6' if v >= threshold else 'background-color: #ffe6e6' for v in vals]
            except:
                return [''] * len(s)
        return [''] * len(s)
    
    # Define alternating row colors
    def alternating_rows(s):
        return ['background-color: #f9f9f9' if i % 2 == 0 else '' for i in range(len(s))]
    
    # Apply styling
    styled_df = df.style\
        .apply(highlight_confidence)\
        .set_properties(**{'border': '1px solid #ddd', 'padding': '8px'})\
        .set_table_styles([
            {'selector': 'th', 'props': [('background-color', '#4CAF50'), ('color', 'white'), ('font-weight', 'bold'), ('padding', '10px')]},
            {'selector': 'caption', 'props': [('caption-side', 'top'), ('font-size', '1.2em'), ('font-weight', 'bold')]}
        ])\
        .set_caption('Extraction Results')
    
    return styled_df

def create_text_files_zip(all_pdf_results):
    """
    Create a zip file containing text files for each PDF.
    """
    # Create a BytesIO object to store the zip file
    zip_buffer = io.BytesIO()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Create a ZipFile object
    with zipfile.ZipFile(zip_buffer, 'a', zipfile.ZIP_DEFLATED, False) as zip_file:
        for pdf_result in all_pdf_results:
            filename = pdf_result["filename"]
            base_filename = os.path.splitext(filename)[0]
            
            # Create the text content for this PDF (only key-value pairs)
            page_results_text = create_page_results_text(pdf_result)
            
            # Add structured data as a text file with timestamp
            zip_file.writestr(f"{base_filename}_{timestamp}.txt", page_results_text)
    
    # Seek to the beginning of the BytesIO object
    zip_buffer.seek(0)
    return zip_buffer

def create_page_results_text(pdf_result):
    """
    Create a text file containing only the key-value pairs from each page.
    Returns a string with the formatted key-value pairs.
    """
    # Define the fields we're extracting
    fields = [
        "VendorName", "InvoiceNumber", "InvoiceDate", "CustomerName", 
        "PurchaseOrder", "StockCode", "UnitPrice", "InvoiceAmount", 
        "Freight", "Salestax", "Total"
    ]
    
    result_text = ""
    
    for page in pdf_result["pages"]:
        page_num = page["page"]
        data = page["data"]
        
        result_text += f"--- PAGE {page_num} ---\n"
        
        if "error" in data:
            result_text += f"error: {data['error']}\n\n"
            continue
            
        # Process fields with confidence scores
        for field in fields:
            display_field = ''.join(' ' + char if char.isupper() else char for char in field).strip().lower()
            
            field_data = data.get(field, {})
            if isinstance(field_data, dict):
                value = field_data.get("value", "N/A")
                confidence = field_data.get("confidence", 0)
                result_text += f"{display_field}: {value}\n"
                result_text += f"{display_field} confidence: {round(confidence * 100, 2)}%\n"
            else:
                result_text += f"{display_field}: {field_data}\n"
        
        result_text += "\n"
        
    return result_text

def evaluate_extraction_results(all_pdf_results, confidence_threshold=90.0):
    """
    Evaluate the quality and completeness of extraction results using the
    confidence scores provided by Azure AI Vision.
    """
    # Define the fields we're extracting
    fields = [
        "VendorName", "InvoiceNumber", "InvoiceDate", "CustomerName", 
        "PurchaseOrder", "StockCode", "UnitPrice", "InvoiceAmount", 
        "Freight", "Salestax", "Total"
    ]
    
    evaluation_results = {
        "total_documents": len(all_pdf_results),
        "total_pages": 0,
        "successful_pages": 0,
        "failed_pages": 0,
        "field_confidence": {},
        "documents_with_errors": [],
        "fields_needing_review": {}  # Track fields that need review
    }
    
    # Initialize field confidence data structure
    for field in fields:
        evaluation_results["field_confidence"][field] = {
            "total": 0,
            "average_confidence": 0,
            "pages_above_threshold": 0,
            "percent_above_threshold": 0
        }
        evaluation_results["fields_needing_review"][field] = []
    
    # Collect all confidence scores by field
    all_confidences = {}
    for field in fields:
        all_confidences[field] = []
    
    for pdf_result in all_pdf_results:
        filename = pdf_result["filename"]
        document_has_error = False
        
        for page in pdf_result["pages"]:
            evaluation_results["total_pages"] += 1
            page_num = page["page"]
            data = page["data"]
            
            if "error" in data:
                evaluation_results["failed_pages"] += 1
                document_has_error = True
                continue
                
            page_successful = True
            
            # Check each field for confidence scores
            for field in fields:
                field_data = data.get(field, {})
                
                if isinstance(field_data, dict) and "confidence" in field_data:
                    confidence = field_data.get("confidence", 0)
                    value = field_data.get("value", "N/A")
                    evaluation_results["field_confidence"][field]["total"] += 1
                    all_confidences[field].append(confidence)
                    
                    # Track fields that need review (below threshold)
                    confidence_percent = confidence * 100
                    if confidence_percent < confidence_threshold:
                        evaluation_results["fields_needing_review"][field].append({
                            "filename": filename,
                            "page": page_num,
                            "value": value,
                            "confidence": confidence_percent
                        })
                    
                    # Count pages above threshold
                    if confidence_percent >= confidence_threshold:
                        evaluation_results["field_confidence"][field]["pages_above_threshold"] += 1
                    else:
                        page_successful = False
                else:
                    page_successful = False
            
            if page_successful:
                evaluation_results["successful_pages"] += 1
            else:
                evaluation_results["failed_pages"] += 1
                document_has_error = True
        
        if document_has_error:
            evaluation_results["documents_with_errors"].append(filename)
    
    # Calculate average confidence for each field
    for field in all_confidences:
        confidences = all_confidences[field]
        if confidences:
            avg_confidence = sum(confidences) / len(confidences)
            evaluation_results["field_confidence"][field]["average_confidence"] = round(avg_confidence * 100, 2)
            
            # Calculate percentage of pages above threshold
            total = evaluation_results["field_confidence"][field]["total"]
            if total > 0:
                above_threshold = evaluation_results["field_confidence"][field]["pages_above_threshold"]
                evaluation_results["field_confidence"][field]["percent_above_threshold"] = round((above_threshold / total) * 100, 2)
    
    # Calculate overall success rate
    if evaluation_results["total_pages"] > 0:
        evaluation_results["success_rate"] = round((evaluation_results["successful_pages"] / evaluation_results["total_pages"]) * 100, 2)
    
    # Calculate overall confidence score (average of field confidence)
    field_scores = [field_data["average_confidence"] for field_data in evaluation_results["field_confidence"].values() if "average_confidence" in field_data]
    if field_scores:
        evaluation_results["overall_confidence_score"] = round(sum(field_scores) / len(field_scores), 2)
    
    return evaluation_results

def upload_to_blob_storage(blob_service_client, container_name, blob_name, data, content_type):
    """
    Upload data to Azure Blob Storage.
    """
    try:
        # Get the blob client
        container_client = blob_service_client.get_container_client(container_name)
        
        # Create the container if it doesn't exist
        if not container_client.exists():
            container_client.create_container()
        
        # Upload blob
        blob_client = container_client.get_blob_client(blob_name)
        
        # Set content settings
        content_settings = ContentSettings(content_type=content_type)
        
        # Upload the file
        blob_client.upload_blob(data, overwrite=True, content_settings=content_settings)
        
        return True, blob_client.url
    except Exception as e:
        return False, str(e)

def update_pdf_results_from_dataframe(all_pdf_results, edited_df):
    """
    Update the original PDF results with edited values from the DataFrame.
    This allows edited values to be saved back to the JSON and TXT output files.
    """
    # Define the fields we're extracting
    fields = [
        "VendorName", "InvoiceNumber", "InvoiceDate", "CustomerName", 
        "PurchaseOrder", "StockCode", "UnitPrice", "InvoiceAmount", 
        "Freight", "Salestax", "Total"
    ]
    
    try:
        # Iterate through the DataFrame rows
        for _, row in edited_df.iterrows():
            filename = row['Filename']
            page_num = int(row['Page'])
            
            # Find the corresponding PDF result
            for pdf_result in all_pdf_results:
                if pdf_result["filename"] == filename:
                    # Find the corresponding page
                    for page in pdf_result["pages"]:
                        if page["page"] == page_num:
                            # Update each field value
                            for field in fields:
                                # Skip if there's an error in this page
                                if "error" in page["data"]:
                                    continue
                                    
                                # Get the value from the edited DataFrame
                                new_value = row[field]
                                
                                # Update the value in the PDF result
                                if isinstance(page["data"].get(field), dict):
                                    # The field exists and is a dictionary
                                    page["data"][field]["value"] = new_value
                                    
                                    # If the value was edited by user (not just displayed), mark the confidence as 1.0
                                    confidence_col = f"{field} Confidence"
                                    if confidence_col in row:
                                        # Consider it user-verified if confidence is exactly 100
                                        if float(row[confidence_col]) == 100.0:
                                            page["data"][field]["confidence"] = 1.0
                                else:
                                    # The field doesn't exist or isn't a dictionary, create a new one
                                    page["data"][field] = {
                                        "value": new_value,
                                        "confidence": 1.0  # User-provided value has confidence 1.0
                                    }
        
        return all_pdf_results
        
    except Exception as e:
        st.error(f"Error updating PDF results from edited DataFrame: {e}")
        return all_pdf_results

def display_edit_form(results_df, pdf_results, current_pdf_index, current_page_index):
    """
    Display a form for editing extracted values with low confidence.
    """
    if results_df is None or results_df.empty:
        st.warning("No data available to edit")
        return None
    
    # Get unique filenames
    filenames = results_df['Filename'].unique()
    
    if len(filenames) == 0:
        st.warning("No files to edit")
        return None
    
    # Get the current document to edit
    selected_pdf_index = st.selectbox(
        "Select Document to Edit:", 
        range(len(filenames)), 
        format_func=lambda i: filenames[i],
        index=min(current_pdf_index, len(filenames)-1)
    )
    
    selected_pdf = filenames[selected_pdf_index]
    
    # Filter rows for the selected PDF
    pdf_rows = results_df[results_df['Filename'] == selected_pdf]
    
    # Get pages for this PDF
    pages = sorted(pdf_rows['Page'].unique())
    
    if len(pages) == 0:
        st.warning(f"No pages found for {selected_pdf}")
        return None
    
    # Get the current page to edit
    selected_page_index = st.selectbox(
        "Select Page to Edit:", 
        range(len(pages)), 
        format_func=lambda i: f"Page {pages[i]}",
        index=min(current_page_index, len(pages)-1)
    )
    
    selected_page = pages[selected_page_index]
    
    # Get the row for this page
    page_row = pdf_rows[pdf_rows['Page'] == selected_page].iloc[0].copy()
    
    # Define the fields to edit
    fields = [
        "VendorName", "InvoiceNumber", "InvoiceDate", "CustomerName", 
        "PurchaseOrder", "StockCode", "UnitPrice", "InvoiceAmount", 
        "Freight", "Salestax", "Total"
    ]
    
    # Create a PDF preview of the current page if available
    st.subheader(f"Preview: {selected_pdf} - Page {selected_page}")
    
    # Try to get the PDF file for display
    pdf_file = None
    # Find the file in the list of files to process
    if isinstance(st.session_state.files_to_process[0], str):  # Blob storage
        blob_name = next((f for f in st.session_state.files_to_process if f.split('/')[-1] == selected_pdf), None)
        if blob_name:
            blob_content = download_blob_to_memory(st.session_state.blob_service_client, st.session_state.selected_container, blob_name)
            if blob_content:
                # Create temporary PDF file with just the selected page
                tmp_path = None
                try:
                    # Create a temporary file for the full PDF
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                        tmp_file.write(blob_content)
                        tmp_path = tmp_file.name
                    
                    # Open the PDF and extract the specific page
                    with fitz.open(tmp_path) as doc:
                        if 0 <= int(selected_page) - 1 < len(doc):
                            page_index = int(selected_page) - 1
                            # Extract the page
                            page = doc.load_page(page_index)
                            
                            # Render the page to an image
                            zoom = 2.0  # zoom factor
                            mat = fitz.Matrix(zoom, zoom)
                            pix = page.get_pixmap(matrix=mat)
                            
                            # Convert to an image and display
                            img_bytes = pix.tobytes()
                            st.image(img_bytes, caption=f"Page {selected_page} of {selected_pdf}", use_column_width=True)
                        else:
                            st.warning(f"Page {selected_page} not found in the PDF")
                finally:
                    # Clean up temporary file
                    if tmp_path and os.path.exists(tmp_path):
                        try:
                            os.unlink(tmp_path)
                        except Exception as cleanup_error:
                            st.warning(f"Could not remove temporary file: {cleanup_error}")
    else:  # Uploaded files
        file_obj = next((f for f in st.session_state.files_to_process if f.name == selected_pdf), None)
        if file_obj:
            # Get file position
            pos = file_obj.tell()
            
            # Create temporary PDF file with just the selected page
            tmp_path = None
            try:
                # Create a temporary file for the full PDF
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                    tmp_file.write(file_obj.getvalue())
                    tmp_path = tmp_file.name
                
                # Open the PDF and extract the specific page
                with fitz.open(tmp_path) as doc:
                    if 0 <= int(selected_page) - 1 < len(doc):
                        page_index = int(selected_page) - 1
                        # Extract the page
                        page = doc.load_page(page_index)
                        
                        # Render the page to an image
                        zoom = 2.0  # zoom factor
                        mat = fitz.Matrix(zoom, zoom)
                        pix = page.get_pixmap(matrix=mat)
                        
                        # Convert to an image and display
                        img_bytes = pix.tobytes()
                        st.image(img_bytes, caption=f"Page {selected_page} of {selected_pdf}", use_column_width=True)
                    else:
                        st.warning(f"Page {selected_page} not found in the PDF")
            finally:
                # Clean up temporary file
                if tmp_path and os.path.exists(tmp_path):
                    try:
                        os.unlink(tmp_path)
                    except Exception as cleanup_error:
                        st.warning(f"Could not remove temporary file: {cleanup_error}")
                
                # Reset file position
                file_obj.seek(pos)
    
    # Create a form for editing values
    with st.form(key=f"edit_form_{selected_pdf}_{selected_page}"):
        st.subheader("Edit Extraction Results")
        
        edited_values = {}
        
        # Display fields with their confidence scores
        for field in fields:
            # Get current value and confidence
            current_value = page_row[field]
            confidence_col = f"{field} Confidence"
            confidence = float(page_row[confidence_col]) if confidence_col in page_row else 0
            
            # Style based on confidence threshold
            confidence_color = "#90EE90" if confidence >= st.session_state.confidence_threshold else "#FFCCCB"
            
            # Create labeled container with colored background
            st.markdown(
                f"<div style='background-color: {confidence_color}; padding: 10px; border-radius: 5px;'>"
                f"<label><b>{field}</b> (Confidence: {confidence:.1f}%)</label>"
                "</div>", 
                unsafe_allow_html=True
            )
            
            # Text input for the field value
            new_value = st.text_input(
                f"Edit {field}",
                value=current_value,
                key=f"{selected_pdf}_{selected_page}_{field}"
            )
            
            # Store the edited value
            edited_values[field] = new_value
            
            # For numeric fields, validate the input
            if field in ["UnitPrice", "InvoiceAmount", "Freight", "Salestax", "Total"]:
                try:
                    # Try to parse as a number (but don't convert in the form)
                    float(new_value.replace(',', '').replace(', ''))
                except ValueError:
                    st.warning(f"{field} should be a numeric value")
            
            # Add a little space between fields
            st.markdown("<div style='margin-bottom: 10px;'></div>", unsafe_allow_html=True)
        
        # Submit button
        col1, col2 = st.columns([5, 1])
        with col1:
            submit_button = st.form_submit_button("Save Changes")
        with col2:
            # Mark as verified button - sets confidence to 100% for all fields
            verified_button = st.form_submit_button("Mark All Verified")
        
        # Form processing
        if submit_button or verified_button:
            # Update the page row with edited values
            for field in fields:
                page_row[field] = edited_values[field]
                
                # If verified button was clicked, set all confidences to 100%
                if verified_button:
                    confidence_col = f"{field} Confidence"
                    if confidence_col in page_row:
                        page_row[confidence_col] = 100.0
            
            # Update the DataFrame
            results_df.loc[(results_df['Filename'] == selected_pdf) & (results_df['Page'] == selected_page)] = page_row
            
            # Regenerate the PDF results from the edited DataFrame
            updated_pdf_results = update_pdf_results_from_dataframe(pdf_results, results_df)
            
            # Update the session state
            st.session_state.edited_results_df = results_df
            st.session_state.all_pdf_results = updated_pdf_results
            
            # Notify user
            if verified_button:
                st.success(f"All fields marked as verified for {selected_pdf} - Page {selected_page}")
            else:
                st.success(f"Changes saved for {selected_pdf} - Page {selected_page}")
            
            # Remember the current position
            st.session_state.current_pdf_index = selected_pdf_index
            st.session_state.current_page_index = selected_page_index
            
            # Force a rerun to update the interface
            st.experimental_rerun()
    
    # Navigation buttons
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Previous page button
        if selected_page_index > 0:
            if st.button("‚Üê Previous Page"):
                st.session_state.current_pdf_index = selected_pdf_index
                st.session_state.current_page_index = selected_page_index - 1
                st.experimental_rerun()
    
    with col2:
        # Jump to low confidence button
        st.button("Find Next Low Confidence", help="Jump to the next page with low confidence fields")
        # TODO: Implement the logic to find the next page with low confidence
    
    with col3:
        # Next page button
        if selected_page_index < len(pages) - 1:
            if st.button("Next Page ‚Üí"):
                st.session_state.current_pdf_index = selected_pdf_index
                st.session_state.current_page_index = selected_page_index + 1
                st.experimental_rerun()
    
    return results_df

def display_confidence_settings():
    """
    Display settings for confidence threshold and filtering.
    """
    st.sidebar.header("Confidence Settings")
    
    # Confidence threshold slider
    confidence_threshold = st.sidebar.slider(
        "Confidence Threshold (%)", 
        min_value=0.0, 
        max_value=100.0, 
        value=st.session_state.confidence_threshold,
        step=5.0,
        help="Fields with confidence below this threshold will be highlighted for review"
    )
    
    # Update the session state if the value changed
    if confidence_threshold != st.session_state.confidence_threshold:
        st.session_state.confidence_threshold = confidence_threshold
        st.experimental_rerun()
    
    # Display the current mode
    st.sidebar.info(
        f"Current Mode: {'Editing' if st.session_state.editing_mode else 'Viewing'}\n\n"
        f"Confidence Threshold: {st.session_state.confidence_threshold}%"
    )
    
    # Toggle editing mode
    if st.sidebar.button("Toggle Editing Mode"):
        st.session_state.editing_mode = not st.session_state.editing_mode
        st.experimental_rerun()

def display_bulk_editing_interface(results_df):
    """
    Display a bulk editing interface for modifying multiple fields at once.
    """
    if results_df is None or results_df.empty:
        st.warning("No data available for bulk editing")
        return None
    
    st.subheader("Bulk Field Editing")
    
    # Allow user to edit the DataFrame directly
    edited_df = st.data_editor(
        results_df,
        use_container_width=True,
        num_rows="dynamic",
        key="bulk_editor",
        disabled=["Filename", "Page"]  # These columns cannot be edited
    )
    
    if st.button("Save Bulk Changes"):
        # Update the session state with the edited DataFrame
        st.session_state.edited_results_df = edited_df
        
        # Regenerate the PDF results from the edited DataFrame
        updated_pdf_results = update_pdf_results_from_dataframe(st.session_state.all_pdf_results, edited_df)
        st.session_state.all_pdf_results = updated_pdf_results
        
        st.success("Bulk changes saved successfully!")
    
    return edited_df

def main():
    st.set_page_config(
        page_title="PDF Financial Data Extractor",
        page_icon="üìä",
        layout="wide"
    )
    
    st.title("PDF Financial Data Extractor")
    st.subheader("Extract and Edit Invoice Data from PDF Files")
    
    # Check if Azure OpenAI credentials are available
    if not all([aoai_endpoint, aoai_api_key, aoai_deployment_name]):
        st.error("Azure OpenAI credentials are missing. Please set AOAI_ENDPOINT, AOAI_API_KEY, and AOAI_DEPLOYMENT environment variables.")
        return
    
    # Check if Azure Blob Storage credentials are available
    if not azure_storage_connection_string:
        st.warning("Azure Blob Storage connection string is missing. Some features will be disabled. Please set AZURE_STORAGE_CONNECTION_STRING environment variable.")
    
    # Initialize the clients
    client = get_client()
    blob_service_client = get_blob_service_client() if azure_storage_connection_string else None
    st.session_state.blob_service_client = blob_service_client
    
    # Display confidence settings in sidebar
    display_confidence_settings()
    
    # Create tabs for the main workflow
    main_tabs = st.tabs(["1. Extract Data", "2. Edit & Verify", "3. Export Results"])
    
    # Tab 1: Extract Data
    with main_tabs[0]:
        # Advanced settings in an expandable section
        with st.expander("Advanced Settings"):
            prompt = st.text_area(
                "Extraction Prompt", 
                """Based on this image, extract the following information from the invoice:   
                1) What is the vendor name?
                2) What is the invoice number?
                3) What is the invoice date?
                4) What is the customer name?
                5) What is the purchase order number?
                6) What is the stock code?
                7) What is the unit price?
                8) What is the invoice amount?
                9) What is the freight cost?
                10) What is the sales tax?
                11) What is the total amount?""",
                help="Customize the prompt sent to Azure OpenAI Vision to extract information"
            )
        
        # Input method selection
        input_method = st.radio(
            "Select Input Method",
            ["Upload Files", "Azure Blob Storage"],
            help="Choose how to input PDF files for processing",
            key="input_method_radio"
        )
        
        st.session_state.input_method = input_method
        files_to_process = None
        
        if input_method == "Upload Files":
            # File uploader
            uploaded_files = st.file_uploader(
                "Upload PDF files", 
                type="pdf", 
                accept_multiple_files=True,
                help="Upload one or more PDF files containing financial statements"
            )
            
            # Display previews in sidebar if files are uploaded
            if uploaded_files:
                display_pdf_previews_sidebar(uploaded_files)
            
            # Process button
            process_button = st.button("Process Documents", type="primary")
            
            if process_button and not uploaded_files:
                st.warning("Please upload at least one PDF file.")
                return
                
            files_to_process = uploaded_files if process_button else None
            
        else:  # Azure Blob Storage
            if not blob_service_client:
                st.error("Azure Blob Storage connection is required for this option. Please set AZURE_STORAGE_CONNECTION_STRING environment variable.")
                return
            
            # Get available containers
            containers = get_blob_containers(blob_service_client)
            
            if not containers:
                st.error("No containers found in the Azure Blob Storage account. Please create at least one container.")
                return
            
            # Container selection
            selected_container = st.selectbox(
                "Select Container",
                containers,
                help="Choose an Azure Blob Storage container"
            )
            
            st.session_state.selected_container = selected_container
            
            # Get folders in the selected container
            folders = get_blob_folders(blob_service_client, selected_container)
            
            # Folder selection
            selected_folder = st.selectbox(
                "Select Folder",
                folders,
                format_func=lambda x: "Root (No Folder)" if x == "" else x,
                help="Choose a folder within the container"
            )
            
            # List available PDFs
            pdf_blobs = list_pdf_blobs(blob_service_client, selected_container, selected_folder)
            
            if not pdf_blobs:
                st.warning(f"No PDF files found in the selected location. Please choose another container or folder.")
                return
            
            # Show available PDFs
            st.write(f"Found {len(pdf_blobs)} PDF files:")
            
            # Create columns for better display
            pdf_cols = st.columns(3)
            for i, pdf in enumerate(pdf_blobs):
                display_name = pdf.split('/')[-1]  # Remove folder path for display
                pdf_cols[i % 3].write(f"- {display_name}")
                if i >= 11:  # Limit display to avoid cluttering
                    pdf_cols[(i + 1) % 3].write("...")
                    break
            
            # Display previews in sidebar
            display_pdf_previews_sidebar(pdf_blobs, blob_service_client, selected_container)
            
            # Process button
            process_button = st.button("Process Blob Documents", type="primary")
            
            files_to_process = pdf_blobs if process_button else None
        
        # Save files to process in session state
        if files_to_process:
            st.session_state.files_to_process = files_to_process
        
        # Process files if requested
        if files_to_process:
            with st.spinner("Processing documents..."):
                # Create a container for the whole processing section
                processing_container = st.container()
                
                with processing_container:
                    # Store all PDF results
                    all_pdf_results = []
                    
                    # Create a timestamp for the filename
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    
                    # Process the PDFs based on input method
                    if input_method == "Upload Files":
                        # Process uploaded PDFs
                        progress_bar = st.progress(0)
                        progress_text = st.empty()
                        
                        # Process each uploaded PDF
                        for i, pdf_file in enumerate(files_to_process):
                            progress_text.text(f"Processing file {i+1}/{len(files_to_process)}: {pdf_file.name}")
                            
                            # Process the PDF and get results
                            pdf_result = process_pdf(
                                pdf_file, 
                                prompt, 
                                client, 
                                aoai_deployment_name,
                                progress_bar,
                                progress_text
                            )
                            
                            # Add to our collection of all PDF results
                            all_pdf_results.append(pdf_result)
                            
                            # Update overall progress
                            progress_bar.progress((i + 1) / len(files_to_process))
                            
                        progress_text.text("Processing complete!")
                        progress_bar.progress(1.0)
                    else:
                        # Process PDFs from Blob Storage
                        all_pdf_results = process_blob_pdfs(
                            blob_service_client,
                            selected_container,
                            files_to_process,
                            prompt,
                            client,
                            aoai_deployment_name
                        )
                    
                    # Save results to session state
                    st.session_state.all_pdf_results = all_pdf_results
                    
                    # Create a DataFrame view
                    if all_pdf_results:
                        try:
                            results_df = create_results_dataframe(all_pdf_results)
                            
                            if not results_df.empty:
                                # Save to session state
                                st.session_state.results_df = results_df
                                st.session_state.edited_results_df = results_df.copy()
                                
                                # Apply styling based on confidence threshold
                                styled_df = apply_confidence_highlighting(results_df, st.session_state.confidence_threshold)
                                
                                # Display the DataFrame
                                st.subheader("Extraction Results")
                                st.dataframe(styled_df, use_container_width=True)
                                
                                # Success message with instructions
                                st.success("‚úÖ Extraction complete! Navigate to the 'Edit & Verify' tab to review and correct any low-confidence fields.")
                            else:
                                st.warning("Could not create results table due to data format issues.")
                                
                        except Exception as e:
                            st.error(f"Error displaying results table: {e}")
                            st.info("Please try processing again with fewer documents to reduce memory usage.")
    
    # Tab 2: Edit & Verify
    with main_tabs[1]:
        if 'all_pdf_results' in st.session_state and st.session_state.all_pdf_results:
            # Show a message if no results have been extracted yet
            st.info("Select fields to edit based on confidence scores. Low confidence fields are highlighted in red.")
            
            # Create subtabs for different editing methods
            edit_tabs = st.tabs(["Form Editor", "Bulk Editor"])
            
            # Form Editor Tab
            with edit_tabs[0]:
                # Display the edit form for selected document and page
                edited_df = display_edit_form(
                    st.session_state.edited_results_df if 'edited_results_df' in st.session_state else st.session_state.results_df,
                    st.session_state.all_pdf_results,
                    st.session_state.current_pdf_index,
                    st.session_state.current_page_index
                )
                
                if edited_df is not None:
                    st.session_state.edited_results_df = edited_df
            
            # Bulk Editor Tab
            with edit_tabs[1]:
                # Display the bulk editing interface
                bulk_edited_df = display_bulk_editing_interface(
                    st.session_state.edited_results_df if 'edited_results_df' in st.session_state else st.session_state.results_df
                )
        else:
            st.warning("No extraction results to edit. Please go to the 'Extract Data' tab first to process your documents.")
    
    # Tab 3: Export Results
    with main_tabs[2]:
        if 'all_pdf_results' in st.session_state and st.session_state.all_pdf_results:
            st.subheader("Export Options")
            
            # Create a timestamp for filenames
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Update all_pdf_results from edited_results_df if available
            if 'edited_results_df' in st.session_state and st.session_state.edited_results_df is not None:
                all_pdf_results = update_pdf_results_from_dataframe(
                    st.session_state.all_pdf_results,
                    st.session_state.edited_results_df
                )
            else:
                all_pdf_results = st.session_state.all_pdf_results
            
            # Evaluation results
            evaluation_results = evaluate_extraction_results(all_pdf_results, st.session_state.confidence_threshold)
            
            # Create a quality report
            quality_cols = st.columns(3)
            
            with quality_cols[0]:
                st.metric(
                    "Overall Success Rate", 
                    f"{evaluation_results.get('success_rate', 0)}%",
                    help="Percentage of pages with all fields above confidence threshold"
                )
            
            with quality_cols[1]:
                st.metric(
                    "Overall Confidence Score", 
                    f"{evaluation_results.get('overall_confidence_score', 0)}%",
                    help="Average confidence across all fields"
                )
            
            with quality_cols[2]:
                st.metric(
                    "Documents with Issues", 
                    f"{len(evaluation_results.get('documents_with_errors', []))}",
                    help="Number of documents with fields below confidence threshold"
                )
            
            # Display documents needing verification
            docs_to_verify = evaluation_results.get('documents_with_errors', [])
            if docs_to_verify:
                st.subheader("Documents Needing Verification")
                for doc in docs_to_verify:
                    st.warning(f"‚ö†Ô∏è {doc} - Has fields with less than {st.session_state.confidence_threshold}% confidence")
            else:
                st.success("‚úÖ All documents have been verified")
            
            # Export options in three columns
            export_cols = st.columns(3)
            
            with export_cols[0]:
                # Create text files zip
                text_zip = create_text_files_zip(all_pdf_results)
                
                # Download text files button
                st.download_button(
                    label="Download Text Files (ZIP)",
                    data=text_zip,
                    file_name=f"extracted_data_{timestamp}.zip",
                    mime="application/zip",
                    help="Download all extraction results as individual text files in a ZIP archive"
                )
            
            with export_cols[1]:
                # Create a CSV of the results
                if 'edited_results_df' in st.session_state and not st.session_state.edited_results_df.empty:
                    try:
                        csv = st.session_state.edited_results_df.to_csv(index=False)
                        st.download_button(
                            label="Download CSV Results",
                            data=csv,
                            file_name=f"financial_data_extraction_{timestamp}.csv",
                            mime="text/csv",
                            help="Download all extraction results in CSV format"
                        )
                    except Exception as e:
                        st.error(f"Error creating CSV: {e}")
                        st.info("CSV download is unavailable due to an error.")
                else:
                    st.download_button(
                        label="Download CSV Results",
                        data="No data available",
                        file_name=f"financial_data_extraction_{timestamp}.csv",
                        mime="text/csv",
                        disabled=True
                    )
            
            with export_cols[2]:
                # Create a JSON file of all results
                try:
                    json_data = json.dumps(all_pdf_results, indent=2)
                    st.download_button(
                        label="Download JSON Results",
                        data=json_data,
                        file_name=f"financial_data_extraction_{timestamp}.json",
                        mime="application/json",
                        help="Download all extraction results in JSON format with confidence scores"
                    )
                except Exception as e:
                    st.error(f"Error creating JSON: {e}")
                    st.info("JSON download is unavailable due to an error.")
            
            # Azure Blob Storage upload options
            if blob_service_client:
                st.subheader("Upload Results to Azure Blob Storage")
                
                # Container selection for uploads
                upload_container = st.text_input(
                    "Output Container Name",
                    value=azure_storage_container_name,
                    help="Container where results will be uploaded (will be created if doesn't exist)"
                )
                
                # Upload button
                if st.button("Upload Results to Azure Blob Storage"):
                    with st.spinner("Uploading results..."):
                        upload_results = []
                        
                        # Upload CSV
                        if 'edited_results_df' in st.session_state and not st.session_state.edited_results_df.empty:
                            try:
                                csv_data = st.session_state.edited_results_df.to_csv(index=False)
                                csv_blob_name = f"extraction_results_{timestamp}.csv"
                                csv_success, csv_url = upload_to_blob_storage(
                                    blob_service_client,
                                    upload_container,
                                    csv_blob_name,
                                    csv_data,
                                    "text/csv"
                                )
                                upload_results.append({
                                    "file": csv_blob_name,
                                    "success": csv_success,
                                    "url": csv_url if csv_success else None
                                })
                            except Exception as e:
                                st.error(f"Error uploading CSV: {e}")
                        
                        # Upload JSON
                        try:
                            json_data = json.dumps(all_pdf_results, indent=2)
                            json_blob_name = f"extraction_results_{timestamp}.json"
                            json_success, json_url = upload_to_blob_storage(
                                blob_service_client,
                                upload_container,
                                json_blob_name,
                                json_data,
                                "application/json"
                            )
                            upload_results.append({
                                "file": json_blob_name,
                                "success": json_success,
                                "url": json_url if json_success else None
                            })
                        except Exception as e:
                            st.error(f"Error uploading JSON: {e}")
                        
                        # Upload ZIP with text files
                        try:
                            text_zip.seek(0)  # Reset position to the beginning
                            zip_blob_name = f"extraction_text_files_{timestamp}.zip"
                            zip_success, zip_url = upload_to_blob_storage(
                                blob_service_client,
                                upload_container,
                                zip_blob_name,
                                text_zip.read(),
                                "application/zip"
                            )
                            upload_results.append({
                                "file": zip_blob_name,
                                "success": zip_success,
                                "url": zip_url if zip_success else None
                            })
                        except Exception as e:
                            st.error(f"Error uploading ZIP: {e}")
                        
                        # Display upload results
                        st.subheader("Upload Results")
                        for result in upload_results:
                            if result["success"]:
                                st.success(f"‚úÖ {result['file']} uploaded successfully")
                            else:
                                st.error(f"‚ùå Failed to upload {result['file']}: {result['url']}")
        else:
            st.warning("No extraction results to export. Please go to the 'Extract Data' tab first to process your documents.")

if __name__ == "__main__":
    main()
