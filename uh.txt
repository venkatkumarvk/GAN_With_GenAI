#main.py


"""
MAIN PIPELINE - Document Extraction with Multimodal RAG
========================================================
Entry point. Run: python main.py
"""

import json
from datetime import datetime
from typing import List, Dict, Any

from helper import AzureBlobManager, AzureOpenAIManager, DocumentIntelligenceManager
from unified_rag import create_rag_extractor
from logging_config import (
    setup_logging, log_config, log_provider_start, log_document,
    log_ocr, log_vision, log_rag, log_extraction, log_error,
    log_provider_summary, log_outputs, log_complete
)


def load_config(path: str = "config.json") -> Dict[str, Any]:
    with open(path, 'r') as f:
        return json.load(f)


def process_provider(
    provider: str,
    documents: List[str],
    blob_mgr,
    doc_intel_mgr,
    openai_mgr,
    rag_extractor,
    config: Dict[str, Any]
) -> Dict[str, Any]:
    
    # Create index_name FIRST (before any usage)
    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    index_name = f"{provider.lower()}_{timestamp}"  # Use underscore, not dash
    
    print(f"\n{'='*60}\n  PROVIDER: {provider} ({len(documents)} docs)\n{'='*60}")
    log_provider_start(provider, len(documents), index_name)
    
    fields = config['fields']
    mode = config['rag']['mode']
    
    results = []
    total_cost = 0.0
    
    for idx, doc_name in enumerate(documents, 1):
        print(f"\n [{idx}/{len(documents)}] {doc_name}")
        log_document(idx, len(documents), doc_name)
        
        try:
            doc_bytes = blob_mgr.download_blob(doc_name)
            
            # Get file extension
            import os
            file_extension = os.path.splitext(doc_name)[1]  # e.g., '.pdf', '.jpg'
            
            # Convert to base64 for Document Intelligence
            import base64
            doc_base64 = base64.b64encode(doc_bytes).decode('utf-8')
            
            # OCR (PRIMARY)
            print(f"   üîç OCR...")
            log_ocr(0, 0)  # Start OCR logging
            ocr_result = doc_intel_mgr.analyze_document(doc_base64, file_extension)
            doc_text = ocr_result.get('content', '')
            
            if len(doc_text) < 50:
                print(f"   ‚ö†Ô∏è  Insufficient OCR - skip")
                log_error(doc_name, "Insufficient OCR text")
                continue
            
            print(f"   ‚úì OCR: {len(doc_text)} chars")
            log_ocr(len(doc_text), ocr_result.get('page_count', 1))
            
            # RAG Extraction
            if idx == 1:
                print(f"   üìÑ First doc - no RAG")
                if mode == 'multimodal':
                    result = rag_extractor.extract_without_rag(doc_text, doc_bytes, None, doc_name, provider, index_name)
                else:
                    result = rag_extractor.extract_without_rag(doc_text, None, doc_name, provider, index_name)
            else:
                print(f"   üìã RAG extraction...")
                if mode == 'multimodal':
                    result = rag_extractor.extract_with_rag(doc_text, doc_bytes, provider, index_name, doc_name)
                else:
                    result = rag_extractor.extract_with_rag(doc_text, provider, index_name, doc_name)
            
            extracted = result.get('extracted_fields', {})
            avg_conf = sum([f.get('confidence',0) for f in extracted.values() if isinstance(f,dict)]) / len(extracted) if extracted else 0
            
            print(f"   ‚úì Confidence: {avg_conf:.2f} | RAG: {result.get('used_rag')} | Vision: {result.get('has_vision')}")
            log_rag(result.get('used_rag', False), result.get('similar_docs_count', 0), mode, result.get('has_vision', False))
            log_extraction(extracted, avg_conf)
            
            results.append({
                'document_name': doc_name,
                'extracted_fields': extracted,
                'avg_confidence': avg_conf,
                'used_rag': result.get('used_rag', False),
                'has_vision': result.get('has_vision', False)
            })
            
            total_cost += 0.07 if mode == 'multimodal' else 0.05
            
        except Exception as e:
            print(f"   ‚ùå Error: {e}")
            log_error(doc_name, str(e))
    
    print(f"\n  ‚úì Processed: {len(results)}/{len(documents)} | Cost: ${total_cost:.2f}")
    log_provider_summary(provider, len(results), len(documents), total_cost)
    
    return {
        'provider': provider,
        'results': results,
        'total_cost': total_cost,
        'index_name': index_name
    }


def save_results(provider_results: Dict, blob_mgr, config: Dict):
    provider = provider_results['provider']
    results = provider_results['results']
    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    fields = config['fields']
    confidence_threshold = config.get('confidence_threshold', 0.90)
    
    # CSV - one row
    csv_lines = [','.join(['provider','doc_count'] + fields + ['avg_confidence'])]
    agg = {'provider': provider, 'doc_count': len(results)}
    
    for field in fields:
        for r in results:
            if field in r['extracted_fields']:
                fd = r['extracted_fields'][field]
                agg[field] = fd.get('value','') if isinstance(fd,dict) else str(fd)
                break
        if field not in agg:
            agg[field] = ''
    
    avg = sum([r['avg_confidence'] for r in results]) / len(results) if results else 0
    agg['avg_confidence'] = f"{avg:.2f}"
    
    csv_lines.append(','.join([agg.get('provider',''), str(agg.get('doc_count',0))] + [agg.get(f,'') for f in fields] + [agg.get('avg_confidence','0.00')]))
    
    # Determine confidence category
    confidence_category = "highconfidence" if avg >= confidence_threshold else "lowconfidence"
    
    # NEW FOLDER STRUCTURE: provider/subfolder/file
    # CSV: provider/processedcsvresult/
    csv_file = f"{provider}/processedcsvresult/{provider}_{timestamp}_{confidence_category}.csv"
    blob_mgr.upload_blob(csv_file, '\n'.join(csv_lines).encode('utf-8'))
    print(f"  ‚úì CSV: {csv_file}")
    
    # JSON detailed: provider/processedjsonresult/
    json_file = f"{provider}/processedjsonresult/{provider}_{timestamp}_{confidence_category}_detailed.json"
    blob_mgr.upload_blob(json_file, json.dumps(provider_results, indent=2).encode('utf-8'))
    print(f"  ‚úì JSON: {json_file}")
    
    # Costs: provider/estimatedcosttracking/
    cost_file = f"{provider}/estimatedcosttracking/{provider}_{timestamp}_costs.json"
    cost_data = {
        'provider': provider,
        'total_cost_usd': provider_results['total_cost'],
        'documents': len(results),
        'cost_per_doc': provider_results['total_cost']/len(results) if results else 0,
        'avg_confidence': avg,
        'confidence_category': confidence_category
    }
    blob_mgr.upload_blob(cost_file, json.dumps(cost_data, indent=2).encode('utf-8'))
    print(f"  ‚úì Costs: {cost_file}")
    print(f"  üìä Confidence: {avg:.2f} ‚Üí Category: {confidence_category}")
    log_outputs(csv_file, json_file, cost_file)


def main():
    # Setup logging FIRST
    log_file = setup_logging(log_dir="logs", log_level="INFO")
    
    print("\n" + "="*60)
    print("  MULTIMODAL RAG ‚Äî DOCUMENT EXTRACTION")
    print("  Healthcare / HIPAA ¬∑ Azure BAA")
    print("="*60)
    
    config = load_config()
    log_config(config)
    print(f"\n‚úì Config loaded | Fields: {', '.join(config['fields'])}")
    
    # Get RAG mode safely
    rag_mode = config.get('rag', {}).get('mode', 'text')
    print(f"‚úì RAG Mode: {rag_mode.upper()}")
    
    # Initialize managers
    blob_mgr = AzureBlobManager(
        config['AzureBlob']['connection_string'],
        config['AzureBlob']['inputcontainer'],
        config['AzureBlob']['outputcontainer']
    )
    print(f"‚úì Blob connected")
    
    openai_mgr = AzureOpenAIManager(
        config['AzureOpenAI']['endpoint'],
        config['AzureOpenAI']['api_key'],
        config['AzureOpenAI']['api_version'],
        config['AzureOpenAI']['deployment_name'],
        config['AzureEmbedding']['endpoint'],
        config['AzureEmbedding']['api_key'],
        config['AzureEmbedding'].get('api_version', config['AzureOpenAI']['api_version']),  # Use same version if not specified
        config['AzureEmbedding']['deployment_name'],
        config['AzureEmbedding'].get('dimension', 3072)  # Default to 3072
    )
    print(f"‚úì OpenAI connected")
    
    doc_intel_mgr = DocumentIntelligenceManager(
        config['DocumentIntelligence']['endpoint'],
        config['DocumentIntelligence']['key']
    )
    print(f"‚úì Doc Intelligence connected")
    
    rag_extractor = create_rag_extractor(
        config['rag'],
        config['AzureAISearch']['endpoint'],
        config['AzureAISearch']['api_key'],
        openai_mgr,
        config['fields']
    )
    print(f"‚úì RAG Extractor ready")
    
    # Get documents
    all_docs = blob_mgr.list_blobs()
    print(f"\n‚úì Found {len(all_docs)} documents")
    
    if not all_docs:
        print("\n‚ö†Ô∏è  No documents. Upload to input container and retry.")
        return
    
    # Group by provider
    providers = {}
    for doc in all_docs:
        prov = doc.split('_')[0] if '_' in doc else 'default'
        if prov not in providers:
            providers[prov] = []
        providers[prov].append(doc)
    
    print(f"‚úì Grouped into {len(providers)} providers")
    
    # Process each
    for prov, docs in providers.items():
        prov_results = process_provider(prov, docs, blob_mgr, doc_intel_mgr, openai_mgr, rag_extractor, config)
        save_results(prov_results, blob_mgr, config)
    
    print("\n" + "="*60)
    print("  COMPLETE ‚úì")
    print("="*60 + "\n")
    log_complete(len(providers), len(all_docs))


if __name__ == "__main__":
    main()

----



#doc

"""
DOCUMENT INTELLIGENCE OCR - Standalone OCR Module
==================================================

Complete Azure Document Intelligence OCR implementation.
Supports: PDF, Images (JPG, PNG, TIFF, BMP), Word documents (.doc, .docx)

Features:
- Automatic Word ‚Üí PDF conversion
- Retry logic with exponential backoff
- Multi-page document support
- Base64 input handling
- Page count tracking
- Comprehensive error handling

Usage:
    from document_intelligence_ocr import DocumentIntelligenceOCR
    
    ocr = DocumentIntelligenceOCR(endpoint, api_key)
    result = ocr.extract_text(base64_data, file_extension)
    
    text = result['content']
    pages = result['page_count']
"""

import base64
import logging
import os
import tempfile
from typing import Dict, Any, Optional
from tenacity import retry, stop_after_attempt, wait_exponential

from azure.core.credentials import AzureKeyCredential
from azure.ai.documentintelligence import DocumentIntelligenceClient

logger = logging.getLogger(__name__)


class DocumentIntelligenceOCR:
    """
    Azure Document Intelligence OCR Manager
    
    Extracts text from documents using Azure's prebuilt-read model.
    Handles multiple file formats with automatic conversion.
    """
    
    def __init__(self, endpoint: str, api_key: str):
        """
        Initialize Document Intelligence OCR client
        
        Args:
            endpoint: Azure Document Intelligence endpoint URL
            api_key: Azure Document Intelligence API key
        """
        self.endpoint = endpoint
        self.api_key = api_key
        
        self.client = DocumentIntelligenceClient(
            endpoint=endpoint,
            credential=AzureKeyCredential(api_key)
        )
        
        logger.info(f"DocumentIntelligenceOCR initialized | endpoint={endpoint}")
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
    def extract_text(
        self,
        base64_data: str,
        file_extension: str,
        convert_word: bool = True
    ) -> Dict[str, Any]:
        """
        Extract text from document using Azure Document Intelligence
        
        Args:
            base64_data: Base64-encoded document bytes
            file_extension: File extension (e.g., '.pdf', '.jpg', '.docx')
            convert_word: If True, auto-convert Word docs to PDF (default: True)
        
        Returns:
            Dictionary with:
            {
                'success': True/False,
                'content': 'Extracted text...',
                'page_count': 3,
                'error': 'Error message if failed'
            }
        
        Raises:
            Exception: If OCR fails after 3 retry attempts
        """
        try:
            file_ext = file_extension.lower()
            
            # Handle Word documents - convert to PDF first
            if file_ext in ['.doc', '.docx'] and convert_word:
                logger.info(f"Converting {file_ext} to PDF for OCR processing")
                result = self._convert_word_to_pdf(base64_data, file_ext)
                
                if result['success']:
                    base64_data = result['pdf_base64']
                    file_ext = '.pdf'
                    logger.info("Word document converted to PDF successfully")
                else:
                    # Fallback: Try direct text extraction from Word
                    logger.warning("PDF conversion failed, attempting direct Word text extraction")
                    return self._extract_text_from_word(base64_data, file_ext)
            
            # Validate file type
            supported_types = ['.pdf', '.jpg', '.jpeg', '.png', '.tiff', '.tif', '.bmp']
            if file_ext not in supported_types:
                error_msg = f"Unsupported file type: {file_ext}. Supported: {supported_types}"
                logger.error(error_msg)
                return {
                    'success': False,
                    'content': '',
                    'page_count': 0,
                    'error': error_msg
                }
            
            # Perform OCR using Azure Document Intelligence
            logger.info(f"Starting OCR analysis for {file_ext} file")
            
            # Call Document Intelligence (prebuilt-read model) - CORRECT FORMAT
            poller = self.client.begin_analyze_document(
                model_id="prebuilt-read",
                analyze_request={"base64Source": base64_data}  # Correct format!
            )
            
            # Wait for result
            result = poller.result()
            
            # Extract text content
            content = result.content if hasattr(result, 'content') else ''
            
            # Get page count
            page_count = len(result.pages) if hasattr(result, 'pages') else 0
            
            # Log success
            logger.info(
                f"OCR completed successfully | "
                f"chars={len(content)} | pages={page_count}"
            )
            
            return {
                'success': True,
                'content': content,
                'page_count': page_count,
                'error': None
            }
            
        except Exception as e:
            error_msg = f"OCR extraction failed: {str(e)}"
            logger.error(error_msg, exc_info=True)
            return {
                'success': False,
                'content': '',
                'page_count': 0,
                'error': error_msg
            }
    
    def _convert_word_to_pdf(
        self,
        base64_data: str,
        file_extension: str
    ) -> Dict[str, Any]:
        """
        Convert Word document to PDF
        
        Args:
            base64_data: Base64-encoded Word document
            file_extension: '.doc' or '.docx'
        
        Returns:
            Dictionary with:
            {
                'success': True/False,
                'pdf_base64': 'base64-encoded PDF',
                'error': 'Error message if failed'
            }
        """
        try:
            # Try using docx2pdf (Windows/Mac)
            try:
                from docx2pdf import convert as docx_to_pdf_convert
                
                # Decode base64 to bytes
                document_bytes = base64.b64decode(base64_data)
                
                # Create temporary files
                with tempfile.NamedTemporaryFile(
                    suffix=file_extension,
                    delete=False
                ) as temp_word:
                    temp_word.write(document_bytes)
                    temp_word_path = temp_word.name
                
                temp_pdf_path = temp_word_path.replace(file_extension, '.pdf')
                
                # Convert to PDF
                docx_to_pdf_convert(temp_word_path, temp_pdf_path)
                
                # Read PDF and encode to base64
                with open(temp_pdf_path, 'rb') as pdf_file:
                    pdf_bytes = pdf_file.read()
                    pdf_base64 = base64.b64encode(pdf_bytes).decode('utf-8')
                
                # Clean up temp files
                os.remove(temp_word_path)
                os.remove(temp_pdf_path)
                
                logger.info("Word to PDF conversion successful (docx2pdf)")
                
                return {
                    'success': True,
                    'pdf_base64': pdf_base64,
                    'error': None
                }
                
            except ImportError:
                logger.warning("docx2pdf not installed, trying alternative method")
                
                # Alternative: Use LibreOffice (Linux)
                try:
                    import subprocess
                    
                    document_bytes = base64.b64decode(base64_data)
                    
                    with tempfile.NamedTemporaryFile(
                        suffix=file_extension,
                        delete=False
                    ) as temp_word:
                        temp_word.write(document_bytes)
                        temp_word_path = temp_word.name
                    
                    temp_dir = os.path.dirname(temp_word_path)
                    
                    # Convert using LibreOffice
                    subprocess.run(
                        [
                            'libreoffice',
                            '--headless',
                            '--convert-to',
                            'pdf',
                            '--outdir',
                            temp_dir,
                            temp_word_path
                        ],
                        check=True,
                        capture_output=True
                    )
                    
                    # Read converted PDF
                    pdf_path = temp_word_path.replace(file_extension, '.pdf')
                    
                    with open(pdf_path, 'rb') as pdf_file:
                        pdf_bytes = pdf_file.read()
                        pdf_base64 = base64.b64encode(pdf_bytes).decode('utf-8')
                    
                    # Clean up
                    os.remove(temp_word_path)
                    os.remove(pdf_path)
                    
                    logger.info("Word to PDF conversion successful (LibreOffice)")
                    
                    return {
                        'success': True,
                        'pdf_base64': pdf_base64,
                        'error': None
                    }
                    
                except Exception as e:
                    error_msg = f"LibreOffice conversion failed: {str(e)}"
                    logger.error(error_msg)
                    return {
                        'success': False,
                        'pdf_base64': '',
                        'error': error_msg
                    }
                    
        except Exception as e:
            error_msg = f"Word to PDF conversion failed: {str(e)}"
            logger.error(error_msg, exc_info=True)
            return {
                'success': False,
                'pdf_base64': '',
                'error': error_msg
            }
    
    def _extract_text_from_word(
        self,
        base64_data: str,
        file_extension: str
    ) -> Dict[str, Any]:
        """
        Fallback: Extract text directly from Word document
        
        Args:
            base64_data: Base64-encoded Word document
            file_extension: '.doc' or '.docx'
        
        Returns:
            Dictionary with extracted text
        """
        try:
            from docx import Document
            import io
            
            logger.info("Attempting direct text extraction from Word document")
            
            # Decode base64
            document_bytes = base64.b64decode(base64_data)
            
            # Load Word document
            doc = Document(io.BytesIO(document_bytes))
            
            # Extract all text from paragraphs
            text_parts = []
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    text_parts.append(paragraph.text)
            
            # Extract text from tables
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        if cell.text.strip():
                            text_parts.append(cell.text)
            
            content = '\n'.join(text_parts)
            
            logger.info(
                f"Direct Word text extraction successful | "
                f"chars={len(content)}"
            )
            
            return {
                'success': True,
                'content': content,
                'page_count': 1,  # Approximate
                'error': None
            }
            
        except ImportError:
            error_msg = "python-docx not installed. Cannot extract text from Word."
            logger.error(error_msg)
            return {
                'success': False,
                'content': '',
                'page_count': 0,
                'error': error_msg
            }
            
        except Exception as e:
            error_msg = f"Direct Word text extraction failed: {str(e)}"
            logger.error(error_msg, exc_info=True)
            return {
                'success': False,
                'content': '',
                'page_count': 0,
                'error': error_msg
            }
    
    def extract_from_file(self, file_path: str) -> Dict[str, Any]:
        """
        Extract text from a file on disk
        
        Args:
            file_path: Path to the file
        
        Returns:
            Dictionary with extraction results
        """
        try:
            # Read file
            with open(file_path, 'rb') as f:
                file_bytes = f.read()
            
            # Encode to base64
            base64_data = base64.b64encode(file_bytes).decode('utf-8')
            
            # Get extension
            file_extension = os.path.splitext(file_path)[1]
            
            # Extract text
            return self.extract_text(base64_data, file_extension)
            
        except Exception as e:
            error_msg = f"Failed to read file {file_path}: {str(e)}"
            logger.error(error_msg)
            return {
                'success': False,
                'content': '',
                'page_count': 0,
                'error': error_msg
            }
    
    def extract_from_bytes(
        self,
        file_bytes: bytes,
        file_extension: str
    ) -> Dict[str, Any]:
        """
        Extract text from bytes
        
        Args:
            file_bytes: Document bytes
            file_extension: File extension (e.g., '.pdf')
        
        Returns:
            Dictionary with extraction results
        """
        try:
            # Encode to base64
            base64_data = base64.b64encode(file_bytes).decode('utf-8')
            
            # Extract text
            return self.extract_text(base64_data, file_extension)
            
        except Exception as e:
            error_msg = f"Failed to process bytes: {str(e)}"
            logger.error(error_msg)
            return {
                'success': False,
                'content': '',
                'page_count': 0,
                'error': error_msg
            }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# USAGE EXAMPLES
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

"""
# Example 1: Extract from base64 string
from document_intelligence_ocr import DocumentIntelligenceOCR

ocr = DocumentIntelligenceOCR(
    endpoint="https://YOUR_ENDPOINT.cognitiveservices.azure.com/",
    api_key="YOUR_API_KEY"
)

# Base64-encoded PDF
result = ocr.extract_text(base64_pdf_data, '.pdf')

if result['success']:
    print(f"Extracted text: {result['content'][:200]}...")
    print(f"Pages: {result['page_count']}")
else:
    print(f"Error: {result['error']}")


# Example 2: Extract from file path
result = ocr.extract_from_file('/path/to/document.pdf')
print(result['content'])


# Example 3: Extract from bytes
with open('document.jpg', 'rb') as f:
    file_bytes = f.read()

result = ocr.extract_from_bytes(file_bytes, '.jpg')
print(result['content'])


# Example 4: Word document (auto-converts to PDF)
result = ocr.extract_text(base64_docx_data, '.docx')
# Automatically converts .docx ‚Üí PDF ‚Üí OCR


# Example 5: Error handling
result = ocr.extract_text(invalid_data, '.xyz')
if not result['success']:
    print(f"OCR failed: {result['error']}")
"""



-----


#main.py

"""
MAIN PIPELINE - Document Extraction with Multimodal RAG
========================================================
Entry point. Run: python main.py
"""

import json
from datetime import datetime
from typing import List, Dict, Any

from helper import AzureBlobManager, AzureOpenAIManager, DocumentIntelligenceManager
from unified_rag import create_rag_extractor
from logging_config import (
    setup_logging, log_config, log_provider_start, log_document,
    log_ocr, log_vision, log_rag, log_extraction, log_error,
    log_provider_summary, log_outputs, log_complete
)


def load_config(path: str = "config.json") -> Dict[str, Any]:
    with open(path, 'r') as f:
        return json.load(f)


def process_provider(
    provider: str,
    documents: List[str],
    blob_mgr,
    doc_intel_mgr,
    openai_mgr,
    rag_extractor,
    config: Dict[str, Any]
) -> Dict[str, Any]:
    
    # Create index_name FIRST (before any usage)
    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    index_name = f"{provider.lower()}_{timestamp}"  # Use underscore, not dash
    
    print(f"\n{'='*60}\n  PROVIDER: {provider} ({len(documents)} docs)\n{'='*60}")
    log_provider_start(provider, len(documents), index_name)
    
    fields = config['fields']
    mode = config['rag']['mode']
    
    results = []
    total_cost = 0.0
    
    for idx, doc_name in enumerate(documents, 1):
        print(f"\n [{idx}/{len(documents)}] {doc_name}")
        log_document(idx, len(documents), doc_name)
        
        try:
            doc_bytes = blob_mgr.download_blob(doc_name)
            
            # Get file extension
            import os
            file_extension = os.path.splitext(doc_name)[1]  # e.g., '.pdf', '.jpg'
            
            # Convert to base64 for Document Intelligence
            import base64
            doc_base64 = base64.b64encode(doc_bytes).decode('utf-8')
            
            # OCR (PRIMARY)
            print(f"   üîç OCR...")
            log_ocr(0, 0)  # Start OCR logging
            ocr_result = doc_intel_mgr.analyze_document(doc_base64, file_extension)
            doc_text = ocr_result.get('content', '')
            
            if len(doc_text) < 50:
                print(f"   ‚ö†Ô∏è  Insufficient OCR - skip")
                log_error(doc_name, "Insufficient OCR text")
                continue
            
            print(f"   ‚úì OCR: {len(doc_text)} chars")
            log_ocr(len(doc_text), ocr_result.get('page_count', 1))
            
            # RAG Extraction
            if idx == 1:
                print(f"   üìÑ First doc - no RAG")
                if mode == 'multimodal':
                    result = rag_extractor.extract_without_rag(doc_text, doc_bytes, None, doc_name, provider, index_name)
                else:
                    result = rag_extractor.extract_without_rag(doc_text, None, doc_name, provider, index_name)
            else:
                print(f"   üìã RAG extraction...")
                if mode == 'multimodal':
                    result = rag_extractor.extract_with_rag(doc_text, doc_bytes, provider, index_name, doc_name)
                else:
                    result = rag_extractor.extract_with_rag(doc_text, provider, index_name, doc_name)
            
            extracted = result.get('extracted_fields', {})
            avg_conf = sum([f.get('confidence',0) for f in extracted.values() if isinstance(f,dict)]) / len(extracted) if extracted else 0
            
            print(f"   ‚úì Confidence: {avg_conf:.2f} | RAG: {result.get('used_rag')} | Vision: {result.get('has_vision')}")
            log_rag(result.get('used_rag', False), result.get('similar_docs_count', 0), mode, result.get('has_vision', False))
            log_extraction(extracted, avg_conf)
            
            results.append({
                'document_name': doc_name,
                'extracted_fields': extracted,
                'avg_confidence': avg_conf,
                'used_rag': result.get('used_rag', False),
                'has_vision': result.get('has_vision', False)
            })
            
            total_cost += 0.07 if mode == 'multimodal' else 0.05
            
        except Exception as e:
            print(f"   ‚ùå Error: {e}")
            log_error(doc_name, str(e))
    
    print(f"\n  ‚úì Processed: {len(results)}/{len(documents)} | Cost: ${total_cost:.2f}")
    log_provider_summary(provider, len(results), len(documents), total_cost)
    
    return {
        'provider': provider,
        'results': results,
        'total_cost': total_cost,
        'index_name': index_name
    }


def save_results(provider_results: Dict, blob_mgr, config: Dict):
    provider = provider_results['provider']
    results = provider_results['results']
    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    fields = config['fields']
    confidence_threshold = config.get('confidence_threshold', 0.90)
    
    # CSV - one row
    csv_lines = [','.join(['provider','doc_count'] + fields + ['avg_confidence'])]
    agg = {'provider': provider, 'doc_count': len(results)}
    
    for field in fields:
        for r in results:
            if field in r['extracted_fields']:
                fd = r['extracted_fields'][field]
                agg[field] = fd.get('value','') if isinstance(fd,dict) else str(fd)
                break
        if field not in agg:
            agg[field] = ''
    
    avg = sum([r['avg_confidence'] for r in results]) / len(results) if results else 0
    agg['avg_confidence'] = f"{avg:.2f}"
    
    csv_lines.append(','.join([agg.get('provider',''), str(agg.get('doc_count',0))] + [agg.get(f,'') for f in fields] + [agg.get('avg_confidence','0.00')]))
    
    # Determine confidence category
    confidence_category = "highconfidence" if avg >= confidence_threshold else "lowconfidence"
    
    # NEW FOLDER STRUCTURE: provider/subfolder/file
    # CSV: provider/processedcsvresult/
    csv_file = f"{provider}/processedcsvresult/{provider}_{timestamp}_{confidence_category}.csv"
    blob_mgr.upload_blob(csv_file, '\n'.join(csv_lines).encode('utf-8'))
    print(f"  ‚úì CSV: {csv_file}")
    
    # JSON detailed: provider/processedjsonresult/
    json_file = f"{provider}/processedjsonresult/{provider}_{timestamp}_{confidence_category}_detailed.json"
    blob_mgr.upload_blob(json_file, json.dumps(provider_results, indent=2).encode('utf-8'))
    print(f"  ‚úì JSON: {json_file}")
    
    # Costs: provider/estimatedcosttracking/
    cost_file = f"{provider}/estimatedcosttracking/{provider}_{timestamp}_costs.json"
    cost_data = {
        'provider': provider,
        'total_cost_usd': provider_results['total_cost'],
        'documents': len(results),
        'cost_per_doc': provider_results['total_cost']/len(results) if results else 0,
        'avg_confidence': avg,
        'confidence_category': confidence_category
    }
    blob_mgr.upload_blob(cost_file, json.dumps(cost_data, indent=2).encode('utf-8'))
    print(f"  ‚úì Costs: {cost_file}")
    print(f"  üìä Confidence: {avg:.2f} ‚Üí Saved to '{folder}/' folder")
    log_outputs(csv_file, json_file, cost_file)


def main():
    # Setup logging FIRST
    log_file = setup_logging(log_dir="logs", log_level="INFO")
    
    print("\n" + "="*60)
    print("  MULTIMODAL RAG ‚Äî DOCUMENT EXTRACTION")
    print("  Healthcare / HIPAA ¬∑ Azure BAA")
    print("="*60)
    
    config = load_config()
    log_config(config)
    print(f"\n‚úì Config loaded | Fields: {', '.join(config['fields'])}")
    
    # Get RAG mode safely
    rag_mode = config.get('rag', {}).get('mode', 'text')
    print(f"‚úì RAG Mode: {rag_mode.upper()}")
    
    # Initialize managers
    blob_mgr = AzureBlobManager(
        config['AzureBlob']['connection_string'],
        config['AzureBlob']['inputcontainer'],
        config['AzureBlob']['outputcontainer']
    )
    print(f"‚úì Blob connected")
    
    openai_mgr = AzureOpenAIManager(
        config['AzureOpenAI']['endpoint'],
        config['AzureOpenAI']['api_key'],
        config['AzureOpenAI']['api_version'],
        config['AzureOpenAI']['deployment_name'],
        config['AzureEmbedding']['endpoint'],
        config['AzureEmbedding']['api_key'],
        config['AzureEmbedding'].get('api_version', config['AzureOpenAI']['api_version']),  # Use same version if not specified
        config['AzureEmbedding']['deployment_name'],
        config['AzureEmbedding'].get('dimension', 3072)  # Default to 3072
    )
    print(f"‚úì OpenAI connected")
    
    doc_intel_mgr = DocumentIntelligenceManager(
        config['DocumentIntelligence']['endpoint'],
        config['DocumentIntelligence']['key']
    )
    print(f"‚úì Doc Intelligence connected")
    
    rag_extractor = create_rag_extractor(
        config['rag'],
        config['AzureAISearch']['endpoint'],
        config['AzureAISearch']['api_key'],
        openai_mgr,
        config['fields']
    )
    print(f"‚úì RAG Extractor ready")
    
    # Get documents
    all_docs = blob_mgr.list_blobs()
    print(f"\n‚úì Found {len(all_docs)} documents")
    
    if not all_docs:
        print("\n‚ö†Ô∏è  No documents. Upload to input container and retry.")
        return
    
    # Group by provider
    providers = {}
    for doc in all_docs:
        prov = doc.split('_')[0] if '_' in doc else 'default'
        if prov not in providers:
            providers[prov] = []
        providers[prov].append(doc)
    
    print(f"‚úì Grouped into {len(providers)} providers")
    
    # Process each
    for prov, docs in providers.items():
        prov_results = process_provider(prov, docs, blob_mgr, doc_intel_mgr, openai_mgr, rag_extractor, config)
        save_results(prov_results, blob_mgr, config)
    
    print("\n" + "="*60)
    print("  COMPLETE ‚úì")
    print("="*60 + "\n")
    log_complete(len(providers), len(all_docs))


if __name__ == "__main__":
    main()


----

text.py

"""
TEXT RAG - Text-Only Document Extraction
=========================================

OCR text is PRIMARY source.
Uses Azure AI Search vector search to find similar past documents.
Passes them as few-shot examples to GPT-4o for extraction.

DO NOT EDIT - Stable code
Users configure via config.json
"""

import json
import logging
from typing import List, Dict, Any, Optional

from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential

from prompt_builder import ExtractionPromptBuilder

logger = logging.getLogger(__name__)


class TextRAGExtractor:
    """
    Text-Only RAG Extractor

    Flow:
        Document ‚Üí OCR (primary) ‚Üí Embed ‚Üí Search Similar ‚Üí GPT-4o Extract

    Mode: Fast, cost-effective, 92-95% accuracy
    """

    def __init__(
        self,
        search_endpoint: str,
        search_api_key: str,
        openai_manager,
        fields: List[str],
        top_k: int = 3,
        similarity_threshold: float = 0.7
    ):
        """
        Args:
            search_endpoint:      Azure AI Search endpoint
            search_api_key:       Azure AI Search API key
            openai_manager:       AzureOpenAIManager instance
            fields:               List of fields to extract (from config.json)
            top_k:                Number of similar documents to retrieve
            similarity_threshold: Minimum similarity score (0.0 - 1.0)
        """
        self.search_endpoint      = search_endpoint
        self.search_credential    = AzureKeyCredential(search_api_key)
        self.openai_manager       = openai_manager
        self.fields               = fields
        self.top_k                = top_k
        self.similarity_threshold = similarity_threshold

        self.prompt_builder = ExtractionPromptBuilder(fields)

        logger.info(f"TextRAGExtractor ready | top_k={top_k} | threshold={similarity_threshold}")
        print(f"    ‚úì RAG Mode : TEXT-ONLY")
        print(f"    ‚úì Vision   : Disabled")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # PUBLIC: Extract with RAG
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def extract_with_rag(
        self,
        document_text: str,
        provider: str,
        index_name: str,
        source_document: str,
        document_type: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Extract fields using Text RAG pipeline

        Args:
            document_text:   OCR text from document (PRIMARY)
            provider:        Provider name
            index_name:      Azure AI Search index name
            source_document: Source filename
            document_type:   Document type hint (passport, license, id_card)

        Returns:
            {
              success, extracted_fields, source_document,
              used_rag, similar_docs_count, embeddings
            }
        """
        logger.info(f"Text RAG extraction | doc={source_document} | provider={provider}")

        # Step 1 ‚Äî Generate text embedding (OCR is primary)
        embedding = self.openai_manager.generate_embeddings(document_text)
        logger.info("  ‚úì Text embedding generated")

        # Step 2 ‚Äî Search similar documents
        similar_docs = self._search_similar(embedding, provider, index_name)

        # Step 3 ‚Äî Build prompt
        if similar_docs:
            print(f"    ‚úì RAG context  : {len(similar_docs)} similar documents found")
            logger.info(f"  ‚úì {len(similar_docs)} similar docs retrieved")
            user_prompt = self._build_rag_prompt(document_text, similar_docs)
        else:
            print(f"    ‚ö† RAG context  : No similar documents (first doc or below threshold)")
            logger.info("  ‚ö† No similar docs ‚Äî standard extraction")
            user_prompt = self._build_standard_prompt(document_text)

        # Step 4 ‚Äî GPT-4o extraction
        extracted_fields = self._call_gpt(user_prompt, document_type)
        
        # Step 5 ‚Äî Store in Azure AI Search for future RAG
        confidences = [f.get('confidence', 0.0) for f in extracted_fields.values() if isinstance(f, dict)]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
        
        self._store_in_index(
            index_name=index_name,
            document_name=source_document,
            provider=provider,
            document_text=document_text,
            text_embedding=text_emb,
            extracted_fields=extracted_fields,
            avg_confidence=avg_confidence
        )

        return {
            'success':           True,
            'extracted_fields':  extracted_fields,
            'source_document':   source_document,
            'mode':              'text',
            'used_rag':          len(similar_docs) > 0,
            'similar_docs_count': len(similar_docs),
            'has_vision':        False,
            'visual_description': '',
            'embeddings': {
                'text':     embedding,
                'visual':   None,
                'combined': embedding   # combined = text in text-only mode
            }
        }

    def extract_without_rag(
        self,
        document_text: str,
        document_type: Optional[str] = None,
        source_document: str = '',
        provider: str = '',
        index_name: str = ''
    ) -> Dict[str, Any]:
        """
        Extract without RAG ‚Äî used for first document or fallback

        Args:
            document_text:   OCR text (PRIMARY)
            document_type:   Document type hint
            source_document: Source filename
            provider:        Provider name (for storage)
            index_name:      Index name (for storage)

        Returns:
            Same shape as extract_with_rag
        """
        logger.info(f"Text extraction (no RAG) | doc={source_document}")

        embedding   = self.openai_manager.generate_embeddings(document_text)
        user_prompt = self._build_standard_prompt(document_text)
        extracted_fields = self._call_gpt(user_prompt, document_type)
        
        # Store in index for future RAG (if provider/index provided)
        if provider and index_name:
            confidences = [f.get('confidence', 0.0) for f in extracted_fields.values() if isinstance(f, dict)]
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
            
            self._store_in_index(
                index_name=index_name,
                document_name=source_document,
                provider=provider,
                document_text=document_text,
                text_embedding=embedding,
                extracted_fields=extracted_fields,
                avg_confidence=avg_confidence
            )

        return {
            'success':           True,
            'extracted_fields':  extracted_fields,
            'source_document':   source_document,
            'mode':              'text',
            'used_rag':          False,
            'similar_docs_count': 0,
            'has_vision':        False,
            'visual_description': '',
            'embeddings': {
                'text':     embedding,
                'visual':   None,
                'combined': embedding
            }
        }

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # PRIVATE HELPERS
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def _store_in_index(
        self,
        index_name: str,
        document_name: str,
        provider: str,
        document_text: str,
        text_embedding: List[float],
        extracted_fields: Dict[str, Any],
        avg_confidence: float
    ):
        """
        Store document in Azure AI Search index for future RAG
        """
        try:
            from azure.search.documents.indexes import SearchIndexClient
            from azure.search.documents.indexes.models import (
                SearchIndex, SearchField, SearchFieldDataType,
                VectorSearch, HnswAlgorithmConfiguration, VectorSearchProfile
            )
            
            # Create index if not exists
            index_client = SearchIndexClient(
                endpoint=self.search_endpoint,
                credential=self.search_credential
            )
            
            try:
                index_client.get_index(index_name)
                logger.info(f"  Index '{index_name}' exists")
            except:
                logger.info(f"  Creating index '{index_name}'...")
                
                fields = [
                    SearchField(name="id", type=SearchFieldDataType.String, key=True, filterable=True),
                    SearchField(name="document_name", type=SearchFieldDataType.String, filterable=True, sortable=True),
                    SearchField(name="provider", type=SearchFieldDataType.String, filterable=True),
                    SearchField(name="content", type=SearchFieldDataType.String, searchable=True),
                    SearchField(name="extracted_fields", type=SearchFieldDataType.String),
                    SearchField(name="avg_confidence", type=SearchFieldDataType.Double, filterable=True, sortable=True),
                    SearchField(
                        name="content_vector",
                        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
                        vector_search_dimensions=3072,
                        vector_search_profile_name="text-profile"
                    )
                ]
                
                vector_search = VectorSearch(
                    algorithms=[HnswAlgorithmConfiguration(name="hnsw-config")],
                    profiles=[VectorSearchProfile(name="text-profile", algorithm_configuration_name="hnsw-config")]
                )
                
                index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)
                index_client.create_index(index)
                logger.info(f"  ‚úì Index '{index_name}' created")
            
            # Upload document
            doc_client = SearchClient(
                endpoint=self.search_endpoint,
                index_name=index_name,
                credential=self.search_credential
            )
            
            doc_id = f"{provider}_{document_name}".replace('.', '_').replace('/', '_').replace('-', '_')[:512]
            
            document = {
                "id": doc_id,
                "document_name": document_name,
                "provider": provider,
                "content": document_text[:50000],
                "extracted_fields": json.dumps(extracted_fields),
                "avg_confidence": avg_confidence,
                "content_vector": text_embedding
            }
            
            doc_client.upload_documents([document])
            logger.info(f"  ‚úì Stored in index: {doc_id}")
            
        except Exception as e:
            logger.error(f"Failed to store in index: {e}", exc_info=True)

    def _search_similar(
        self,
        embedding: List[float],
        provider: str,
        index_name: str
    ) -> List[Dict[str, Any]]:
        """Search Azure AI Search for similar documents"""
        try:
            client = SearchClient(
                endpoint=self.search_endpoint,
                index_name=index_name,
                credential=self.search_credential
            )

            results = client.search(
                search_text=None,
                vector_queries=[{
                    "kind":   "vector",
                    "vector": embedding,
                    "fields": "content_vector",
                    "k":      self.top_k
                }],
                filter=f"provider eq '{provider}'",
                select=["document_name", "content", "extracted_fields", "avg_confidence"]
            )

            docs = [
                r for r in results
                if r.get('@search.score', 0.0) >= self.similarity_threshold
            ]

            logger.info(f"  Search: {len(docs)} docs above threshold={self.similarity_threshold}")
            return docs

        except Exception as e:
            logger.error(f"Search failed: {e}", exc_info=True)
            return []

    def _build_rag_prompt(
        self,
        document_text: str,
        similar_docs: List[Dict[str, Any]]
    ) -> str:
        """Build user prompt with RAG few-shot examples"""
        parts = []

        parts.append(f"Reference examples from {len(similar_docs)} similar documents:")
        parts.append("")

        for idx, doc in enumerate(similar_docs[:self.top_k], 1):
            score = doc.get('@search.score', 0.0)
            name  = doc.get('document_name', f'Document {idx}')
            parts.append(f"EXAMPLE {idx}  (similarity: {score:.2f})")
            parts.append(f"Document : {name}")

            raw = doc.get('extracted_fields', '{}')
            try:
                fields = json.loads(raw) if isinstance(raw, str) else raw
                parts.append("Extracted:")
                parts.append(json.dumps(fields, indent=2))
            except Exception:
                pass
            parts.append("")

        parts.append("‚îÄ" * 60)
        parts.append("NOW EXTRACT FROM THIS NEW DOCUMENT:")
        parts.append("")
        parts.append("OCR TEXT (Primary Source):")
        parts.append(document_text[:8000])
        parts.append("")
        parts.append(f"Fields to extract : {', '.join(self.fields)}")
        parts.append("Return ONLY a JSON object with field values and confidence scores.")

        return "\n".join(parts)

    def _build_standard_prompt(self, document_text: str) -> str:
        """Build standard prompt without RAG context"""
        return (
            f"Extract the following fields from this document:\n\n"
            f"OCR TEXT (Primary Source):\n{document_text[:8000]}\n\n"
            f"Fields to extract: {', '.join(self.fields)}\n\n"
            "Return ONLY a JSON object with field values and confidence scores."
        )

    def _call_gpt(
        self,
        user_prompt: str,
        document_type: Optional[str]
    ) -> Dict[str, Any]:
        """Call GPT-4o and return parsed extraction result"""
        try:
            system_prompt = self.prompt_builder.build_system_prompt(
                document_type=document_type
            )

            response = self.openai_manager.gpt_client.chat.completions.create(
                model=self.openai_manager.deployment_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user",   "content": user_prompt}
                ],
                temperature=0.0,
                max_tokens=2000
            )

            # Track tokens
            if hasattr(response, 'usage'):
                self.openai_manager.prompt_tokens     += response.usage.prompt_tokens
                self.openai_manager.completion_tokens += response.usage.completion_tokens
                self.openai_manager.total_tokens      += response.usage.total_tokens

            return self._parse_response(response.choices[0].message.content)

        except Exception as e:
            logger.error(f"GPT call failed: {e}", exc_info=True)
            return {}

    def _parse_response(self, text: str) -> Dict[str, Any]:
        """Parse GPT-4o JSON response"""
        try:
            clean = text.strip()
            if clean.startswith("```"):
                clean = clean.split("```")[1]
                if clean.startswith("json"):
                    clean = clean[4:]
            return json.loads(clean.strip())
        except json.JSONDecodeError as e:
            logger.error(f"JSON parse error: {e} | text: {text[:300]}")
            return {}


-----


multimodal

"""
MULTIMODAL RAG - Vision + Text Document Extraction
====================================================

OCR text is PRIMARY source.
Vision (GPT-4 Vision) is SUPPLEMENTARY enhancement.
Combined embedding (text + visual) improves RAG similarity search.

DO NOT EDIT - Stable code
Users configure via config.json
"""

import base64
import json
import logging
from typing import Dict, Any, List, Optional, Tuple

from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential

from prompt_builder import ExtractionPromptBuilder

logger = logging.getLogger(__name__)


class MultimodalRAGExtractor:
    """
    Multimodal RAG Extractor ‚Äî Text + Vision

    Flow:
        Document ‚Üí OCR (primary)       ‚Üí Text Embed   ‚îÄ‚îê
                 ‚Üí Vision (supplement) ‚Üí Visual Embed ‚îÄ‚î§ ‚Üí Combined ‚Üí Search ‚Üí GPT-4o
                                                       ‚îÄ‚îò

    Mode: Higher accuracy (95-97%), 100% coverage (handles image-only docs)
    """

    def __init__(
        self,
        search_endpoint: str,
        search_api_key: str,
        openai_manager,
        fields: List[str],
        top_k: int = 3,
        similarity_threshold: float = 0.7,
        text_weight: float = 0.7,
        visual_weight: float = 0.3
    ):
        """
        Args:
            search_endpoint:      Azure AI Search endpoint
            search_api_key:       Azure AI Search API key
            openai_manager:       AzureOpenAIManager instance
            fields:               List of fields to extract (from config.json)
            top_k:                Number of similar documents to retrieve
            similarity_threshold: Minimum similarity score (0.0 - 1.0)
            text_weight:          Weight for text embedding in combined vector (default 0.7)
            visual_weight:        Weight for visual embedding in combined vector (default 0.3)
        """
        self.search_endpoint      = search_endpoint
        self.search_credential    = AzureKeyCredential(search_api_key)
        self.openai_manager       = openai_manager
        self.fields               = fields
        self.top_k                = top_k
        self.similarity_threshold = similarity_threshold
        self.text_weight          = text_weight
        self.visual_weight        = visual_weight

        self.prompt_builder = ExtractionPromptBuilder(fields)

        logger.info(
            f"MultimodalRAGExtractor ready | "
            f"top_k={top_k} | text_w={text_weight} | visual_w={visual_weight}"
        )
        print(f"    ‚úì RAG Mode : MULTIMODAL (Text + Vision)")
        print(f"    ‚úì Vision   : Enabled")
        print(f"    ‚úì Weights  : text={text_weight} | visual={visual_weight}")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # PUBLIC: Extract with RAG
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def extract_with_rag(
        self,
        document_text: str,
        image_bytes: bytes,
        provider: str,
        index_name: str,
        source_document: str,
        document_type: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Extract fields using Multimodal RAG pipeline

        Args:
            document_text:   OCR text from document (PRIMARY)
            image_bytes:     Raw image bytes for vision analysis
            provider:        Provider name
            index_name:      Azure AI Search index name
            source_document: Source filename
            document_type:   Document type hint (passport, license, id_card)

        Returns:
            {
              success, extracted_fields, source_document,
              used_rag, similar_docs_count, has_vision,
              visual_description, embeddings
            }
        """
        logger.info(f"Multimodal RAG | doc={source_document} | provider={provider}")

        # Step 1 ‚Äî Vision analysis (supplementary)
        visual_description = ''
        if image_bytes:
            print(f"    üîç Vision analysis (supplementary)...")
            result = self._analyze_vision(image_bytes, document_type)
            if result['success']:
                visual_description = result['visual_description']
                print(f"    ‚úì Vision       : {len(visual_description)} chars")
                logger.info(f"  ‚úì Vision complete ({len(visual_description)} chars)")
            else:
                print(f"    ‚ö† Vision failed ‚Äî OCR only (primary)")
                logger.warning(f"  ‚ö† Vision failed: {result.get('error')}")
        else:
            print(f"    ‚ö† No image bytes ‚Äî OCR only (primary)")

        # Step 2 ‚Äî Generate embeddings
        text_emb, visual_emb, combined_emb = self._generate_embeddings(
            document_text, visual_description
        )
        emb_mode = "text + visual" if visual_description else "text only (vision unavailable)"
        print(f"    ‚úì Embeddings   : {emb_mode}")
        logger.info(f"  ‚úì Embeddings generated: {emb_mode}")

        # Step 3 ‚Äî Search similar documents
        similar_docs = self._search_similar(combined_emb, provider, index_name)

        # Step 4 ‚Äî Build prompt
        if similar_docs:
            print(f"    ‚úì RAG context  : {len(similar_docs)} similar documents found")
            logger.info(f"  ‚úì {len(similar_docs)} similar docs retrieved")
            user_prompt = self._build_rag_prompt(document_text, visual_description, similar_docs)
        else:
            print(f"    ‚ö† RAG context  : No similar documents (first doc or below threshold)")
            logger.info("  ‚ö† No similar docs ‚Äî standard extraction")
            user_prompt = self._build_standard_prompt(document_text, visual_description)

        # Step 5 ‚Äî GPT-4o extraction
        extracted_fields = self._call_gpt(user_prompt, document_type)
        
        # Step 6 ‚Äî Store in Azure AI Search for future RAG
        confidences = [f.get('confidence', 0.0) for f in extracted_fields.values() if isinstance(f, dict)]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
        
        self._store_in_index(
            index_name=index_name,
            document_name=source_document,
            provider=provider,
            document_text=document_text,
            visual_description=visual_description,
            combined_embedding=combined_emb,
            extracted_fields=extracted_fields,
            avg_confidence=avg_confidence
        )

        return {
            'success':            True,
            'extracted_fields':   extracted_fields,
            'source_document':    source_document,
            'mode':               'multimodal',
            'used_rag':           len(similar_docs) > 0,
            'similar_docs_count': len(similar_docs),
            'has_vision':         bool(visual_description),
            'visual_description': visual_description,
            'embeddings': {
                'text':     text_emb,
                'visual':   visual_emb,
                'combined': combined_emb
            }
        }

    def extract_without_rag(
        self,
        document_text: str,
        image_bytes: Optional[bytes] = None,
        document_type: Optional[str] = None,
        source_document: str = '',
        provider: str = '',
        index_name: str = ''
    ) -> Dict[str, Any]:
        """
        Extract without RAG ‚Äî first document or fallback

        Args:
            document_text:   OCR text (PRIMARY)
            image_bytes:     Image bytes for vision (optional)
            document_type:   Document type hint
            source_document: Source filename
            provider:        Provider name (for storage)
            index_name:      Index name (for storage)
        """
        logger.info(f"Multimodal extraction (no RAG) | doc={source_document}")

        visual_description = ''
        if image_bytes:
            result = self._analyze_vision(image_bytes, document_type)
            if result['success']:
                visual_description = result['visual_description']

        text_emb, visual_emb, combined_emb = self._generate_embeddings(
            document_text, visual_description
        )

        user_prompt      = self._build_standard_prompt(document_text, visual_description)
        extracted_fields = self._call_gpt(user_prompt, document_type)
        
        # Store in index for future RAG (if provider/index provided)
        if provider and index_name:
            confidences = [f.get('confidence', 0.0) for f in extracted_fields.values() if isinstance(f, dict)]
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
            
            self._store_in_index(
                index_name=index_name,
                document_name=source_document,
                provider=provider,
                document_text=document_text,
                visual_description=visual_description,
                combined_embedding=combined_emb,
                extracted_fields=extracted_fields,
                avg_confidence=avg_confidence
            )

        return {
            'success':            True,
            'extracted_fields':   extracted_fields,
            'source_document':    source_document,
            'mode':               'multimodal',
            'used_rag':           False,
            'similar_docs_count': 0,
            'has_vision':         bool(visual_description),
            'visual_description': visual_description,
            'embeddings': {
                'text':     text_emb,
                'visual':   visual_emb,
                'combined': combined_emb
            }
        }

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # PRIVATE HELPERS
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def _analyze_vision(
        self,
        image_bytes: bytes,
        document_type: Optional[str] = None
    ) -> Dict[str, Any]:
        """Analyze document image using GPT-4 Vision"""
        try:
            b64 = base64.b64encode(image_bytes).decode('utf-8')

            type_hints = {
                'passport': "\n\nFocus on: MRZ zone, country emblem, biographical page layout.",
                'license':  "\n\nFocus on: License number position, photo, endorsements.",
                'id_card':  "\n\nFocus on: ID number placement, official seals, front/back layout."
            }
            doc_hint = type_hints.get(document_type, '') if document_type else ''

            prompt = (
                "Analyze this identity document image and describe:\n"
                "1. Document type and layout\n"
                "2. Security features (holograms, watermarks, seals)\n"
                "3. Document condition and image quality\n"
                "4. Photo position and quality\n"
                "5. Any notable visual elements or anomalies\n\n"
                "Keep description concise (max 400 chars) ‚Äî it supplements OCR text."
                + doc_hint
            )

            response = self.openai_manager.gpt_client.chat.completions.create(
                model=self.openai_manager.deployment_name,
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url":    f"data:image/jpeg;base64,{b64}",
                                "detail": "high"
                            }
                        }
                    ]
                }],
                max_tokens=500,
                temperature=0.0
            )

            if hasattr(response, 'usage'):
                self.openai_manager.prompt_tokens     += response.usage.prompt_tokens
                self.openai_manager.completion_tokens += response.usage.completion_tokens
                self.openai_manager.total_tokens      += response.usage.total_tokens

            return {
                'success':            True,
                'visual_description': response.choices[0].message.content
            }

        except Exception as e:
            logger.error(f"Vision analysis failed: {e}", exc_info=True)
            return {'success': False, 'visual_description': '', 'error': str(e)}

    def _generate_embeddings(
        self,
        document_text: str,
        visual_description: str
    ) -> Tuple[List[float], Optional[List[float]], List[float]]:
        """
        Generate text, visual, and combined embeddings

        Returns:
            (text_embedding, visual_embedding_or_None, combined_embedding)
        """
        text_emb = self.openai_manager.generate_embeddings(document_text)

        if visual_description:
            visual_emb   = self.openai_manager.generate_embeddings(visual_description)
            combined_emb = [
                self.text_weight * text_emb[i] + self.visual_weight * visual_emb[i]
                for i in range(len(text_emb))
            ]
            return text_emb, visual_emb, combined_emb
        else:
            return text_emb, None, text_emb   # fallback: combined = text

    def _search_similar(
        self,
        combined_embedding: List[float],
        provider: str,
        index_name: str
    ) -> List[Dict[str, Any]]:
        """Search Azure AI Search using combined embedding"""
        try:
            client = SearchClient(
                endpoint=self.search_endpoint,
                index_name=index_name,
                credential=self.search_credential
            )

            results = client.search(
                search_text=None,
                vector_queries=[{
                    "kind":   "vector",
                    "vector": combined_embedding,
                    "fields": "content_vector",
                    "k":      self.top_k
                }],
                filter=f"provider eq '{provider}'",
                select=[
                    "document_name", "content",
                    "extracted_fields", "visual_description", "avg_confidence"
                ]
            )

            docs = [
                r for r in results
                if r.get('@search.score', 0.0) >= self.similarity_threshold
            ]

            logger.info(f"  Search: {len(docs)} docs above threshold={self.similarity_threshold}")
            return docs

        except Exception as e:
            logger.error(f"Search failed: {e}", exc_info=True)
            return []

    def _store_in_index(
        self,
        index_name: str,
        document_name: str,
        provider: str,
        document_text: str,
        visual_description: str,
        combined_embedding: List[float],
        extracted_fields: Dict[str, Any],
        avg_confidence: float
    ):
        """
        Store document in Azure AI Search index for future RAG
        
        Creates index if doesn't exist, then uploads document
        """
        try:
            from azure.search.documents.indexes import SearchIndexClient
            from azure.search.documents.indexes.models import (
                SearchIndex, SearchField, SearchFieldDataType,
                VectorSearch, HnswAlgorithmConfiguration, VectorSearchProfile
            )
            
            # Create index if not exists
            index_client = SearchIndexClient(
                endpoint=self.search_endpoint,
                credential=self.search_credential
            )
            
            try:
                index_client.get_index(index_name)
                logger.info(f"  Index '{index_name}' exists")
            except:
                logger.info(f"  Creating index '{index_name}'...")
                
                fields = [
                    SearchField(name="id", type=SearchFieldDataType.String, key=True, filterable=True),
                    SearchField(name="document_name", type=SearchFieldDataType.String, filterable=True, sortable=True),
                    SearchField(name="provider", type=SearchFieldDataType.String, filterable=True),
                    SearchField(name="content", type=SearchFieldDataType.String, searchable=True),
                    SearchField(name="visual_description", type=SearchFieldDataType.String, searchable=True),
                    SearchField(name="extracted_fields", type=SearchFieldDataType.String),
                    SearchField(name="avg_confidence", type=SearchFieldDataType.Double, filterable=True, sortable=True),
                    SearchField(
                        name="content_vector",
                        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
                        vector_search_dimensions=3072,
                        vector_search_profile_name="multimodal-profile"
                    )
                ]
                
                vector_search = VectorSearch(
                    algorithms=[HnswAlgorithmConfiguration(name="hnsw-config")],
                    profiles=[VectorSearchProfile(name="multimodal-profile", algorithm_configuration_name="hnsw-config")]
                )
                
                index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)
                index_client.create_index(index)
                logger.info(f"  ‚úì Index '{index_name}' created")
            
            # Upload document
            doc_client = SearchClient(
                endpoint=self.search_endpoint,
                index_name=index_name,
                credential=self.search_credential
            )
            
            doc_id = f"{provider}_{document_name}".replace('.', '_').replace('/', '_').replace('-', '_')[:512]
            
            document = {
                "id": doc_id,
                "document_name": document_name,
                "provider": provider,
                "content": document_text[:50000],  # Limit size
                "visual_description": visual_description,
                "extracted_fields": json.dumps(extracted_fields),
                "avg_confidence": avg_confidence,
                "content_vector": combined_embedding
            }
            
            doc_client.upload_documents([document])
            logger.info(f"  ‚úì Stored in index: {doc_id}")
            
        except Exception as e:
            logger.error(f"Failed to store in index: {e}", exc_info=True)

    def _build_rag_prompt(
        self,
        document_text: str,
        visual_description: str,
        similar_docs: List[Dict[str, Any]]
    ) -> str:
        """Build prompt with RAG few-shot examples + visual context"""
        parts = []

        parts.append(f"Reference examples from {len(similar_docs)} similar documents:")
        parts.append("")

        for idx, doc in enumerate(similar_docs[:self.top_k], 1):
            score = doc.get('@search.score', 0.0)
            name  = doc.get('document_name', f'Document {idx}')
            parts.append(f"EXAMPLE {idx}  (similarity: {score:.2f})")
            parts.append(f"Document : {name}")

            raw = doc.get('extracted_fields', '{}')
            try:
                fields = json.loads(raw) if isinstance(raw, str) else raw
                parts.append("Extracted:")
                parts.append(json.dumps(fields, indent=2))
            except Exception:
                pass

            visual_ctx = doc.get('visual_description', '')
            if visual_ctx:
                parts.append(f"Visual   : {visual_ctx[:150]}")

            parts.append("")

        parts.append("‚îÄ" * 60)
        parts.append("NOW EXTRACT FROM THIS NEW DOCUMENT:")
        parts.append("")

        parts.append("OCR TEXT (Primary Source):")
        parts.append(document_text[:7000])
        parts.append("")

        if visual_description:
            parts.append("VISUAL ANALYSIS (Supplementary):")
            parts.append(visual_description)
            parts.append("")

        parts.append(f"Fields to extract : {', '.join(self.fields)}")
        parts.append("Return ONLY a JSON object with field values and confidence scores.")

        return "\n".join(parts)

    def _build_standard_prompt(
        self,
        document_text: str,
        visual_description: str
    ) -> str:
        """Standard prompt (no RAG) with optional visual context"""
        parts = [
            "Extract the following fields from this document:",
            "",
            "OCR TEXT (Primary Source):",
            document_text[:7000],
            ""
        ]
        if visual_description:
            parts += ["VISUAL ANALYSIS (Supplementary):", visual_description, ""]

        parts += [
            f"Fields to extract: {', '.join(self.fields)}",
            "Return ONLY a JSON object with field values and confidence scores."
        ]
        return "\n".join(parts)

    def _call_gpt(
        self,
        user_prompt: str,
        document_type: Optional[str]
    ) -> Dict[str, Any]:
        """Call GPT-4o and return parsed extraction"""
        try:
            system_prompt = self.prompt_builder.build_system_prompt(
                document_type=document_type
            )
            response = self.openai_manager.gpt_client.chat.completions.create(
                model=self.openai_manager.deployment_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user",   "content": user_prompt}
                ],
                temperature=0.0,
                max_tokens=2000
            )

            if hasattr(response, 'usage'):
                self.openai_manager.prompt_tokens     += response.usage.prompt_tokens
                self.openai_manager.completion_tokens += response.usage.completion_tokens
                self.openai_manager.total_tokens      += response.usage.total_tokens

            return self._parse_response(response.choices[0].message.content)

        except Exception as e:
            logger.error(f"GPT call failed: {e}", exc_info=True)
            return {}

    def _parse_response(self, text: str) -> Dict[str, Any]:
        """Parse GPT-4o JSON response"""
        try:
            clean = text.strip()
            if clean.startswith("```"):
                clean = clean.split("```")[1]
                if clean.startswith("json"):
                    clean = clean[4:]
            return json.loads(clean.strip())
        except json.JSONDecodeError as e:
            logger.error(f"JSON parse error: {e} | text: {text[:300]}")
            return {}
