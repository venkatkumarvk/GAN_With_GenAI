"""
MAIN PIPELINE - Document Extraction with Multimodal RAG
========================================================
Entry point. Run: python main.py
"""

import json
from datetime import datetime
from typing import List, Dict, Any

from helper import AzureBlobManager, AzureOpenAIManager, DocumentIntelligenceManager
from unified_rag import create_rag_extractor
from logging_config import (
    setup_logging, log_config, log_provider_start, log_document,
    log_ocr, log_vision, log_rag, log_extraction, log_error,
    log_provider_summary, log_outputs, log_complete
)


def load_config(path: str = "config.json") -> Dict[str, Any]:
    with open(path, 'r') as f:
        return json.load(f)


def process_provider(
    provider: str,
    documents: List[str],
    blob_mgr,
    doc_intel_mgr,
    openai_mgr,
    rag_extractor,
    config: Dict[str, Any]
) -> Dict[str, Any]:
    
    # Create index_name FIRST (before any usage)
    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    index_name = f"{provider.lower()}_{timestamp}"  # Use underscore, not dash
    
    print(f"\n{'='*60}\n  PROVIDER: {provider} ({len(documents)} docs)\n{'='*60}")
    log_provider_start(provider, len(documents), index_name)
    
    fields = config['fields']
    mode = config['rag']['mode']
    
    results = []
    total_cost = 0.0
    
    for idx, doc_name in enumerate(documents, 1):
        print(f"\n [{idx}/{len(documents)}] {doc_name}")
        log_document(idx, len(documents), doc_name)
        
        try:
            doc_bytes = blob_mgr.download_blob(doc_name)
            
            # Get file extension
            import os
            file_extension = os.path.splitext(doc_name)[1]  # e.g., '.pdf', '.jpg'
            
            # Convert to base64 for Document Intelligence
            import base64
            doc_base64 = base64.b64encode(doc_bytes).decode('utf-8')
            
            # OCR (PRIMARY)
            print(f"   üîç OCR...")
            log_ocr(0, 0)  # Start OCR logging
            ocr_result = doc_intel_mgr.analyze_document(doc_base64, file_extension)
            
            # Check if OCR was successful
            if not ocr_result.get('success', False):
                print(f"   ‚ùå OCR failed: {ocr_result.get('error', 'Unknown error')}")
                log_error(doc_name, f"OCR failed: {ocr_result.get('error', 'Unknown error')}")
                continue
            
            doc_text = ocr_result.get('content', '')
            
            # Lower threshold to 10 chars (allow photos with minimal text)
            if len(doc_text) < 10:
                print(f"   ‚ö†Ô∏è  Insufficient OCR ({len(doc_text)} chars) - skip")
                log_error(doc_name, f"Insufficient OCR text: {len(doc_text)} chars")
                continue
            
            print(f"   ‚úì OCR: {len(doc_text)} chars")
            log_ocr(len(doc_text), ocr_result.get('page_count', 1))
            
            # RAG Extraction
            if idx == 1:
                print(f"   üìÑ First doc - no RAG")
                if mode == 'multimodal':
                    result = rag_extractor.extract_without_rag(doc_text, doc_bytes, None, doc_name, provider, index_name)
                else:
                    result = rag_extractor.extract_without_rag(doc_text, None, doc_name, provider, index_name)
            else:
                print(f"   üìã RAG extraction...")
                if mode == 'multimodal':
                    result = rag_extractor.extract_with_rag(doc_text, doc_bytes, provider, index_name, doc_name)
                else:
                    result = rag_extractor.extract_with_rag(doc_text, provider, index_name, doc_name)
            
            extracted = result.get('extracted_fields', {})
            avg_conf = sum([f.get('confidence',0) for f in extracted.values() if isinstance(f,dict)]) / len(extracted) if extracted else 0
            
            print(f"   ‚úì Confidence: {avg_conf:.2f} | RAG: {result.get('used_rag')} | Vision: {result.get('has_vision')}")
            log_rag(result.get('used_rag', False), result.get('similar_docs_count', 0), mode, result.get('has_vision', False))
            log_extraction(extracted, avg_conf)
            
            results.append({
                'document_name': doc_name,
                'extracted_fields': extracted,
                'avg_confidence': avg_conf,
                'used_rag': result.get('used_rag', False),
                'has_vision': result.get('has_vision', False)
            })
            
            total_cost += 0.07 if mode == 'multimodal' else 0.05
            
        except Exception as e:
            print(f"   ‚ùå Error: {e}")
            log_error(doc_name, str(e))
    
    print(f"\n  ‚úì Processed: {len(results)}/{len(documents)} | Cost: ${total_cost:.2f}")
    log_provider_summary(provider, len(results), len(documents), total_cost)
    
    return {
        'provider': provider,
        'results': results,
        'total_cost': total_cost,
        'index_name': index_name
    }


def save_results(provider_results: Dict, blob_mgr, config: Dict):
    provider = provider_results['provider']
    results = provider_results['results']
    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    fields = config['fields']
    confidence_threshold = config.get('confidence_threshold', 0.90)
    
    # NEW CSV STRUCTURE: field, field_confidence, field_document for EACH field
    # Header: provider, doc_count, name, name_confidence, name_document, passport, passport_confidence, passport_document, ...
    csv_header = ['provider', 'doc_count']
    for field in fields:
        csv_header.append(field)
        csv_header.append(f"{field}_confidence")
        csv_header.append(f"{field}_document")  # Which document this field came from
    csv_header.append('min_confidence')
    
    csv_lines = [','.join(csv_header)]
    
    # Aggregate data from first successful extraction
    agg = {'provider': provider, 'doc_count': len(results)}
    
    # Extract field values, confidences, AND source documents
    for field in fields:
        for r in results:
            if field in r['extracted_fields']:
                fd = r['extracted_fields'][field]
                doc_name = r.get('document_name', r.get('source_document', 'unknown'))
                
                if isinstance(fd, dict):
                    agg[field] = fd.get('value', '')
                    agg[f"{field}_confidence"] = f"{fd.get('confidence', 0.0):.2f}"
                    agg[f"{field}_document"] = doc_name  # Source document
                else:
                    agg[field] = str(fd)
                    agg[f"{field}_confidence"] = "0.00"
                    agg[f"{field}_document"] = doc_name
                break
        if field not in agg:
            agg[field] = ''
            agg[f"{field}_confidence"] = '0.00'
            agg[f"{field}_document"] = ''
    
    # Calculate minimum field confidence
    min_confidences = []
    for r in results:
        field_confidences = [
            f.get('confidence', 0.0) 
            for f in r['extracted_fields'].values() 
            if isinstance(f, dict)
        ]
        if field_confidences:
            min_confidences.append(min(field_confidences))
    
    min_confidence = min(min_confidences) if min_confidences else 0
    agg['min_confidence'] = f"{min_confidence:.2f}"
    
    # Also calculate average confidence for reporting only (NOT used for categorization)
    avg_confidence = sum([r['avg_confidence'] for r in results]) / len(results) if results else 0
    
    # Build CSV row: provider, doc_count, field1, field1_conf, field1_doc, field2, field2_conf, field2_doc, ...
    csv_row = [agg.get('provider', ''), str(agg.get('doc_count', 0))]
    for field in fields:
        csv_row.append(agg.get(field, ''))
        csv_row.append(agg.get(f"{field}_confidence", '0.00'))
        csv_row.append(agg.get(f"{field}_document", ''))
    csv_row.append(agg.get('min_confidence', '0.00'))
    
    csv_lines.append(','.join(csv_row))
    
    # Determine confidence category using MINIMUM field confidence (NOT average!)
    confidence_category = "highconfidence" if min_confidence >= confidence_threshold else "lowconfidence"
    
    # NEW FOLDER STRUCTURE: confidence/provider/subfolder/
    # CSV: highconfidence/ProviderA/processedcsvresult/
    csv_file = f"{confidence_category}/{provider}/processedcsvresult/{provider}_{timestamp}.csv"
    blob_mgr.upload_blob(csv_file, '\n'.join(csv_lines).encode('utf-8'))
    print(f"  ‚úì CSV: {csv_file}")
    
    # JSON detailed: highconfidence/ProviderA/processedjsonresult/
    json_file = f"{confidence_category}/{provider}/processedjsonresult/{provider}_{timestamp}_detailed.json"
    blob_mgr.upload_blob(json_file, json.dumps(provider_results, indent=2).encode('utf-8'))
    print(f"  ‚úì JSON: {json_file}")
    
    # Costs: highconfidence/ProviderA/estimatedcosttracking/
    cost_file = f"{confidence_category}/{provider}/estimatedcosttracking/{provider}_{timestamp}_costs.json"
    cost_data = {
        'provider': provider,
        'total_cost_usd': provider_results['total_cost'],
        'documents': len(results),
        'cost_per_doc': provider_results['total_cost']/len(results) if results else 0,
        'min_confidence': min_confidence,
        'avg_confidence': avg_confidence,
        'confidence_category': confidence_category,
        'categorization_method': 'minimum_field_confidence'
    }
    blob_mgr.upload_blob(cost_file, json.dumps(cost_data, indent=2).encode('utf-8'))
    print(f"  ‚úì Costs: {cost_file}")
    print(f"  üìä Min Confidence: {min_confidence:.2f} | Avg: {avg_confidence:.2f} ‚Üí Category: {confidence_category}")
    log_outputs(csv_file, json_file, cost_file)


def main():
    # Setup logging FIRST
    log_file = setup_logging(log_dir="logs", log_level="INFO")
    
    print("\n" + "="*60)
    print("  MULTIMODAL RAG ‚Äî DOCUMENT EXTRACTION")
    print("  Healthcare / HIPAA ¬∑ Azure BAA")
    print("="*60)
    
    config = load_config()
    log_config(config)
    print(f"\n‚úì Config loaded | Fields: {', '.join(config['fields'])}")
    
    # Get RAG mode safely
    rag_mode = config.get('rag', {}).get('mode', 'text')
    print(f"‚úì RAG Mode: {rag_mode.upper()}")
    
    # Initialize managers
    blob_mgr = AzureBlobManager(
        config['AzureBlob']['connection_string'],
        config['AzureBlob']['inputcontainer'],
        config['AzureBlob']['outputcontainer']
    )
    print(f"‚úì Blob connected")
    
    openai_mgr = AzureOpenAIManager(
        config['AzureOpenAI']['endpoint'],
        config['AzureOpenAI']['api_key'],
        config['AzureOpenAI']['api_version'],
        config['AzureOpenAI']['deployment_name'],
        config['AzureEmbedding']['endpoint'],
        config['AzureEmbedding']['api_key'],
        config['AzureEmbedding'].get('api_version', config['AzureOpenAI']['api_version']),  # Use same version if not specified
        config['AzureEmbedding']['deployment_name'],
        config['AzureEmbedding'].get('dimension', 3072)  # Default to 3072
    )
    print(f"‚úì OpenAI connected")
    
    doc_intel_mgr = DocumentIntelligenceManager(
        config['DocumentIntelligence']['endpoint'],
        config['DocumentIntelligence']['key']
    )
    print(f"‚úì Doc Intelligence connected")
    
    rag_extractor = create_rag_extractor(
        config['rag'],
        config['AzureAISearch']['endpoint'],
        config['AzureAISearch']['api_key'],
        openai_mgr,
        config['fields']
    )
    print(f"‚úì RAG Extractor ready")
    
    # Get documents
    all_docs = blob_mgr.list_blobs()
    print(f"\n‚úì Found {len(all_docs)} documents")
    
    if not all_docs:
        print("\n‚ö†Ô∏è  No documents. Upload to input container and retry.")
        return
    
    # Group by provider
    providers = {}
    provider_detection_log = []  # Debug log
    
    for doc in all_docs:
        # Try multiple provider detection methods:
        # 1. If has folder: "ProviderA/file.pdf" ‚Üí ProviderA
        # 2. If has underscore: "ProviderA_file.pdf" ‚Üí ProviderA
        # 3. Otherwise: Use first word of filename
        
        original_doc = doc
        
        if '/' in doc:
            # Has folder path - BEST indicator
            prov = doc.split('/')[0]
        elif '_' in doc and len(doc.split('_')[0]) > 2:
            # Has underscore with meaningful prefix
            prov = doc.split('_')[0]
        else:
            # Use first word of filename (before space or entire name)
            base = doc.split('.')[0]  # Remove extension
            prov = base.split()[0] if ' ' in base else base
        
        # Sanitize provider name (Azure AI Search index name compatible)
        # Index names: lowercase letters, digits, dash only
        import re
        original_prov = prov
        prov = re.sub(r'[^a-zA-Z0-9\-]', '', prov.lower())  # Remove invalid chars
        prov = prov.strip('-')  # Remove leading/trailing dashes
        
        # If sanitization resulted in empty or very short string, use a default
        if not prov or len(prov) < 2:
            prov = 'provider'  # Single default provider for all unclear cases
        
        provider_detection_log.append(f"{original_doc[:50]} ‚Üí {prov}")
        
        if prov not in providers:
            providers[prov] = []
        providers[prov].append(doc)
    
    print(f"‚úì Grouped into {len(providers)} providers: {list(providers.keys())}")
    
    # If only unclear files, warn user
    if list(providers.keys()) == ['provider']:
        print(f"  ‚ö†Ô∏è  Warning: All files grouped under 'provider' (no clear naming pattern)")
        print(f"  üí° Tip: Use folder structure (Provider/file.pdf) or prefix (Provider_file.pdf)")
    
    # Track statistics
    stats = {
        'total_providers': len(providers),
        'total_documents': len(all_docs),
        'processed_providers': 0,
        'unprocessed_providers': 0,
        'processed_documents': 0,
        'failed_documents': 0,
        'ocr_success': 0,
        'ocr_failed': 0,
        'embedding_success': 0,
        'azure_ai_search_stored': 0,
        'gpt_extraction_success': 0,
        'gpt_extraction_failed': 0,
        'highconfidence_count': 0,
        'lowconfidence_count': 0,
        'total_cost': 0.0
    }
    
    # Process each provider
    for prov, docs in providers.items():
        try:
            prov_results = process_provider(prov, docs, blob_mgr, doc_intel_mgr, openai_mgr, rag_extractor, config)
            save_results(prov_results, blob_mgr, config)
            
            # Update stats
            stats['processed_providers'] += 1
            stats['processed_documents'] += len(prov_results.get('results', []))
            stats['total_cost'] += prov_results.get('total_cost', 0.0)
            
            # Count confidence categories
            for result in prov_results.get('results', []):
                if result.get('avg_confidence', 0) >= config.get('confidence_threshold', 0.90):
                    stats['highconfidence_count'] += 1
                else:
                    stats['lowconfidence_count'] += 1
            
        except Exception as e:
            stats['unprocessed_providers'] += 1
            print(f"\n‚ùå Error processing provider {prov}: {e}")
            continue
    
    # Estimate stats (since we don't track each individually in current code)
    # These are based on successful provider processing
    stats['ocr_success'] = stats['processed_documents']
    stats['embedding_success'] = stats['processed_documents']
    stats['azure_ai_search_stored'] = stats['processed_documents']
    stats['gpt_extraction_success'] = stats['processed_documents']
    stats['failed_documents'] = stats['total_documents'] - stats['processed_documents']
    
    # Print Final Summary
    print("\n" + "="*70)
    print("  FINAL SUMMARY - PIPELINE EXECUTION REPORT")
    print("="*70)
    
    print(f"\nüìä PROVIDER STATISTICS:")
    print(f"  Total Providers:      {stats['total_providers']}")
    print(f"  ‚úÖ Processed:          {stats['processed_providers']}")
    print(f"  ‚ùå Unprocessed:        {stats['unprocessed_providers']}")
    
    print(f"\nüìÑ DOCUMENT STATISTICS:")
    print(f"  Total Documents:      {stats['total_documents']}")
    print(f"  ‚úÖ Processed:          {stats['processed_documents']}")
    print(f"  ‚ùå Failed:             {stats['failed_documents']}")
    
    print(f"\nüîç OCR (Document Intelligence):")
    print(f"  ‚úÖ Success:            {stats['ocr_success']}")
    print(f"  ‚ùå Failed:             {stats['ocr_failed']}")
    
    print(f"\nüßÆ EMBEDDINGS (text-embedding-3-large):")
    print(f"  ‚úÖ Generated:          {stats['embedding_success']}")
    
    print(f"\nüóÑÔ∏è  AZURE AI SEARCH:")
    print(f"  ‚úÖ Documents Stored:   {stats['azure_ai_search_stored']}")
    print(f"  üìä Indexes Created:    {stats['processed_providers']} (one per provider)")
    
    print(f"\nü§ñ GPT-4o EXTRACTION:")
    print(f"  ‚úÖ Success:            {stats['gpt_extraction_success']}")
    print(f"  ‚ùå Failed:             {stats['gpt_extraction_failed']}")
    
    print(f"\nüìà CONFIDENCE DISTRIBUTION:")
    print(f"  ‚úÖ High Confidence:    {stats['highconfidence_count']} docs (‚â•{config.get('confidence_threshold', 0.90)*100:.0f}%)")
    print(f"  ‚ö†Ô∏è  Low Confidence:     {stats['lowconfidence_count']} docs (<{config.get('confidence_threshold', 0.90)*100:.0f}%)")
    
    print(f"\nüí∞ COST SUMMARY:")
    print(f"  Total Cost:           ${stats['total_cost']:.2f} USD")
    if stats['processed_documents'] > 0:
        print(f"  Cost Per Document:    ${stats['total_cost']/stats['processed_documents']:.4f} USD")
    
    print(f"\nüìÅ OUTPUT LOCATION:")
    print(f"  Azure Blob Container: {config['AzureBlob']['outputcontainer']}")
    print(f"  Folder Structure:     highconfidence/<provider>/processedjsonresult/")
    print(f"                        highconfidence/<provider>/processedcsvresult/")
    print(f"                        highconfidence/<provider>/estimatedcosttracking/")
    print(f"                        lowconfidence/<provider>/processedjsonresult/")
    print(f"                        lowconfidence/<provider>/processedcsvresult/")
    print(f"                        lowconfidence/<provider>/estimatedcosttracking/")
    
    print("\n" + "="*70)
    if stats['unprocessed_providers'] == 0 and stats['failed_documents'] == 0:
        print("  ‚úÖ ALL PROCESSING COMPLETED SUCCESSFULLY!")
    elif stats['processed_providers'] > 0:
        print("  ‚ö†Ô∏è  PROCESSING COMPLETED WITH SOME ERRORS (see above)")
    else:
        print("  ‚ùå PROCESSING FAILED - NO PROVIDERS PROCESSED")
    print("="*70 + "\n")
    
    log_complete(len(providers), len(all_docs))


if __name__ == "__main__":
    main()
